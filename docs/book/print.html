<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Iris Documentation</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="highlight-css" href="highlight.css">
        <link rel="stylesheet" id="tomorrow-night-css" href="tomorrow-night.css">
        <link rel="stylesheet" id="ayu-highlight-css" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "";
            const default_light_theme = "light";
            const default_dark_theme = "navy";
            window.path_to_searchindex_js = "searchindex.js";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>←</kbd> or <kbd>→</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Iris Documentation</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/mosuka/iris" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <div class="search-wrapper">
                            <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                            <div class="spinner-wrapper">
                                <i class="fa fa-spinner fa-spin"></i>
                            </div>
                        </div>
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="iris"><a class="header" href="#iris">IRiS</a></h1>
<p><a href="https://crates.io/crates/iris"><img src="https://img.shields.io/crates/v/iris.svg" alt="Crates.io" /></a>
<a href="https://docs.rs/iris"><img src="https://docs.rs/iris/badge.svg" alt="Documentation" /></a>
<a href="https://opensource.org/licenses/MIT"><img src="https://img.shields.io/badge/License-MIT-yellow.svg" alt="License: MIT" /></a></p>
<p>IRiS is a <strong>high-performance</strong> search core library written in Rust, designed for <strong>Information Retrieval with Semantics</strong>.</p>
<p>IRiS provides the foundational mechanisms <strong>essential for</strong> advanced search capabilities:</p>
<ul>
<li><strong>Lexical search primitives</strong> for precise, exact-match retrieval</li>
<li><strong>Vector-based similarity search</strong> for deep semantic understanding</li>
<li><strong>Hybrid scoring and ranking</strong> to synthesize multiple signals into coherent results</li>
</ul>
<p>Rather than functioning as a monolithic search engine, IRiS is architected as a <strong>composable search core</strong> — a suite of modular building blocks designed to be embedded into applications, extended with custom logic, or orchestrated within distributed systems.</p>
<h2 id="documentation"><a class="header" href="#documentation">Documentation</a></h2>
<p>Comprehensive documentation is available in the <a href="https://github.com/mosuka/iris/tree/main/docs"><code>docs/</code></a> directory and online at <a href="https://mosuka.github.io/iris/">https://mosuka.github.io/iris/</a>:</p>
<ul>
<li><a href="https://mosuka.github.io/iris/getting_started/index.html"><strong>Getting Started</strong></a>: Installation and basic usage.</li>
<li><a href="https://mosuka.github.io/iris/concepts/index.html"><strong>Core Concepts</strong></a>: Architecture, Lexical Search, and Vector Search.</li>
<li><a href="https://mosuka.github.io/iris/advanced/index.html"><strong>Advanced Features</strong></a>: ID Management, Persistence, and Deletions.</li>
<li><a href="https://docs.rs/iris"><strong>API Reference</strong></a></li>
</ul>
<h2 id="features"><a class="header" href="#features">Features</a></h2>
<ul>
<li><strong>Pure Rust Implementation</strong>: Memory-safe and fast performance with zero-cost abstractions.</li>
<li><strong>Hybrid Search</strong>: Seamlessly combine BM25 lexical search with HNSW vector search using configurable fusion strategies.</li>
<li><strong>Multimodal capabilities</strong>: Native support for text-to-image and image-to-image search via CLIP embeddings.</li>
<li><strong>Rich Query DSL</strong>: Term, phrase, boolean, fuzzy, wildcard, range, and geographic queries.</li>
<li><strong>Flexible Analysis</strong>: Configurable pipelines for tokenization, normalization, and stemming (including CJK support).</li>
<li><strong>Pluggable Storage</strong>: Interfaces for in-memory, file-system, and memory-mapped storage backends.</li>
</ul>
<h2 id="quick-start"><a class="header" href="#quick-start">Quick Start</a></h2>
<pre><pre class="playground"><code class="language-rust">use iris::{Document, Engine, FieldOption, FusionAlgorithm, Schema, SearchRequestBuilder};
use iris::analysis::analyzer::standard::StandardAnalyzer;
use iris::lexical::{FieldOption as LexicalFieldOption, TextOption, TermQuery};
use iris::vector::{FlatOption, VectorOption, VectorSearchRequestBuilder};
use iris::storage::{StorageConfig, StorageFactory};
use iris::storage::memory::MemoryStorageConfig;
use std::sync::Arc;

fn main() -&gt; iris::Result&lt;()&gt; {
    // 1. Create storage
    let storage = StorageFactory::create(StorageConfig::Memory(MemoryStorageConfig::default()))?;

    // 2. Define schema with separate lexical and vector fields
    let schema = Schema::builder()
        .add_field("content", FieldOption::Lexical(LexicalFieldOption::Text(TextOption::default())))
        .add_field("content_vec", FieldOption::Vector(VectorOption::Flat(FlatOption { dimension: 384, ..Default::default() })))
        .build();

    // 3. Create engine with analyzer and embedder
    let engine = Engine::builder(storage, schema)
        .analyzer(Arc::new(StandardAnalyzer::default()))
        .embedder(Arc::new(MyEmbedder))  // Your embedder implementation
        .build()?;

    engine.index(
        Document::new_with_id("doc1")
            .add_text("content", "Rust is a systems programming language")
            .add_text("content_vec", "Rust is a systems programming language")
    )?;
    engine.index(
        Document::new_with_id("doc2")
            .add_text("content", "Python is great for machine learning")
            .add_text("content_vec", "Python is great for machine learning")
    )?;
    engine.commit()?;

    // 4. Hybrid search (combines lexical keyword match + semantic similarity)
    let results = engine.search(
        SearchRequestBuilder::new()
            .with_lexical(Box::new(TermQuery::new("content", "programming")))
            .with_vector(VectorSearchRequestBuilder::new().add_text("content_vec", "systems language").build())
            .fusion(FusionAlgorithm::RRF { k: 60.0 })
            .build()
    )?;

    // 5. Display results with document content
    for hit in results {
        if let Ok(Some(doc)) = engine.get_document(hit.doc_id) {
            let id = doc.id().unwrap_or("unknown");
            let content = doc.fields.get("content").and_then(|v| v.as_text()).unwrap_or("");
            println!("[{}] {} (internal_id={}, score={:.4})", id, content, hit.doc_id, hit.score);
        }
    }

    Ok(())
}</code></pre></pre>
<h2 id="examples"><a class="header" href="#examples">Examples</a></h2>
<p>You can find usage examples in the <a href="https://github.com/mosuka/iris/tree/main/examples"><code>examples/</code></a> directory:</p>
<h3 id="search"><a class="header" href="#search">Search</a></h3>
<ul>
<li><a href="https://github.com/mosuka/iris/blob/main/examples/search.rs">Unified Search</a> - Lexical, Vector, and Hybrid search in one cohesive example</li>
<li><a href="https://github.com/mosuka/iris/blob/main/examples/multimodal_search.rs">Multimodal Search</a> - Text-to-image and image-to-image search</li>
</ul>
<h3 id="query-types"><a class="header" href="#query-types">Query Types</a></h3>
<ul>
<li><a href="https://github.com/mosuka/iris/blob/main/examples/term_query.rs">Term Query</a> - Basic keyword search</li>
<li><a href="https://github.com/mosuka/iris/blob/main/examples/boolean_query.rs">Boolean Query</a> - Complex boolean expressions (AND, OR, NOT)</li>
<li><a href="https://github.com/mosuka/iris/blob/main/examples/phrase_query.rs">Phrase Query</a> - Exact phrase matching</li>
<li><a href="https://github.com/mosuka/iris/blob/main/examples/fuzzy_query.rs">Fuzzy Query</a> - Approximate string matching</li>
<li><a href="https://github.com/mosuka/iris/blob/main/examples/wildcard_query.rs">Wildcard Query</a> - Pattern-based search</li>
<li><a href="https://github.com/mosuka/iris/blob/main/examples/range_query.rs">Range Query</a> - Numeric and date range queries</li>
<li><a href="https://github.com/mosuka/iris/blob/main/examples/geo_query.rs">Geo Query</a> - Geographic search</li>
<li><a href="https://github.com/mosuka/iris/blob/main/examples/span_query.rs">Span Query</a> - Positional queries</li>
</ul>
<h3 id="embeddings"><a class="header" href="#embeddings">Embeddings</a></h3>
<ul>
<li><a href="https://github.com/mosuka/iris/blob/main/examples/embedding_with_candle.rs">Candle Embedder</a> - Local BERT embeddings</li>
<li><a href="https://github.com/mosuka/iris/blob/main/examples/embedding_with_openai.rs">OpenAI Embedder</a> - Cloud-based embeddings</li>
</ul>
<h2 id="contributing"><a class="header" href="#contributing">Contributing</a></h2>
<p>We welcome contributions! Please see our <a href="https://github.com/mosuka/iris/blob/main/CONTRIBUTING.md">Contributing Guidelines</a> for details.</p>
<ol>
<li>Fork the repository</li>
<li>Create a feature branch (<code>git checkout -b feature/amazing-feature</code>)</li>
<li>Commit your changes (<code>git commit -m 'Add some amazing feature'</code>)</li>
<li>Push to the branch (<code>git push origin feature/amazing-feature</code>)</li>
<li>Open a Pull Request</li>
</ol>
<h2 id="license"><a class="header" href="#license">License</a></h2>
<p>This project is licensed under either of</p>
<ul>
<li>MIT License (<a href="https://github.com/mosuka/iris/blob/main/LICENSE-MIT">LICENSE-MIT</a> or <a href="http://opensource.org/licenses/MIT">http://opensource.org/licenses/MIT</a>)</li>
</ul>
<p>at your option.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="getting-started"><a class="header" href="#getting-started">Getting Started</a></h1>
<p>Welcome to the Iris getting started guide. This section is designed to try out Iris quickly.</p>
<h2 id="workflow-overview"><a class="header" href="#workflow-overview">Workflow Overview</a></h2>
<p>Building a search application with Iris typically involves the following steps:</p>
<ol>
<li><strong>Installation</strong>: Adding <code>iris</code> to your project dependencies.</li>
<li><strong>Configuration</strong>: Setting up the <code>Engine</code> with <code>Schema</code> and choosing a storage backend (Memory, File, or Mmap).</li>
<li><strong>Indexing</strong>: Inserting documents that contain both text (for lexical search) and vectors (for semantic search).</li>
<li><strong>Searching</strong>: Executing queries to retrieve relevant results.</li>
</ol>
<h2 id="in-this-section"><a class="header" href="#in-this-section">In this Section</a></h2>
<ul>
<li><strong><a href="./getting_started/installation.html">Installation</a></strong>
Learn how to add Iris to your Rust project and configure necessary feature flags (e.g., for different tokenizer support).</li>
</ul>
<h2 id="quick-example"><a class="header" href="#quick-example">Quick Example</a></h2>
<p>For a complete, runnable example of how to set up a Hybrid Search (combining vector and text search), please refer to the <strong><a href="https://github.com/mosuka/iris/blob/main/examples/search.rs">Unified Search Example</a></strong> in the repository.</p>
<pre><pre class="playground"><code class="language-rust">use iris::{Document, Engine, FieldOption, FusionAlgorithm, Schema, SearchRequestBuilder};
use iris::analysis::analyzer::standard::StandardAnalyzer;
use iris::lexical::{FieldOption as LexicalFieldOption, TextOption, TermQuery};
use iris::vector::{FlatOption, VectorOption, VectorSearchRequestBuilder};
use iris::storage::{StorageConfig, StorageFactory};
use iris::storage::memory::MemoryStorageConfig;
use std::sync::Arc;

fn main() -&gt; iris::Result&lt;()&gt; {
    // 1. Create storage
    let storage = StorageFactory::create(StorageConfig::Memory(MemoryStorageConfig::default()))?;

    // 2. Define schema with separate lexical and vector fields
    let schema = Schema::builder()
        .add_field("content", FieldOption::Lexical(LexicalFieldOption::Text(TextOption::default())))
        .add_field("content_vec", FieldOption::Vector(VectorOption::Flat(FlatOption { dimension: 384, ..Default::default() })))
        .build();

    // 3. Create engine with analyzer and embedder
    let engine = Engine::builder(storage, schema)
        .analyzer(Arc::new(StandardAnalyzer::default()))
        .embedder(Arc::new(MyEmbedder))  // Your embedder implementation
        .build()?;

    engine.put_document("doc1",
        Document::new()
            .add_text("content", "Rust is a systems programming language")
            .add_text("content_vec", "Rust is a systems programming language")
    )?;
    engine.put_document("doc2",
        Document::new()
            .add_text("content", "Python is great for machine learning")
            .add_text("content_vec", "Python is great for machine learning")
    )?;
    engine.commit()?;

    // 4. Hybrid search (combines lexical keyword match + semantic similarity)
    let results = engine.search(
        SearchRequestBuilder::new()
            .with_lexical(Box::new(TermQuery::new("content", "programming")))
            .with_vector(VectorSearchRequestBuilder::new().add_text("content_vec", "systems language").build())
            .fusion(FusionAlgorithm::RRF { k: 60.0 })
            .build()
    )?;

    // 5. Display results
    for hit in results {
        println!("[{}] score={:.4}", hit.id, hit.score);
    }

    Ok(())
}</code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="installation"><a class="header" href="#installation">Installation</a></h1>
<p>Add iris to your <code>Cargo.toml</code>:</p>
<pre><code class="language-toml">[dependencies]
iris = "0.1.0"
</code></pre>
<h2 id="feature-flags"><a class="header" href="#feature-flags">Feature Flags</a></h2>
<p>Iris provides several feature flags to enable optional functionalities, particularly for embedding generation:</p>
<ul>
<li><code>embeddings-candle</code>: Enables Hugging Face Candle integration for running models locally.</li>
<li><code>embeddings-openai</code>: Enables OpenAI API integration.</li>
<li><code>embeddings-multimodal</code>: Enables multimodal embedding support (image + text) via Candle.</li>
<li><code>embeddings-all</code>: Enables all embedding features.</li>
</ul>
<pre><code class="language-toml"># Example: interacting with OpenAI
iris = { version = "0.1.0", features = ["embeddings-openai"] }
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="core-concepts"><a class="header" href="#core-concepts">Core Concepts</a></h1>
<p>This section details the internal architecture and design philosophy of IRiS, based on its current Rust implementation.</p>
<h2 id="unified-vector-engine-architecture"><a class="header" href="#unified-vector-engine-architecture">Unified Vector Engine Architecture</a></h2>
<p>At the heart of IRiS is the <code>VectorEngine</code> (<code>src/vector/engine.rs</code>), which acts as the unified coordinator for all search operations. Unlike traditional systems that treat vector search and keyword search as separate silos, IRiS integrates them into a single cohesive system.</p>
<h3 id="key-components"><a class="header" href="#key-components">Key Components</a></h3>
<ol>
<li>
<p><strong>VectorEngine</strong>:</p>
<ul>
<li><strong>Responsibility</strong>: Manages the lifecycle of documents, handles persistence (WAL &amp; Snapshots), and coordinates search queries.</li>
<li><strong>Unified Indexing</strong>: When a document is indexed, <code>VectorEngine</code> splits it into:
<ul>
<li><strong>Vector Data</strong>: Stored in field-specific indices (HNSW, Flat, IVF).</li>
<li><strong>Lexical Data</strong>: Stored in a managed <code>LexicalEngine</code> instance (<code>metadata_index</code>).</li>
</ul>
</li>
<li><strong>Implicit Schema</strong>: By default, fields are registered dynamically upon insertion (<code>implicit_schema: true</code>), allowing for a schemaless-like experience while maintaining strict typing internally.</li>
</ul>
</li>
<li>
<p><strong>LexicalEngine</strong> (<code>src/lexical/engine.rs</code>):</p>
<ul>
<li><strong>Role</strong>: Serves as an internal component of <code>VectorEngine</code> to handle:
<ul>
<li><strong>Inverted Indices</strong>: For <code>Term</code>, <code>Phrase</code>, and <code>Boolean</code> queries.</li>
<li><strong>ID Mapping</strong>: Maps external string IDs (e.g., "product-123") to internal 64-bit integer IDs (<code>u64</code>).</li>
<li><strong>Metadata Storage</strong>: Stores non-vector document fields (JSON-like metadata).</li>
</ul>
</li>
<li><strong>Design</strong>: Uses a "Near Real-Time" (NRT) architecture with a <code>writer_cache</code> for uncommitted changes and a <code>searcher_cache</code> for committed views.</li>
</ul>
</li>
<li>
<p><strong>Storage Abstraction</strong> (<code>src/storage.rs</code>):</p>
<ul>
<li>All components interact with data through the <code>Storage</code> trait, enabling seamless switching between backends:
<ul>
<li><code>MemoryStorage</code>: Pure in-memory usage (great for testing/embedded).</li>
<li><code>FileStorage</code>: Standard disk-based persistence.</li>
<li><code>MmapStorage</code>: Memory-mapped files for high-performance large datasets.</li>
</ul>
</li>
</ul>
</li>
</ol>
<h2 id="data-model"><a class="header" href="#data-model">Data Model</a></h2>
<p>IRiS uses a flexible data model centered around the <code>DocumentVector</code> structure.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct DocumentVector {
    /// Vector fields (e.g., "embedding", "image_vec")
    pub fields: HashMap&lt;String, StoredVector&gt;,
    /// Metadata fields (e.g., "title", "category", "_id")
    pub metadata: HashMap&lt;String, String&gt;,
}
<span class="boring">}</span></code></pre></pre>
<ul>
<li><strong>External ID (<code>_id</code>)</strong>: Every document has a unique string ID. Internally, this is mapped to a dense <code>u64</code> ID for performance.</li>
<li><strong>Vector Fields</strong>: Store high-dimensional vectors. Supported formats include:
<ul>
<li><strong>Flat</strong>: Brute-force exact search.</li>
<li><strong>HNSW</strong>: Hierarchical Navigable Small World graphs for approximate nearest neighbor search.</li>
<li><strong>IVF</strong>: Inverted File Index for quantized search.</li>
</ul>
</li>
<li><strong>Payloads</strong>: You can index raw text or images. The engine uses configured <code>Embedder</code>s (e.g., CLIP, BERT) to convert these payloads into vectors on the fly.</li>
</ul>
<h2 id="hybrid-search--fusion"><a class="header" href="#hybrid-search--fusion">Hybrid Search &amp; Fusion</a></h2>
<p>One of IRiS's core strengths is its ability to perform <strong>Hybrid Search</strong>—combining semantic similarity (Vector) with keyword relevance (Lexical).</p>
<h3 id="search-flow"><a class="header" href="#search-flow">Search Flow</a></h3>
<ol>
<li><strong>Request</strong>: The user sends a <code>VectorSearchRequest</code> containing both a query vector and a lexical query (e.g., "find red shoes" + <code>category:"sale"</code>).</li>
<li><strong>Parallel Execution</strong>:
<ul>
<li>The <strong>Vector Searcher</strong> scans the HNSW index to find nearest neighbors.</li>
<li>The <strong>Lexical Searcher</strong> scans the Inverted Index to find matching terms.</li>
</ul>
</li>
<li><strong>Fusion</strong>: The results are merged using a configurable strategy (<code>FusionAlgorithm</code>):
<ul>
<li><strong>RRF (Reciprocal Rank Fusion)</strong>: Ranks documents based on their positional rank in each result set. Robust and parameter-free.</li>
<li><strong>Weighted Sum</strong>: Linearly combines normalized scores (<code>alpha * vector_score + beta * lexical_score</code>).</li>
</ul>
</li>
</ol>
<h2 id="persistence--durability"><a class="header" href="#persistence--durability">Persistence &amp; durability</a></h2>
<p>IRiS ensures data safety through a combination of <strong>Write-Ahead Logging (WAL)</strong> and <strong>Snapshots</strong>.</p>
<ul>
<li><strong>WAL (<code>src/vector/index/wal.rs</code>)</strong>: Every write operation (Upsert/Delete) is appended to a log file immediately. This ensures that even if the process crashes, recent changes can be replayed on startup.</li>
<li><strong>Snapshots</strong>: Periodically, the in-memory state of the registry and documents is serialized to disk (<code>document_snapshot.bin</code>). This speeds up recovery by avoiding full WAL replay.</li>
<li><strong>Commit</strong>: Calling <code>commit()</code> forces a flush of all in-memory buffers to persistent storage and rotates the logs.</li>
</ul>
<pre><code class="language-mermaid">graph TD
    User[User Update] --&gt;|1. Write| WAL[Write-Ahead Log]
    User --&gt;|2. Update| Mem[In-Memory Index]
    
    subgraph "Persistence"
        WAL
        Snapshot[Snapshot File]
    end
    
    Mem --&gt;|Commit/Flush| Snapshot
    WAL --&gt;|Recovery| Mem
    Snapshot --&gt;|Recovery| Mem
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="architecture"><a class="header" href="#architecture">Architecture</a></h1>
<p>Iris is built on a unified modular architecture where the <strong>Engine</strong> serves as the core orchestrator.</p>
<h2 id="1-engine-unified"><a class="header" href="#1-engine-unified">1. Engine (Unified)</a></h2>
<p>The primary engine associated with the library. It unifies vector similarity search with full-text search capabilities.</p>
<ul>
<li><strong>Orchestration</strong>: Manages both VectorStore (HNSW/IVF/Flat index) and LexicalStore (Inverted Index).</li>
<li><strong>Hybrid Search</strong>: Performs unified queries combining vector similarity and keyword relevance.</li>
<li><strong>ID Management</strong>: Manages external ID to internal integer ID mapping.</li>
</ul>
<h2 id="2-lexicalstore-component"><a class="header" href="#2-lexicalstore-component">2. LexicalStore (Component)</a></h2>
<p>Operates as a component managed by the Engine, handling full-text search.</p>
<ul>
<li><strong>Inverted Index</strong>: Standard posting lists for term lookups.</li>
<li><strong>Analyzers</strong>: Tokenization and normalization pipeline.</li>
<li><strong>Query Parser</strong>: Supports boolean, phrase, and structured queries.</li>
</ul>
<h2 id="3-vectorstore-component"><a class="header" href="#3-vectorstore-component">3. VectorStore (Component)</a></h2>
<p>Operates as a component managed by the Engine, handling vector similarity search.</p>
<ul>
<li><strong>Vector Index</strong>: Supports HNSW, IVF, and Flat index types.</li>
<li><strong>Embedder</strong>: Automatic text/image to vector embedding.</li>
<li><strong>Distance Metrics</strong>: Cosine, Euclidean, and DotProduct similarity.</li>
</ul>
<pre><code class="language-mermaid">graph TD
    subgraph "Application Layer"
        User[User / App]
        Req[SearchRequest]
    end

    subgraph "Iris Engine"
        E[Engine]

        subgraph "Components"
            VS[VectorStore]
            LS[LexicalStore]
            DS[DocumentStore]
            WAL[Write-Ahead Log]
        end

        Fusion[Result Fusion]
    end

    subgraph "Storage Layer"
        FS[FileStorage / Mmap]
    end

    %% Flows
    User --&gt;|index/search| E
    E --&gt; VS
    E --&gt; LS
    E --&gt; DS
    E --&gt; WAL

    LS --&gt; FS
    VS --&gt; FS
    DS --&gt; FS
    WAL --&gt; FS

    %% Search Flow
    Req --&gt; E
    E --&gt;|Vector Query| VS
    E --&gt;|Keyword Query| LS

    VS --&gt;|Hits| Fusion
    LS --&gt;|Hits| Fusion

    Fusion --&gt;|Unified Results| User
</code></pre>
<h2 id="storage-layer"><a class="header" href="#storage-layer">Storage Layer</a></h2>
<p>All components abstract their storage through a <code>Storage</code> trait, allowing seamless switching between:</p>
<ul>
<li><strong>Memory</strong>: For testing and ephemeral data.</li>
<li><strong>File</strong>: For persistent on-disk storage.</li>
<li><strong>Mmap</strong>: For high-performance memory-mapped file access.</li>
</ul>
<h2 id="component-structure"><a class="header" href="#component-structure">Component Structure</a></h2>
<p>Each store follows a simplified 4-member structure pattern:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct LexicalStore {
    index: Box&lt;dyn LexicalIndex&gt;,
    writer_cache: Mutex&lt;Option&lt;Box&lt;dyn LexicalIndexWriter&gt;&gt;&gt;,
    searcher_cache: RwLock&lt;Option&lt;Box&lt;dyn LexicalIndexSearcher&gt;&gt;&gt;,
    doc_store: Arc&lt;RwLock&lt;UnifiedDocumentStore&gt;&gt;,
}

pub struct VectorStore {
    index: Box&lt;dyn VectorIndex&gt;,
    writer_cache: Mutex&lt;Option&lt;Box&lt;dyn VectorIndexWriter&gt;&gt;&gt;,
    searcher_cache: RwLock&lt;Option&lt;Box&lt;dyn VectorIndexSearcher&gt;&gt;&gt;,
    doc_store: Arc&lt;RwLock&lt;UnifiedDocumentStore&gt;&gt;,
}
<span class="boring">}</span></code></pre></pre>
<p>This pattern provides:</p>
<ul>
<li><strong>Lazy Initialization</strong>: Writers and searchers are created on-demand.</li>
<li><strong>Cache Invalidation</strong>: Searcher cache is invalidated after commit/optimize.</li>
<li><strong>Shared Document Store</strong>: Both stores share the same document storage.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="lexical-search"><a class="header" href="#lexical-search">Lexical Search</a></h1>
<p>Lexical search matches documents based on exact or approximate keyword matches. It is the traditional "search engine" functionality found in Lucene or Elasticsearch.</p>
<blockquote>
<p><strong>Note</strong>: In the unified Iris architecture, Lexical Search is handled by the <code>Engine</code>, which orchestrates both lexical (LexicalStore) and vector (VectorStore) components concurrently.</p>
</blockquote>
<h2 id="document-structure"><a class="header" href="#document-structure">Document Structure</a></h2>
<p>In Iris, a <strong>Document</strong> is the fundamental unit of indexing. It follows a <strong>schema-less</strong> design, allowing fields to be added dynamically without defining a schema upfront.</p>
<p>Each <code>Document</code> consists of multiple <code>Fields</code> stored in a Map where the key is the field name. Each <code>Field</code> has a <strong>Value</strong> and <strong>Options</strong> defining how it should be indexed.</p>
<pre><code class="language-mermaid">flowchart LR
    IntID1("Internal ID&lt;br&gt;1") --&gt; Document_Container

    subgraph Document_Container [Document]
        direction TB
        
        ExtID1["Field (External ID)&lt;br&gt;Name: '_id'&lt;br&gt;Value: 'product_123'&lt;br&gt;Type: Text"]
        F11["Field&lt;br&gt;Name: 'title'&lt;br&gt;Value: 'Apple'&lt;br&gt;Type: Text"]
        F12["Field&lt;br&gt;Name: 'price'&lt;br&gt;Value: 10.00&lt;br&gt;Type: Float"]
    end
    
    IntID2("Internal ID&lt;br&gt;2") --&gt; Document_Container2

    subgraph Document_Container2 [Document]
        direction TB
        
        ExtID2["Field (External ID)&lt;br&gt;Name: '_id'&lt;br&gt;Value: 'product_456'&lt;br&gt;Type: Text"]
        F21["Field&lt;br&gt;Name: 'title'&lt;br&gt;Value: 'Orange'&lt;br&gt;Type: Text"]
        F22["Field&lt;br&gt;Name: 'price'&lt;br&gt;Value: 11.00&lt;br&gt;Type: Float"]
    end
</code></pre>
<h3 id="document"><a class="header" href="#document">Document</a></h3>
<p>The fundamental unit of indexing in Iris.</p>
<ul>
<li><strong>Schema-less</strong>: Fields can be added dynamically without a predefined schema.</li>
<li><strong>Map Structure</strong>: Fields are stored in a <code>HashMap</code> where the key is the field name (String).</li>
<li><strong>Flexible</strong>: A single document can contain a mix of different field types (Text, Integer, Blob, etc.).</li>
</ul>
<h3 id="field"><a class="header" href="#field">Field</a></h3>
<p>A container representing a single data point within a document.</p>
<ul>
<li><strong>Value</strong>: The actual data content (e.g., "Hello World", 123, true). Defined by <code>FieldValue</code>.</li>
<li><strong>Option</strong>: Configuration for how this data should be handled (e.g., indexed, stored). Defined by <code>FieldOption</code>.</li>
</ul>
<h3 id="field-values"><a class="header" href="#field-values">Field Values</a></h3>
<ul>
<li><strong>Text</strong>: UTF-8 string. Typically analyzed and indexed for full-text search.</li>
<li><strong>Integer / Float</strong>: Numeric values. Used for range queries (BKD Tree) and sorting.</li>
<li><strong>Boolean</strong>: True/False values.</li>
<li><strong>DateTime</strong>: UTC timestamps.</li>
<li><strong>Geo</strong>: Latitude/Longitude coordinates. Indexed in a 2D BKD tree for efficient spatial queries (distance and bounding box) and stored for precise calculations.</li>
<li><strong>Blob</strong>: Raw byte data with MIME type. Used for storing binary content (images, etc.) or vector source data. <strong>Stored only</strong>, never indexed by the lexical engine.</li>
</ul>
<h3 id="field-options"><a class="header" href="#field-options">Field Options</a></h3>
<p>Configuration for the field defining how it should be indexed and stored.</p>
<ul>
<li><strong>TextOption</strong>:
<ul>
<li><code>indexed</code>: If true, the text is analyzed and added to the inverted index (searchable).</li>
<li><code>stored</code>: If true, the original text is stored in the doc store (retrievable).</li>
<li><code>term_vectors</code>: If true, stores term positions and offsets (needed for highlighting and "More Like This").</li>
</ul>
</li>
<li><strong>IntegerOption / FloatOption</strong>:
<ul>
<li><code>indexed</code>: If true, the value is added to the BKD tree (range searchable).</li>
<li><code>stored</code>: If true, the original value is stored.</li>
</ul>
</li>
<li><strong>BooleanOption</strong>:
<ul>
<li><code>indexed</code>: If true, the value is indexed.</li>
<li><code>stored</code>: If true, the original value is stored.</li>
</ul>
</li>
<li><strong>DateTimeOption</strong>:
<ul>
<li><code>indexed</code>: If true, the timestamp is added to the BKD tree (range searchable).</li>
<li><code>stored</code>: If true, the original timestamp is stored.</li>
</ul>
</li>
<li><strong>GeoOption</strong>:
<ul>
<li><code>indexed</code>: If true, the coordinates are added to the 2D BKD tree (efficient spatial search).</li>
<li><code>stored</code>: If true, the original coordinates are stored.</li>
</ul>
</li>
<li><strong>BlobOption</strong>:
<ul>
<li><code>stored</code>: If true, the binary data is stored. <strong>Note</strong>: Blobs cannot be indexed by the lexical engine.</li>
</ul>
</li>
</ul>
<h2 id="indexing-process"><a class="header" href="#indexing-process">Indexing Process</a></h2>
<p>The lexical indexing process translates documents into inverted indexes and BKD trees.</p>
<pre><code class="language-mermaid">graph TD
    subgraph "Indexing Flow"
        Input["Raw Data"] --&gt; DocBuilder["Document Construction"]
        
        subgraph "Processing (InvertedIndexWriter)"
            DocBuilder --&gt;|Text| CharFilter["Char Filter"]
            DocBuilder --&gt;|Numeric/Date/Geo| Normalizer["String Normalizer"]
            DocBuilder --&gt;|Numeric/Date/Geo| PtExt["Point Extractor"]
            DocBuilder --&gt;|Stored Field| StoreProc["Field Values Collector"]
            DocBuilder --&gt;|All Fields| LenTracker["Field Length Tracker"]
            DocBuilder --&gt;|Doc Values| DVTracker["Doc Values Collector"]
            
            subgraph "Analysis Chain"
                CharFilter --&gt; Tokenizer["Tokenizer"]
                Tokenizer --&gt; TokenFilter["Token Filter"]
            end
        end
        
        subgraph "In-Memory Buffering"
            TokenFilter --&gt;|Terms| InvBuffer["Term Posting Index"]
            Normalizer --&gt;|Terms| InvBuffer
            PtExt --&gt;|Points| BkdBuffer["Point Values Buffer"]
            StoreProc --&gt;|Data| DocsBuffer["Stored Docs Buffer"]
        end
        
        subgraph "Segment Flushing (Disk)"
            InvBuffer --&gt;|Write| Postings[".dict / .post"]
            BkdBuffer --&gt;|Sort &amp; Write| BKD[".bkd"]
            DocsBuffer --&gt;|Write| DOCS[".docs"]
            DVTracker --&gt;|Write| DV[".dv"]
            LenTracker --&gt;|Write| LENS[".lens"]
            InvBuffer -.-&gt;|Stats| Meta[".meta / .fstats"]
        end
    end
</code></pre>
<ol>
<li><strong>Document Processing</strong>:
<ul>
<li><strong>Analysis &amp; Normalization</strong>: Text is processed through the Analysis Chain (<code>Char Filter</code>, <code>Tokenizer</code>, <code>Token Filter</code>). Non-text fields are handled by the <code>String Normalizer</code>.</li>
<li><strong>Point Extraction</strong>: Multidimensional values (Numeric, Date, and Geo) are extracted by the <code>Point Extractor</code> for spatial indexing (BKD Tree).</li>
<li><strong>Tracking &amp; Collection</strong>: <code>Field Length Tracker</code> and <code>Doc Values Collector</code> gather metadata and columnar data.</li>
</ul>
</li>
<li><strong>In-Memory Buffering</strong>:
<ul>
<li>Terms are added to the <code>Term Posting Index</code>.</li>
<li>Extracted points and stored fields are staged in the <code>Point Values Buffer</code> and <code>Stored Docs Buffer</code>.</li>
</ul>
</li>
<li><strong>Segment Flushing</strong>:
<ul>
<li>Buffered data is periodically sorted and serialized into immutable <strong>Segment</strong> files on disk.</li>
</ul>
</li>
<li><strong>Merging</strong>:
<ul>
<li>A background process automatically merges smaller segments into larger ones to optimize read performance and reclaim space from deleted documents.</li>
</ul>
</li>
</ol>
<h3 id="analyzers"><a class="header" href="#analyzers">Analyzers</a></h3>
<p>Text analysis is the process of converting raw text into tokens. An Analyzer is typically composed of a pipeline:</p>
<ol>
<li><strong>Char Filters</strong>: Transform the raw character stream (e.g., removing HTML tags).</li>
<li><strong>Tokenizer</strong>: Splits the character stream into a token stream (e.g., splitting by whitespace).</li>
<li><strong>Token Filters</strong>: Modify the token stream (e.g., lowercasing, stemming, removing stop words).</li>
</ol>
<p>Iris provides several built-in analyzers:</p>
<ul>
<li><strong>StandardAnalyzer</strong>: Good default for most European languages.</li>
<li><strong>JapaneseAnalyzer</strong>: Optimized for Japanese text using Lindera (morphological analysis).</li>
<li><strong>KeywordAnalyzer</strong>: Treats the entire input as a single token.</li>
<li><strong>PipelineAnalyzer</strong>: A flexible builder for creating custom analysis pipelines.</li>
</ul>
<h2 id="core-concepts-1"><a class="header" href="#core-concepts-1">Core Concepts</a></h2>
<h3 id="inverted-index"><a class="header" href="#inverted-index">Inverted Index</a></h3>
<p>The inverted index is the fundamental structure for full-text search. While a traditional database maps documents to their terms, an inverted index maps <strong>terms to the list of documents</strong> containing them.</p>
<ul>
<li><strong>Term Dictionary</strong>: A sorted repository of all unique terms across the index.</li>
<li><strong>Postings Lists</strong>: For each term, a list of document IDs (postings) where the term appears, along with frequency and position data for scoring.</li>
</ul>
<h3 id="bkd-tree"><a class="header" href="#bkd-tree">BKD Tree</a></h3>
<p>For non-textual data like numbers, dates, and geographic coordinates, Iris uses a <strong>BKD Tree</strong>. It is a multi-dimensional tree structure optimized for block-based storage on disk.
Unlike an inverted index, a BKD tree is designed for <strong>range search</strong> and <strong>spatial search</strong>. It effectively partitions the data space into hierarchical blocks, allowing the search engine to skip large portions of irrelevant data.</p>
<h3 id="simd-optimization"><a class="header" href="#simd-optimization">SIMD Optimization</a></h3>
<p>Iris uses SIMD-accelerated batch scoring for high-throughput ranking. The BM25 scoring algorithm is optimized to process multiple documents simultaneously, leveraging modern CPU instructions to provide a several-fold increase in performance compared to scalar processing.</p>
<h2 id="engine-architecture"><a class="header" href="#engine-architecture">Engine Architecture</a></h2>
<h3 id="lexicalstore"><a class="header" href="#lexicalstore">LexicalStore</a></h3>
<p>The store component that manages indexing and searching for text data. It coordinates between <code>LexicalIndexWriter</code> and <code>LexicalIndexSearcher</code>.
In the unified architecture, LexicalStore operates as a <strong>sub-component</strong> managed by the <code>Engine</code>, handling the inverted index portions of hybrid documents.</p>
<h3 id="index-components"><a class="header" href="#index-components">Index Components</a></h3>
<ul>
<li><strong>InvertedIndexWriter</strong>: The primary interface for adding documents. It orchestrates analysis, point extraction, and buffering.</li>
<li><strong>Segment Manager</strong>: Controls the lifecycle and visibility of segments, maintaining the manifest and tracking deletions.</li>
<li><strong>In-Memory Buffering</strong>: High-performance mapping of terms and staged BKD/Stored data before merging into disk segments.</li>
</ul>
<h2 id="index-segment-files"><a class="header" href="#index-segment-files">Index Segment Files</a></h2>
<p>A single segment is composed of several specialized files:</p>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Extension</th><th style="text-align: left">Component</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>.dict</code></td><td style="text-align: left">Term Dictionary</td><td style="text-align: left">Maps terms to their locations in the postings list.</td></tr>
<tr><td style="text-align: left"><code>.post</code></td><td style="text-align: left">Postings Lists</td><td style="text-align: left">Stores document IDs, frequencies, and positions for each term.</td></tr>
<tr><td style="text-align: left"><code>.bkd</code></td><td style="text-align: left">BKD Tree</td><td style="text-align: left">Provides multidimensional indexing for numeric and geospatial fields.</td></tr>
<tr><td style="text-align: left"><code>.docs</code></td><td style="text-align: left">Document Store</td><td style="text-align: left">Stores the original (stored) field values in a compressed format.</td></tr>
<tr><td style="text-align: left"><code>.dv</code></td><td style="text-align: left">Doc Values</td><td style="text-align: left">Columnar storage for fast sorting and aggregations.</td></tr>
<tr><td style="text-align: left"><code>.meta</code></td><td style="text-align: left">Segment Metadata</td><td style="text-align: left">Statistics, document count, and configuration.</td></tr>
<tr><td style="text-align: left"><code>.lens</code></td><td style="text-align: left">Field Lengths</td><td style="text-align: left">Token counts per field per document (used for scoring).</td></tr>
</tbody></table>
</div>
<h2 id="search-process"><a class="header" href="#search-process">Search Process</a></h2>
<p>The search process involves structure-aware traversal and weighted scoring.</p>
<pre><code class="language-mermaid">graph TD
    subgraph "Search Flow"
        UserQuery["User Query"] --&gt; Parser
        
        subgraph "Searcher"
            Parser["Query Parser"] --&gt; QueryObj["Query"]
            QueryObj --&gt; WeightObj["Weight"]
            WeightObj --&gt; MatcherObj["Matcher"]
            WeightObj --&gt; ScorerObj["Scorer"]
            
            subgraph "Index Access"
                MatcherObj -.-&gt;|Look up| II["Inverted Index"]
                MatcherObj -.-&gt;|Range Scan| BKD["BKD Tree"]
            end
            
            MatcherObj --&gt;|Doc IDs| CollectorObj["Collector"]
            ScorerObj --&gt;|Scores| CollectorObj
            CollectorObj -.-&gt;|Sort by Field| DV["Doc Values"]
            CollectorObj --&gt;|Top Doc IDs| Fetcher["Fetcher"]
            Fetcher -.-&gt;|Retrieve Fields| Docs
        end
        
        Fetcher --&gt; Result["Search Results"]
    end
</code></pre>
<ol>
<li><strong>Query Parsing</strong>: Translates a human-friendly string or DSL into a structured <code>Query</code> tree.</li>
<li><strong>Weight Creation</strong>: Precomputes global statistics (like IDF) to prepare for execution across multiple segments.</li>
<li><strong>Matching &amp; Scoring</strong>:
<ul>
<li><strong>Matcher</strong>: Navigates the Term Dictionary or BKD Tree to identify document IDs.</li>
<li><strong>Scorer</strong>: Computes the relevance score (BM25) using precomputed weights and segment-local frequencies.</li>
</ul>
</li>
<li><strong>Collection &amp; Fetching</strong>: Aggregates top results into a sorted list and retrieves original field data for the final response.</li>
</ol>
<h2 id="query-types-1"><a class="header" href="#query-types-1">Query Types</a></h2>
<p>Iris supports a wide range of queries for different information needs.</p>
<ul>
<li><strong>Term Query</strong>: Match a single analyzed term exactly.</li>
<li><strong>Boolean Query</strong>: Logical combinations (<code>MUST</code>, <code>SHOULD</code>, <code>MUST_NOT</code>).</li>
<li><strong>Approximate Queries</strong>: <code>Fuzzy</code>, <code>Prefix</code>, <code>Wildcard</code>, and <code>Regexp</code> queries.</li>
<li><strong>Phrase Query</strong>: Matches terms in a specific order with optional "slop".</li>
<li><strong>Numeric Range Query</strong>: High-performance range search using the BKD tree.</li>
<li><strong>Geospatial Queries</strong>: Distance-based or bounding-box search for geographic points.</li>
</ul>
<h2 id="scoring-bm25"><a class="header" href="#scoring-bm25">Scoring (BM25)</a></h2>
<p>Iris uses <strong>Okapi BM25</strong> as its default scoring function. It improves results by prioritizing rare terms and normalizing for document length, ensuring that matches in shorter, focused documents are ranked appropriately.</p>
<h2 id="code-examples"><a class="header" href="#code-examples">Code Examples</a></h2>
<h3 id="1-configuring-engine-for-lexical-search"><a class="header" href="#1-configuring-engine-for-lexical-search">1. Configuring Engine for Lexical Search</a></h3>
<p>Setting up an engine with a lexical field and default analyzer.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use std::sync::Arc;
use iris::{Engine, Schema};
use iris::analysis::analyzer::standard::StandardAnalyzer;
use iris::lexical::{FieldOption, TextOption};
use iris::storage::{StorageConfig, StorageFactory};
use iris::storage::memory::MemoryStorageConfig;

fn setup_engine() -&gt; iris::Result&lt;Engine&gt; {
    let storage = StorageFactory::create(StorageConfig::Memory(MemoryStorageConfig::default()))?;

    let schema = Schema::builder()
        .add_lexical_field("title", FieldOption::Text(TextOption::default()))
        .add_lexical_field("content", FieldOption::Text(TextOption::default()))
        .build();

    Engine::builder(storage, schema)
        .analyzer(Arc::new(StandardAnalyzer::default()))
        .build()
}
<span class="boring">}</span></code></pre></pre>
<h3 id="2-adding-documents"><a class="header" href="#2-adding-documents">2. Adding Documents</a></h3>
<p>Creating and indexing documents with various field types.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use iris::{Document, DataValue};

fn add_documents(engine: &amp;Engine) -&gt; iris::Result&lt;()&gt; {
    let doc = Document::new()
        .add_text("title", "Iris Search")
        .add_text("content", "Fast and semantic search engine in Rust")
        .add_field("price", DataValue::Integer(100));

    engine.put_document("doc1", doc)?;
    engine.commit()?; // Flush and commit to make searchable
    Ok(())
}
<span class="boring">}</span></code></pre></pre>
<h3 id="3-searching-with-term-query"><a class="header" href="#3-searching-with-term-query">3. Searching with Term Query</a></h3>
<p>Executing a simple search using a term query.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use iris::SearchRequestBuilder;
use iris::lexical::TermQuery;

fn search(engine: &amp;Engine) -&gt; iris::Result&lt;()&gt; {
    let results = engine.search(
        SearchRequestBuilder::new()
            .with_lexical(Box::new(TermQuery::new("content", "rust")))
            .limit(10)
            .build()
    )?;

    for hit in results {
        println!("[{}] Score: {:.4}", hit.id, hit.score);
    }
    Ok(())
}
<span class="boring">}</span></code></pre></pre>
<h3 id="4-custom-analyzer-setup"><a class="header" href="#4-custom-analyzer-setup">4. Custom Analyzer Setup</a></h3>
<p>Configuring a Japanese analyzer for specific fields.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use iris::analysis::analyzer::japanese::JapaneseAnalyzer;

fn setup_japanese_engine() -&gt; iris::Result&lt;Engine&gt; {
    let storage = StorageFactory::create(StorageConfig::Memory(MemoryStorageConfig::default()))?;

    // Configure default analyzer to Japanese
    let analyzer = Arc::new(JapaneseAnalyzer::default());
    let schema = Schema::builder()
        .add_lexical_field("content", FieldOption::Text(TextOption::default()))
        .build();

    Engine::builder(storage, schema)
        .analyzer(analyzer)
        .build()
}
<span class="boring">}</span></code></pre></pre>
<h2 id="future-outlook"><a class="header" href="#future-outlook">Future Outlook</a></h2>
<ul>
<li><strong>Advanced Scoring Functions</strong>: Support for BM25F and custom script-based scoring.</li>
<li><strong>Improved NRT (Near-Real-Time)</strong>: Faster segment flushing and background merging optimizations.</li>
<li><strong>Multilingual Support</strong>: Integration with more language-specific tokenizers and dictionaries.</li>
<li><strong>Tiered Storage</strong>: Support for moving older segments to slower/cheaper storage automatically.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="vector-search"><a class="header" href="#vector-search">Vector Search</a></h1>
<p>Vector search (finding "nearest neighbors") enables semantic retrieval where matches are based on meaning rather than exact keywords. Iris provides a <strong>Unified Engine</strong> that combines this semantic search with traditional lexical (keyword) search capabilities.</p>
<h2 id="document-structure-1"><a class="header" href="#document-structure-1">Document Structure</a></h2>
<p>With the unified engine, a document can contain both vector fields (for semantic search) and lexical fields (for keyword search/filtering).</p>
<pre><code class="language-mermaid">flowchart LR
    IntID1("Internal ID&lt;br&gt;1") --&gt; DocContainer1_Vec
    IntID1 --&gt; DocContainer1_Lex

    subgraph DocContainer1_Vec [Vector Document]
        direction TB
        subgraph VecField1 [Vector Field]
            direction TB
            F11["Vector Field&lt;br&gt;Name: 'image_vec'&lt;br&gt;Value: [0.12, 0.05, ...]&lt;br&gt;Type: HNSW"]
        end
        subgraph Meta1 [Metadata]
            direction TB
            F12["Metadata Field&lt;br&gt;Name: '_id'&lt;br&gt;Value: 'img_001'"]
            F13["Metadata Field&lt;br&gt;Name: '_mime_type'&lt;br&gt;Value: 'image/jpeg'"]
        end
        VecField1 --&gt; Meta1

        subgraph VecField1_2 [Vector Field]
            direction TB
            F11_2["Vector Field&lt;br&gt;Name: 'text_vec'&lt;br&gt;Value: [0.33, 0.44, ...]&lt;br&gt;Type: HNSW"]
        end
        subgraph Meta1_2 [Metadata]
            direction TB
            F12_2["Metadata Field&lt;br&gt;Name: '_id'&lt;br&gt;Value: 'img_001'"]
            F13_2["Metadata Field&lt;br&gt;Name: '_mime_type'&lt;br&gt;Value: 'text/plain'"]
        end
        VecField1_2 --&gt; Meta1_2
    end

    subgraph DocContainer1_Lex [Lexical Document]
        direction TB
        ExtID1_Lex["Lexical Field (External ID)&lt;br&gt;Name: '_id'&lt;br&gt;Value: 'img_001'&lt;br&gt;Type: Text"]
        L11["Lexical Field&lt;br&gt;Name: 'description'&lt;br&gt;Value: 'A cute cat'&lt;br&gt;Type: Text"]
        L12["Lexical Field&lt;br&gt;Name: 'like'&lt;br&gt;Value: 53&lt;br&gt;Type: Integer"]
    end

    IntID2("Internal ID&lt;br&gt;2") --&gt; DocContainer2_Vec
    IntID2 --&gt; DocContainer2_Lex

    subgraph DocContainer2_Vec [Vector Document]
        direction TB
        subgraph VecField2 [Vector Field]
            direction TB
            F21["Vector Field&lt;br&gt;Name: 'image_vec'&lt;br&gt;Value: [0.88, 0.91, ...]&lt;br&gt;Type: HNSW"]
        end
        subgraph Meta2 [Metadata]
            direction TB
            F22["Metadata Field&lt;br&gt;Name: '_id'&lt;br&gt;Value: 'img_002'"]
            F23["Metadata Field&lt;br&gt;Name: '_mime_type'&lt;br&gt;Value: 'image/jpeg'"]
        end
        VecField2 --&gt; Meta2

        subgraph VecField2_2 [Vector Field]
            direction TB
            F21_2["Vector Field&lt;br&gt;Name: 'text_vec'&lt;br&gt;Value: [0.11, 0.99, ...]&lt;br&gt;Type: HNSW"]
        end
        subgraph Meta2_2 [Metadata]
            direction TB
            F22_2["Metadata Field&lt;br&gt;Name: '_id'&lt;br&gt;Value: 'img_002'"]
            F23_2["Metadata Field&lt;br&gt;Name: '_mime_type'&lt;br&gt;Value: 'text/plain'"]
        end
        VecField2_2 --&gt; Meta2_2
    end

    subgraph DocContainer2_Lex [Lexical Document]
        direction TB
        ExtID2_Lex["Lexical Field (External ID)&lt;br&gt;Name: '_id'&lt;br&gt;Value: 'img_002'&lt;br&gt;Type: Text"]
        L21["Lexical Field&lt;br&gt;Name: 'description'&lt;br&gt;Value: 'A loyal dog'&lt;br&gt;Type: Text"]
        L22["Lexical Field&lt;br&gt;Name: 'like'&lt;br&gt;Value: 42&lt;br&gt;Type: Integer"]
    end
</code></pre>
<h3 id="vector"><a class="header" href="#vector">Vector</a></h3>
<p>A mathematical representation of an object (text, image, audio) in a multi-dimensional space.</p>
<ul>
<li><strong>Dimension</strong>: The number of elements in the vector (e.g., 384, 768, 1536).</li>
<li><strong>Normalization</strong>: Vectors can be normalized (e.g., to unit length) to optimize distance calculations.</li>
</ul>
<h3 id="vector-field-configuration"><a class="header" href="#vector-field-configuration">Vector Field Configuration</a></h3>
<p>Defines how vectors in a specific field are indexed and queried.</p>
<ul>
<li><strong>Distance Metric</strong>: The formula used to calculate "similarity" between vectors.</li>
<li><strong>Index Type</strong>: The algorithm used for storage and retrieval (HNSW, IVF, Flat).</li>
<li><strong>Quantization</strong>: Compression techniques to reduce memory usage.</li>
</ul>
<h2 id="indexing-process-1"><a class="header" href="#indexing-process-1">Indexing Process</a></h2>
<p>The vector indexing process transforms raw data or pre-computed vectors into efficient, searchable structures.</p>
<pre><code class="language-mermaid">graph TD
    subgraph "Vector Indexing Flow"
        Input["Raw Input (Text/Image)"] --&gt; Embedder["Embedding Model"]
        Embedder --&gt;|Vector| Norm["Normalization"]
        PreComp["Pre-computed Vector"] --&gt; Norm
        
        subgraph "VectorEngine"
            Norm --&gt; Quant["Quantizer (PQ/SQ)"]
            Quant --&gt;|Quantized| Buffer["In-memory Buffer"]
            Norm --&gt;|Raw| Buffer
            
            subgraph "Index Building"
                Buffer --&gt;|HNSW| GraphBuilder["Graph Builder"]
                Buffer --&gt;|IVF| Clustering["K-Means Clustering"]
                Buffer --&gt;|Flat| ArrayBuilder["Linear Array Builder"]
            end
        end
        
        subgraph "Segment Flushing"
            GraphBuilder --&gt;|Write| HNSWFiles[".hnsw / .vecs"]
            Clustering --&gt;|Write| IVFFiles[".ivf / .vecs"]
            ArrayBuilder --&gt;|Write| FlatFiles[".vecs"]
            Quant -.-&gt;|Codebook| QMeta[".quant"]
        end
    end
</code></pre>
<ol>
<li><strong>Vector Acquisition</strong>: Vectors are either provided directly or generated from text/images using an <code>Embedder</code>.</li>
<li><strong>Processing</strong>:
<ul>
<li><strong>Normalization</strong>: Adjusting vectors to a consistent scale (e.g., unit norm for Cosine similarity).</li>
<li><strong>Quantization</strong>: Optional compression (e.g., Product Quantization) to reduce the memory footprint.</li>
</ul>
</li>
<li><strong>Index Construction</strong>:
<ul>
<li><strong>HNSW</strong>: Builds a hierarchical graph structure for sub-linear search time.</li>
<li><strong>IVF</strong>: Clusters vectors into partitions to restrict the search space.</li>
</ul>
</li>
<li><strong>Segment Flushing</strong>: Serializes the in-memory structures into immutable files on disk.</li>
</ol>
<h2 id="core-concepts-2"><a class="header" href="#core-concepts-2">Core Concepts</a></h2>
<h3 id="approximate-nearest-neighbor-ann"><a class="header" href="#approximate-nearest-neighbor-ann">Approximate Nearest Neighbor (ANN)</a></h3>
<p>In large-scale vector search, calculating exact distances to every vector is too slow. ANN algorithms provide a high-speed search with a small, controllable loss in accuracy (Recall).</p>
<h3 id="index-types"><a class="header" href="#index-types">Index Types</a></h3>
<h4 id="flat-index-exact-search"><a class="header" href="#flat-index-exact-search">Flat Index (Exact Search)</a></h4>
<p>Stores all vectors directly in an array and calculates distances between the query and every vector during search.</p>
<ul>
<li><strong>Implementation</strong>: <code>FlatIndexWriter</code>, <code>FlatVectorIndexReader</code></li>
<li><strong>Characteristics</strong>: 100% precision (Exact Search), but search speed decreases linearly with data volume.</li>
<li><strong>Use Cases</strong>: Small datasets or as a baseline for ANN precision.</li>
</ul>
<h4 id="hnsw-hierarchical-navigable-small-world"><a class="header" href="#hnsw-hierarchical-navigable-small-world">HNSW (Hierarchical Navigable Small World)</a></h4>
<p>Iris's primary ANN algorithm. It constructs a multi-layered graph where the top layers are sparse (long-distance "express" links) and bottom layers are dense (short-distance local links).</p>
<ul>
<li><strong>Efficiency</strong>: Search time is logarithmic $O(\log N)$.</li>
<li><strong>Implementation</strong>: <code>HnswIndexWriter</code>, <code>HnswIndexReader</code></li>
<li><strong>Parameters</strong>: <code>m</code> (links per node) and <code>ef_construction</code> control the trade-off between index quality and build speed.</li>
</ul>
<h4 id="ivf-inverted-file-index"><a class="header" href="#ivf-inverted-file-index">IVF (Inverted File Index)</a></h4>
<p>Clusters vectors into $K$ Voronoi cells. During search, only the nearest <code>n_probe</code> cells are scanned.</p>
<ul>
<li><strong>Centroids</strong>: Calculated during a <code>Training</code> phase using K-Means.</li>
<li><strong>Implementation</strong>: <code>IvfIndexWriter</code>, <code>IvfIndexReader</code></li>
<li><strong>Use Case</strong>: Efficient for extremely large datasets where HNSW memory overhead becomes prohibitive. Works best when combined with PQ quantization.</li>
</ul>
<h3 id="distance-metrics"><a class="header" href="#distance-metrics">Distance Metrics</a></h3>
<p>Iris leverages Rust's SIMD (Single Instruction Multiple Data) instructions to maximize performance for distance calculations.</p>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Metric</th><th style="text-align: left">Description</th><th style="text-align: left">Rust Implementation Class</th><th style="text-align: left">Features</th></tr></thead><tbody>
<tr><td style="text-align: left"><strong>Cosine</strong></td><td style="text-align: left">Measures the angle between vectors.</td><td style="text-align: left"><code>DistanceMetric::Cosine</code></td><td style="text-align: left">Ideal for semantic text similarity.</td></tr>
<tr><td style="text-align: left"><strong>Euclidean</strong></td><td style="text-align: left">Measures straight-line distance.</td><td style="text-align: left"><code>DistanceMetric::Euclidean</code></td><td style="text-align: left">Suitable for image retrieval and physical proximity.</td></tr>
<tr><td style="text-align: left"><strong>DotProduct</strong></td><td style="text-align: left">Calculates the dot product.</td><td style="text-align: left"><code>DistanceMetric::DotProduct</code></td><td style="text-align: left">Extremely fast for pre-normalized vectors.</td></tr>
</tbody></table>
</div>
<h3 id="quantization"><a class="header" href="#quantization">Quantization</a></h3>
<p>To reduce memory usage and improve search speed, Iris supports several quantization methods:</p>
<ul>
<li><strong>Scalar 8-bit (SQ8)</strong>: Maps 32-bit floating-points to 8-bit integers (4x compression).</li>
<li><strong>Product Quantization (PQ)</strong>: Decomposes vectors into sub-vectors and performs clustering (16x-64x compression).</li>
</ul>
<h2 id="engine-architecture-1"><a class="header" href="#engine-architecture-1">Engine Architecture</a></h2>
<h3 id="vectorstore"><a class="header" href="#vectorstore">VectorStore</a></h3>
<p>The store component that manages vector indexing and searching. It follows a simplified 4-member structure:</p>
<ul>
<li><strong>index</strong>: The underlying vector index (HNSW, IVF, or Flat)</li>
<li><strong>writer_cache</strong>: Cached writer for write operations</li>
<li><strong>searcher_cache</strong>: Cached searcher for search operations</li>
<li><strong>doc_store</strong>: Shared document storage</li>
</ul>
<h3 id="index-components-1"><a class="header" href="#index-components-1">Index Components</a></h3>
<ul>
<li><strong>VectorIndex</strong>: Trait for vector index implementations (HnswIndex, IvfIndex, FlatIndex).</li>
<li><strong>VectorIndexWriter</strong>: Handles vector insertion and embedding.</li>
<li><strong>VectorIndexSearcher</strong>: Performs nearest neighbor search.</li>
<li><strong>EmbeddingVectorIndexWriter</strong>: Wrapper that automatically embeds text/images before indexing.</li>
</ul>
<h2 id="index-segment-files-1"><a class="header" href="#index-segment-files-1">Index Segment Files</a></h2>
<p>A vector segment consists of several specialized files:</p>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Extension</th><th style="text-align: left">Component</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>.hnsw</code></td><td style="text-align: left">HNSW Graph</td><td style="text-align: left">Adjacency lists for hierarchical navigation.</td></tr>
<tr><td style="text-align: left"><code>.vecs</code></td><td style="text-align: left">Raw Vectors</td><td style="text-align: left">Stored raw floating-point vectors (f32).</td></tr>
<tr><td style="text-align: left"><code>.quant</code></td><td style="text-align: left">Codebook</td><td style="text-align: left">Trained centroids and parameters for quantization.</td></tr>
<tr><td style="text-align: left"><code>.idx</code></td><td style="text-align: left">Quantized IDs</td><td style="text-align: left">Compressed vector representations.</td></tr>
<tr><td style="text-align: left"><code>.meta</code></td><td style="text-align: left">Metadata</td><td style="text-align: left">Segment statistics, dimension, and configuration.</td></tr>
</tbody></table>
</div>
<h2 id="search-process-1"><a class="header" href="#search-process-1">Search Process</a></h2>
<p>Finding the nearest neighbors involves navigating the index structure to minimize distance calculations.</p>
<pre><code class="language-mermaid">graph TD
    subgraph "Vector Search Flow"
        Query["Query Vector"] --&gt; Quant["Quantization (Encoding)"]
        
        subgraph "Segment Search"
            Quant --&gt;|HNSW| HNSWNav["Graph Navigation"]
            Quant --&gt;|IVF| CentroidScan["Nearest Centroid Probe"]
            
            HNSWNav --&gt;|Top-K| ResBuffer["Candidate Buffer"]
            CentroidScan --&gt;|Top-K| ResBuffer
        end
        
        ResBuffer --&gt;|Re-ranking| Refine["Precision Scoring (Raw Vectors)"]
        Refine --&gt; Final["Sorted Hits"]
    end
</code></pre>
<ol>
<li><strong>Preparation</strong>: The query vector is normalized and/or quantized to match the index format.</li>
<li><strong>Navigation</strong>:
<ul>
<li>In <strong>HNSW</strong>, the search starts at the top layer and descends toward the target vector through graph neighbors.</li>
<li>In <strong>IVF</strong>, the nearest cluster centroids are identified, and search is restricted to those cells.</li>
</ul>
</li>
<li><strong>Refinement</strong>: (Optional) If quantization was used, raw vectors may be accessed to re-rank the top candidates for higher precision.</li>
</ol>
<h2 id="query-types-2"><a class="header" href="#query-types-2">Query Types</a></h2>
<h3 id="k-nn-search-k-nearest-neighbors"><a class="header" href="#k-nn-search-k-nearest-neighbors">K-NN Search (K-Nearest Neighbors)</a></h3>
<p>The basic vector search query.</p>
<ul>
<li><strong>Parameters</strong>: <code>K</code> (the number of neighbors to return).</li>
<li><strong>Recall vs. Speed</strong>: Adjusted via search parameters like <code>ef_search</code> for HNSW.</li>
</ul>
<h3 id="filtered-vector-search"><a class="header" href="#filtered-vector-search">Filtered Vector Search</a></h3>
<p>Combines vector search with boolean filters. Iris supports pre-filtering using metadata filters (backed by LexicalEngine) to restrict the search space to documents matching specific metadata criteria.</p>
<h3 id="hybrid-search"><a class="header" href="#hybrid-search">Hybrid Search</a></h3>
<p>Leverages both Lexical and Vector engines simultaneously. Results are combined using algorithms like <strong>Reciprocal Rank Fusion (RRF)</strong> to produce a single, high-quality ranked list.</p>
<h4 id="fusion-strategies"><a class="header" href="#fusion-strategies">Fusion Strategies</a></h4>
<p>Results from the vector and lexical searches are combined using fusion strategies.</p>
<ol>
<li>
<p><strong>Weighted Sum</strong>: Scores are normalized and combined using linear weights.
<code>FinalScore = (LexicalScore * alpha) + (VectorScore * beta)</code></p>
</li>
<li>
<p><strong>RRF (Reciprocal Rank Fusion)</strong>: Calculates scores based on rank position, robust to different score distributions.
<code>Score = Σ_i (1 / (k + rank_i))</code></p>
</li>
</ol>
<h2 id="search-process-for-hybrid-queries"><a class="header" href="#search-process-for-hybrid-queries">Search Process for Hybrid Queries</a></h2>
<pre><code class="language-mermaid">graph TD
    Query["SearchRequest"] --&gt; Engine["Engine"]
    Engine --&gt;|Lexical Query| LexSearch["LexicalStore"]
    Engine --&gt;|Vector Query| VecSearch["VectorStore"]

    LexSearch --&gt; LexHits["Lexical Hits"]
    VecSearch --&gt; VecHits["Vector Hits"]

    LexHits --&gt; Fusion["Result Fusion"]
    VecHits --&gt; Fusion

    Fusion --&gt; Combine["Score Combination"]
    Combine --&gt; TopDocs["Final Top Results"]
</code></pre>
<h2 id="code-examples-1"><a class="header" href="#code-examples-1">Code Examples</a></h2>
<h3 id="1-configuring-engine-for-vector-search"><a class="header" href="#1-configuring-engine-for-vector-search">1. Configuring Engine for Vector Search</a></h3>
<p>Example of creating an engine with an embedder and vector field configurations.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use std::sync::Arc;
use iris::{Engine, Schema};
use iris::vector::{FlatOption, HnswOption, VectorOption, DistanceMetric};
use iris::storage::{StorageConfig, StorageFactory};
use iris::storage::memory::MemoryStorageConfig;

fn setup_engine() -&gt; iris::Result&lt;Engine&gt; {
    let storage = StorageFactory::create(StorageConfig::Memory(MemoryStorageConfig::default()))?;

    let schema = Schema::builder()
        .add_vector_field(
            "embedding",
            VectorOption::Hnsw(HnswOption {
                dimension: 384,
                distance: DistanceMetric::Cosine,
                m: 16,
                ef_construction: 200,
                ..Default::default()
            }),
        )
        .build();

    Engine::builder(storage, schema)
        .embedder(Arc::new(MyEmbedder))  // Your embedder implementation
        .build()
}
<span class="boring">}</span></code></pre></pre>
<h3 id="2-adding-documents-1"><a class="header" href="#2-adding-documents-1">2. Adding Documents</a></h3>
<p>Example of indexing a document with text that gets automatically embedded.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use iris::{Document, DataValue};

fn add_document(engine: &amp;Engine) -&gt; iris::Result&lt;()&gt; {
    // Text is automatically embedded by the configured embedder
    let doc = Document::new()
        .add_text("embedding", "Fast semantic search in Rust")
        .add_field("category", DataValue::Text("technology".into()));

    engine.put_document("doc_001", doc)?;
    engine.commit()?;

    Ok(())
}
<span class="boring">}</span></code></pre></pre>
<h3 id="3-executing-vector-search"><a class="header" href="#3-executing-vector-search">3. Executing Vector Search</a></h3>
<p>Example of performing a search using <code>VectorSearchRequestBuilder</code>.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use iris::SearchRequestBuilder;
use iris::vector::VectorSearchRequestBuilder;

fn search(engine: &amp;Engine) -&gt; iris::Result&lt;()&gt; {
    let results = engine.search(
        SearchRequestBuilder::new()
            .with_vector(
                VectorSearchRequestBuilder::new()
                    .add_text("embedding", "semantic search")
                    .build()
            )
            .limit(10)
            .build()
    )?;

    for hit in results {
        println!("[{}] Score: {:.4}", hit.id, hit.score);
    }

    Ok(())
}
<span class="boring">}</span></code></pre></pre>
<h3 id="4-hybrid-search"><a class="header" href="#4-hybrid-search">4. Hybrid Search</a></h3>
<p>Example of combining vector and keyword search. Note that vector and lexical searches use separate fields.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use iris::{FusionAlgorithm, SearchRequestBuilder};
use iris::lexical::TermQuery;
use iris::vector::VectorSearchRequestBuilder;

fn hybrid_search(engine: &amp;Engine) -&gt; iris::Result&lt;()&gt; {
    let results = engine.search(
        SearchRequestBuilder::new()
            // Vector search (semantic) on vector field
            .with_vector(
                VectorSearchRequestBuilder::new()
                    .add_text("content_vec", "fast semantic search")
                    .build()
            )
            // Lexical search (keyword) on lexical field
            .with_lexical(Box::new(TermQuery::new("content", "rust")))
            // Fusion strategy
            .fusion(FusionAlgorithm::RRF { k: 60.0 })
            .limit(10)
            .build()
    )?;

    for hit in results {
        println!("[{}] score={:.4}", hit.id, hit.score);
    }

    Ok(())
}
<span class="boring">}</span></code></pre></pre>
<h3 id="5-weighted-sum-fusion"><a class="header" href="#5-weighted-sum-fusion">5. Weighted Sum Fusion</a></h3>
<p>Example using weighted sum fusion for fine-grained control.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn weighted_hybrid_search(engine: &amp;Engine) -&gt; iris::Result&lt;()&gt; {
    let results = engine.search(
        SearchRequestBuilder::new()
            .with_vector(
                VectorSearchRequestBuilder::new()
                    .add_text("content_vec", "machine learning")
                    .build()
            )
            .with_lexical(Box::new(TermQuery::new("content", "python")))
            .fusion(FusionAlgorithm::WeightedSum {
                vector_weight: 0.7,  // 70% semantic
                lexical_weight: 0.3, // 30% keyword
            })
            .limit(10)
            .build()
    )?;

    Ok(())
}
<span class="boring">}</span></code></pre></pre>
<h2 id="future-outlook-1"><a class="header" href="#future-outlook-1">Future Outlook</a></h2>
<ul>
<li><strong>Full Implementation of Product Quantization (PQ)</strong>: Optimizing PQ clustering, currently a placeholder.</li>
<li><strong>GPU Acceleration</strong>: Offloading distance calculations to GPUs, in addition to model inference.</li>
<li><strong>Disk-ANN Support</strong>: Mechanisms to efficiently search large indexes stored on SSDs when they exceed memory capacity.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><div style="break-before: page; page-break-before: always;"></div><h1 id="query-dsl"><a class="header" href="#query-dsl">Query DSL</a></h1>
<p>Iris provides a unified query DSL (Domain Specific Language) that allows lexical (keyword) and vector (semantic) search in a single query string. The <code>UnifiedQueryParser</code> splits the input into lexical and vector portions and delegates to the appropriate sub-parser.</p>
<h2 id="overview"><a class="header" href="#overview">Overview</a></h2>
<pre><code>title:hello AND content:~"cute kitten"^0.8
|--- lexical --|    |--- vector --------|
</code></pre>
<p>The <code>~"</code> pattern distinguishes vector clauses from lexical clauses. Everything else is treated as a lexical query.</p>
<h2 id="lexical-query-syntax"><a class="header" href="#lexical-query-syntax">Lexical Query Syntax</a></h2>
<p>Lexical queries search the inverted index using exact or approximate keyword matching.</p>
<h3 id="term-query"><a class="header" href="#term-query">Term Query</a></h3>
<p>Match a single term against a field (or the default field):</p>
<pre><code>hello
title:hello
</code></pre>
<h3 id="boolean-operators"><a class="header" href="#boolean-operators">Boolean Operators</a></h3>
<p>Combine clauses with <code>AND</code> and <code>OR</code> (case-insensitive):</p>
<pre><code>title:hello AND body:world
title:hello OR title:goodbye
</code></pre>
<p>Space-separated clauses without an explicit operator use implicit boolean (behaves like OR with scoring).</p>
<h3 id="required--prohibited-clauses"><a class="header" href="#required--prohibited-clauses">Required / Prohibited Clauses</a></h3>
<p>Use <code>+</code> (must match) and <code>-</code> (must not match):</p>
<pre><code>+title:hello -title:goodbye
</code></pre>
<h3 id="phrase-query"><a class="header" href="#phrase-query">Phrase Query</a></h3>
<p>Match an exact phrase using double quotes. Optional proximity (<code>~N</code>) allows N words between terms:</p>
<pre><code>"hello world"
"hello world"~2
</code></pre>
<h3 id="fuzzy-query"><a class="header" href="#fuzzy-query">Fuzzy Query</a></h3>
<p>Approximate matching with edit distance. Append <code>~</code> and optionally the maximum edit distance:</p>
<pre><code>roam~
roam~2
</code></pre>
<h3 id="wildcard-query"><a class="header" href="#wildcard-query">Wildcard Query</a></h3>
<p>Use <code>?</code> (single character) and <code>*</code> (zero or more characters):</p>
<pre><code>te?t
test*
</code></pre>
<h3 id="range-query"><a class="header" href="#range-query">Range Query</a></h3>
<p>Inclusive <code>[]</code> or exclusive <code>{}</code> ranges, useful for numeric and date fields:</p>
<pre><code>price:[100 TO 500]
date:{2024-01-01 TO 2024-12-31}
price:[* TO 100]
</code></pre>
<h3 id="boost"><a class="header" href="#boost">Boost</a></h3>
<p>Increase the weight of a clause with <code>^</code>:</p>
<pre><code>title:hello^2
"important phrase"^1.5
</code></pre>
<h3 id="grouping"><a class="header" href="#grouping">Grouping</a></h3>
<p>Use parentheses for sub-expressions:</p>
<pre><code>(title:hello OR title:hi) AND body:world
</code></pre>
<h3 id="peg-grammar"><a class="header" href="#peg-grammar">PEG Grammar</a></h3>
<p>The full lexical grammar (<a href="https://github.com/mosuka/iris/blob/main/src/lexical/query/parser.pest">parser.pest</a>):</p>
<pre><code class="language-pest">query          = { SOI ~ boolean_query ~ EOI }
boolean_query  = { clause ~ (boolean_op ~ clause | clause)* }
clause         = { required_clause | prohibited_clause | sub_clause }
required_clause   = { "+" ~ sub_clause }
prohibited_clause = { "-" ~ sub_clause }
sub_clause     = { grouped_query | field_query | term_query }
grouped_query  = { "(" ~ boolean_query ~ ")" ~ boost? }
boolean_op     = { ^"AND" | ^"OR" }
field_query    = { field ~ ":" ~ field_value }
field_value    = { range_query | phrase_query | fuzzy_term
                 | wildcard_term | simple_term }
phrase_query   = { "\"" ~ phrase_content ~ "\"" ~ proximity? ~ boost? }
proximity      = { "~" ~ number }
fuzzy_term     = { term ~ "~" ~ fuzziness? ~ boost? }
wildcard_term  = { wildcard_pattern ~ boost? }
simple_term    = { term ~ boost? }
boost          = { "^" ~ boost_value }
</code></pre>
<h2 id="vector-query-syntax"><a class="header" href="#vector-query-syntax">Vector Query Syntax</a></h2>
<p>Vector queries embed text into vectors at parse time and perform similarity search.</p>
<h3 id="basic-syntax"><a class="header" href="#basic-syntax">Basic Syntax</a></h3>
<pre><code>field:~"text"
field:~"text"^weight
</code></pre>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Element</th><th style="text-align: center">Required</th><th style="text-align: left">Description</th><th style="text-align: left">Example</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>field:</code></td><td style="text-align: center">No</td><td style="text-align: left">Target vector field name</td><td style="text-align: left"><code>content:</code></td></tr>
<tr><td style="text-align: left"><code>~</code></td><td style="text-align: center"><strong>Yes</strong></td><td style="text-align: left">Vector query marker</td><td style="text-align: left"></td></tr>
<tr><td style="text-align: left"><code>"text"</code></td><td style="text-align: center"><strong>Yes</strong></td><td style="text-align: left">Text to embed</td><td style="text-align: left"><code>"cute kitten"</code></td></tr>
<tr><td style="text-align: left"><code>^weight</code></td><td style="text-align: center">No</td><td style="text-align: left">Score weight (default: 1.0)</td><td style="text-align: left"><code>^0.8</code></td></tr>
</tbody></table>
</div>
<h3 id="examples-1"><a class="header" href="#examples-1">Examples</a></h3>
<pre><code># Single field
content:~"cute kitten"

# With boost weight
content:~"cute kitten"^0.8

# Default field (when configured)
~"cute kitten"

# Multiple clauses
content:~"cats" image:~"dogs"^0.5

# Nested field name (dot notation)
metadata.embedding:~"text"
</code></pre>
<h3 id="multiple-clauses"><a class="header" href="#multiple-clauses">Multiple Clauses</a></h3>
<p>Multiple vector clauses are space-separated. All clauses are executed and their scores are combined using the <code>score_mode</code> (default: <code>WeightedSum</code>):</p>
<pre><code>content:~"cats" image:~"dogs"^0.5
</code></pre>
<p>This produces:</p>
<pre><code>score = similarity("cats", content) * 1.0
      + similarity("dogs", image)   * 0.5
</code></pre>
<p>There are no <code>AND</code>/<code>OR</code> operators in the vector DSL. Vector search is inherently a ranking operation, and the weight (<code>^</code>) controls the contribution of each clause.</p>
<h3 id="score-modes"><a class="header" href="#score-modes">Score Modes</a></h3>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Mode</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>WeightedSum</code> (default)</td><td style="text-align: left">Sum of (similarity * weight) across all clauses</td></tr>
<tr><td style="text-align: left"><code>MaxSim</code></td><td style="text-align: left">Maximum similarity score across clauses</td></tr>
<tr><td style="text-align: left"><code>LateInteraction</code></td><td style="text-align: left">Late interaction scoring</td></tr>
</tbody></table>
</div>
<p>Score mode cannot be set from DSL syntax. Use the Rust API to override:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let mut request = parser.parse(r#"content:~"cats" image:~"dogs""#).await?;
request.score_mode = VectorScoreMode::MaxSim;
<span class="boring">}</span></code></pre></pre>
<h3 id="peg-grammar-1"><a class="header" href="#peg-grammar-1">PEG Grammar</a></h3>
<p>The full vector grammar (<a href="https://github.com/mosuka/iris/blob/main/src/vector/query/parser.pest">parser.pest</a>):</p>
<pre><code class="language-pest">query          = { SOI ~ vector_clause+ ~ EOI }
vector_clause  = { field_prefix? ~ "~" ~ quoted_text ~ boost? }
field_prefix   = { field_name ~ ":" }
field_name     = @{ (ASCII_ALPHA | "_") ~ (ASCII_ALPHANUMERIC | "_" | ".")* }
quoted_text    = ${ "\"" ~ inner_text ~ "\"" }
inner_text     = @{ (!("\"") ~ ANY)* }
boost          = { "^" ~ float_value }
float_value    = @{ ASCII_DIGIT+ ~ ("." ~ ASCII_DIGIT+)? }
</code></pre>
<h2 id="unified-hybrid-query-syntax"><a class="header" href="#unified-hybrid-query-syntax">Unified (Hybrid) Query Syntax</a></h2>
<p>The <code>UnifiedQueryParser</code> allows mixing lexical and vector clauses freely in a single query string:</p>
<pre><code>title:hello content:~"cute kitten"^0.8
</code></pre>
<h3 id="how-it-works"><a class="header" href="#how-it-works">How It Works</a></h3>
<ol>
<li><strong>Split</strong>: Vector clauses (matching <code>field:~"text"^boost</code> pattern) are extracted via regex.</li>
<li><strong>Delegate</strong>: Vector portion goes to <code>VectorQueryParser</code>, remainder goes to lexical <code>QueryParser</code>.</li>
<li><strong>Fuse</strong>: If both lexical and vector results exist, they are combined using a fusion algorithm.</li>
</ol>
<h3 id="disambiguation"><a class="header" href="#disambiguation">Disambiguation</a></h3>
<p>The <code>~"</code> pattern unambiguously identifies vector clauses because in lexical syntax, <code>~</code> only appears <em>after</em> a term or phrase (e.g., <code>roam~2</code>, <code>"hello world"~10</code>), never before a quote.</p>
<h3 id="fusion-algorithms"><a class="header" href="#fusion-algorithms">Fusion Algorithms</a></h3>
<p>When a query contains both lexical and vector clauses, results are fused:</p>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Algorithm</th><th style="text-align: left">Formula</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><strong>RRF</strong> (default)</td><td style="text-align: left"><code>score = sum(1 / (k + rank))</code></td><td style="text-align: left">Reciprocal Rank Fusion. Robust to different score distributions. Default k=60.</td></tr>
<tr><td style="text-align: left"><strong>WeightedSum</strong></td><td style="text-align: left"><code>score = lexical * a + vector * b</code></td><td style="text-align: left">Linear combination with configurable weights.</td></tr>
</tbody></table>
</div>
<h3 id="examples-2"><a class="header" href="#examples-2">Examples</a></h3>
<pre><code># Lexical only — no fusion
title:hello AND body:world

# Vector only — no fusion
content:~"cute kitten"

# Hybrid — RRF fusion (default)
title:hello content:~"cute kitten"

# Hybrid with boolean operators
title:hello AND category:animal content:~"cute kitten"^0.8

# Multiple vector clauses + lexical
category:animal content:~"cats" image:~"dogs"^0.5

# Default fields (when configured)
hello ~"cats"
</code></pre>
<h2 id="code-examples-2"><a class="header" href="#code-examples-2">Code Examples</a></h2>
<h3 id="lexical-search-with-dsl"><a class="header" href="#lexical-search-with-dsl">Lexical Search with DSL</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use std::sync::Arc;
use iris::analysis::analyzer::standard::StandardAnalyzer;
use iris::lexical::query::QueryParser;

let analyzer = Arc::new(StandardAnalyzer::new()?);
let parser = QueryParser::new(analyzer)
    .with_default_field("title");

let query = parser.parse("title:hello AND body:world")?;
<span class="boring">}</span></code></pre></pre>
<h3 id="vector-search-with-dsl"><a class="header" href="#vector-search-with-dsl">Vector Search with DSL</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use std::sync::Arc;
use iris::vector::query::VectorQueryParser;

let parser = VectorQueryParser::new(embedder)
    .with_default_field("content");

let request = parser.parse(r#"content:~"cute kitten"^0.8"#).await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="hybrid-search-with-unified-dsl"><a class="header" href="#hybrid-search-with-unified-dsl">Hybrid Search with Unified DSL</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use iris::engine::query::UnifiedQueryParser;

let unified = UnifiedQueryParser::new(lexical_parser, vector_parser);

let request = unified.parse(
    r#"title:hello content:~"cute kitten"^0.8"#
).await?;
// request.lexical  -&gt; Some(...)  — lexical query
// request.vector   -&gt; Some(...)  — vector query
// request.fusion   -&gt; Some(RRF)  — fusion algorithm
<span class="boring">}</span></code></pre></pre>
<h3 id="custom-fusion"><a class="header" href="#custom-fusion">Custom Fusion</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use iris::engine::search::FusionAlgorithm;

let unified = UnifiedQueryParser::new(lexical_parser, vector_parser)
    .with_fusion(FusionAlgorithm::WeightedSum {
        lexical_weight: 0.3,
        vector_weight: 0.7,
    });
<span class="boring">}</span></code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="id-management"><a class="header" href="#id-management">ID Management</a></h1>
<p>Iris uses a dual-tiered ID management strategy to ensure efficient document retrieval, updates, and aggregation in distributed environments.</p>
<h2 id="1-external-id-string"><a class="header" href="#1-external-id-string">1. External ID (String)</a></h2>
<p>The External ID is a <strong>logical identifier</strong> used by users and applications to uniquely identify a document.</p>
<ul>
<li><strong>Type</strong>: <code>String</code></li>
<li><strong>Role</strong>: You can use any unique value, such as UUIDs, URLs, or database primary keys.</li>
<li><strong>Storage</strong>: Persisted transparently as a reserved system field name <code>_id</code> within the Lexical Index.</li>
<li><strong>Uniqueness</strong>: Expected to be unique across the entire system.</li>
<li><strong>Updates</strong>: Indexing a document with an existing <code>external_id</code> triggers an automatic "Delete-then-Insert" (Upsert) operation, replacing the old version with the newest.</li>
</ul>
<h2 id="2-internal-id-u64--stable-id"><a class="header" href="#2-internal-id-u64--stable-id">2. Internal ID (u64 / Stable ID)</a></h2>
<p>The Internal ID is a <strong>physical handle</strong> used internally by Iris's engines (Lexical and Vector) for high-performance operations.</p>
<ul>
<li><strong>Type</strong>: Unsigned 64-bit Integer (<code>u64</code>)</li>
<li><strong>Role</strong>: Used for bitmap operations, point references, and routing between distributed nodes.</li>
<li><strong>Immutability (Stable)</strong>: Once assigned, an Internal ID never changes due to index merges (segment compaction) or restarts. This prevents inconsistencies in deletion logs and caches.</li>
</ul>
<h3 id="id-structure-shard-prefixed"><a class="header" href="#id-structure-shard-prefixed">ID Structure (Shard-Prefixed)</a></h3>
<p>Iris employs a <strong>Shard-Prefixed Stable ID</strong> scheme designed for multi-node distributed environments.</p>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Bit Range</th><th style="text-align: left">Name</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><strong>48-63 bit</strong></td><td style="text-align: left"><strong>Shard ID</strong></td><td style="text-align: left">Prefix identifying the node or partition (up to 65,535 shards).</td></tr>
<tr><td style="text-align: left"><strong>0-47 bit</strong></td><td style="text-align: left"><strong>Local ID</strong></td><td style="text-align: left">Monotonically increasing document number within a shard (up to ~281 trillion documents).</td></tr>
</tbody></table>
</div>
<h4 id="why-this-structure"><a class="header" href="#why-this-structure">Why this structure?</a></h4>
<ol>
<li><strong>Zero-Cost Aggregation</strong>: Since <code>u64</code> IDs are globally unique, the aggregator can perform fast sorting and deduplication without worrying about ID collisions between nodes.</li>
<li><strong>Fast Routing</strong>: The aggregator can immediately identify the physical node responsible for a document just by looking at the upper bits, avoiding expensive hash lookups.</li>
<li><strong>High-Performance Fetching</strong>: Internal IDs map directly to physical data structures. This allows Iris to skip the "External-to-Internal ID" conversion step during retrieval, achieving <strong>O(1)</strong> access speed.</li>
</ol>
<h2 id="id-lifecycle"><a class="header" href="#id-lifecycle">ID Lifecycle</a></h2>
<ol>
<li><strong>Registration (<code>engine.index()</code>)</strong>: User provides a document with an External ID.</li>
<li><strong>ID Assignment</strong>: The <code>Engine</code> combines the current <code>shard_id</code> with a new Local ID to issue a Shard-Prefixed Internal ID.</li>
<li><strong>Mapping</strong>: The engine maintains the relationship between the External ID and the new Internal ID.</li>
<li><strong>Search</strong>: Search results return the <code>u64</code> Internal ID for efficiency.</li>
<li><strong>Retrieval/Deletion</strong>: While the user-facing API accepts External IDs for convenience, the engine internally converts them to Internal IDs for near-instant processing.</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="persistence--wal"><a class="header" href="#persistence--wal">Persistence &amp; WAL</a></h1>
<p>To ensure data durability and fast recovery, Iris implements a <strong>Write-Ahead Log (WAL)</strong> system.</p>
<h2 id="write-ahead-log-wal"><a class="header" href="#write-ahead-log-wal">Write-Ahead Log (WAL)</a></h2>
<ul>
<li>All incoming write operations (Add, Delete) are immediately appended to a disk-based log file.</li>
<li>This happens <strong>before</strong> memory structures (like HNSW graph or Inverted Index) are updated.</li>
<li>In case of a crash, Iris replays the WAL on startup to restore the in-memory state.</li>
</ul>
<h2 id="segments"><a class="header" href="#segments">Segments</a></h2>
<p>Indexes can be split into segments (though currently, the implementation focuses on a global segment model with potential for expansion).</p>
<ul>
<li>Larger indexes are safer to manage as smaller, immutable segments that are periodically merged.</li>
</ul>
<h2 id="checkpointing"><a class="header" href="#checkpointing">Checkpointing</a></h2>
<p>Currently, explicit commits flush the in-memory state to durable index files.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>engine.commit()?;  // Flush and persist all changes
<span class="boring">}</span></code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="deletions--compaction"><a class="header" href="#deletions--compaction">Deletions &amp; Compaction</a></h1>
<h2 id="logical-deletion"><a class="header" href="#logical-deletion">Logical Deletion</a></h2>
<p>When a document is deleted:</p>
<ol>
<li>It is <strong>not</strong> immediately removed from the physical files.</li>
<li>Its ID is added to a <strong>Deletion Bitmap</strong>.</li>
<li>Subsequent searches check this bitmap and filter out deleted IDs from results.</li>
<li>This operation is fast O(1).</li>
</ol>
<h2 id="physical-deletion-compaction"><a class="header" href="#physical-deletion-compaction">Physical Deletion (Compaction)</a></h2>
<p>Over time, deleted documents accumulate and waste space.</p>
<ul>
<li><strong>Compaction (Vacuuming)</strong> is the process of rewriting the index files to exclude logically deleted data.</li>
<li>It rebuilds the HNSW graph or Inverted Index segments without the deleted entries.</li>
<li>This is an expensive operation and should be run periodically (e.g., nightly).</li>
</ul>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Example of triggering manual compaction
engine.optimize()?;
<span class="boring">}</span></code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="api-reference"><a class="header" href="#api-reference">API Reference</a></h1>
<p>For detailed API documentation, please refer to the auto-generated Rustdocs.</p>
<p>You can generate them locally by running:</p>
<pre><code class="language-bash">cargo doc --open
</code></pre>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->
        <script src="mermaid.min.js"></script>
        <script src="mermaid-init.js"></script>

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>


    </div>
    </body>
</html>
