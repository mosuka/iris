<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Laurus Documentation</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="highlight-css" href="highlight.css">
        <link rel="stylesheet" id="tomorrow-night-css" href="tomorrow-night.css">
        <link rel="stylesheet" id="ayu-highlight-css" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "";
            const default_light_theme = "light";
            const default_dark_theme = "navy";
            window.path_to_searchindex_js = "searchindex.js";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>←</kbd> or <kbd>→</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Laurus Documentation</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/mosuka/laurus" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <div class="search-wrapper">
                            <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                            <div class="spinner-wrapper">
                                <i class="fa fa-spinner fa-spin"></i>
                            </div>
                        </div>
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="laurus"><a class="header" href="#laurus">Laurus</a></h1>
<p><strong>A fast, featureful hybrid search library for Rust.</strong></p>
<p>Laurus is a pure-Rust library that combines <strong>lexical search</strong> (keyword matching via inverted index) and <strong>vector search</strong> (semantic similarity via embeddings) into a single, unified engine. It is designed to be embedded directly into your Rust application — no external server required.</p>
<h2 id="key-features"><a class="header" href="#key-features">Key Features</a></h2>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Feature</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><strong>Lexical Search</strong></td><td style="text-align: left">Full-text search powered by an inverted index with BM25 scoring</td></tr>
<tr><td style="text-align: left"><strong>Vector Search</strong></td><td style="text-align: left">Approximate nearest neighbor (ANN) search using Flat, HNSW, or IVF indexes</td></tr>
<tr><td style="text-align: left"><strong>Hybrid Search</strong></td><td style="text-align: left">Combine lexical and vector results with fusion algorithms (RRF, WeightedSum)</td></tr>
<tr><td style="text-align: left"><strong>Text Analysis</strong></td><td style="text-align: left">Pluggable analyzer pipeline — tokenizers, filters, stemmers, synonyms</td></tr>
<tr><td style="text-align: left"><strong>Embeddings</strong></td><td style="text-align: left">Built-in support for Candle (local BERT/CLIP), OpenAI API, or custom embedders</td></tr>
<tr><td style="text-align: left"><strong>Storage</strong></td><td style="text-align: left">Pluggable backends — in-memory, file-based, or memory-mapped</td></tr>
<tr><td style="text-align: left"><strong>Query DSL</strong></td><td style="text-align: left">Human-readable query syntax for lexical, vector, and hybrid search</td></tr>
<tr><td style="text-align: left"><strong>Pure Rust</strong></td><td style="text-align: left">No C/C++ dependencies in the core — safe, portable, easy to build</td></tr>
</tbody></table>
</div>
<h2 id="how-it-works"><a class="header" href="#how-it-works">How It Works</a></h2>
<pre><code class="language-mermaid">graph LR
    subgraph Your Application
        D["Document"]
        Q["Query"]
    end

    subgraph Laurus Engine
        SCH["Schema"]
        AN["Analyzer"]
        EM["Embedder"]
        LI["Lexical Index\n(Inverted Index)"]
        VI["Vector Index\n(HNSW / Flat / IVF)"]
        FU["Fusion\n(RRF / WeightedSum)"]
    end

    D --&gt; SCH
    SCH --&gt; AN --&gt; LI
    SCH --&gt; EM --&gt; VI
    Q --&gt; LI --&gt; FU
    Q --&gt; VI --&gt; FU
    FU --&gt; R["Ranked Results"]
</code></pre>
<ol>
<li><strong>Define a Schema</strong> — declare your fields and their types (text, integer, vector, etc.)</li>
<li><strong>Build an Engine</strong> — attach an analyzer for text and an embedder for vectors</li>
<li><strong>Index Documents</strong> — the engine routes each field to the correct index automatically</li>
<li><strong>Search</strong> — run lexical, vector, or hybrid queries and get ranked results</li>
</ol>
<h2 id="document-map"><a class="header" href="#document-map">Document Map</a></h2>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Section</th><th style="text-align: left">What You Will Learn</th></tr></thead><tbody>
<tr><td style="text-align: left"><a href="getting_started.html">Getting Started</a></td><td style="text-align: left">Install Laurus and run your first search in minutes</td></tr>
<tr><td style="text-align: left"><a href="architecture.html">Architecture</a></td><td style="text-align: left">Understand the Engine, its components, and data flow</td></tr>
<tr><td style="text-align: left"><a href="concepts.html">Core Concepts</a></td><td style="text-align: left">Schema, text analysis, embeddings, and storage</td></tr>
<tr><td style="text-align: left"><a href="indexing/lexical_indexing.html">Indexing</a></td><td style="text-align: left">How inverted indexes and vector indexes work internally</td></tr>
<tr><td style="text-align: left"><a href="search/lexical_search.html">Search</a></td><td style="text-align: left">Query types, vector search, and hybrid fusion</td></tr>
<tr><td style="text-align: left"><a href="advanced.html">Advanced Features</a></td><td style="text-align: left">Query DSL, ID management, WAL, and compaction</td></tr>
<tr><td style="text-align: left"><a href="api_reference.html">API Reference</a></td><td style="text-align: left">Key types and methods at a glance</td></tr>
</tbody></table>
</div>
<h2 id="quick-example"><a class="header" href="#quick-example">Quick Example</a></h2>
<pre><pre class="playground"><code class="language-rust">use std::sync::Arc;
use laurus::{Document, Engine, Schema, SearchRequestBuilder, Result};
use laurus::lexical::{TextOption, TermQuery};
use laurus::storage::memory::MemoryStorage;

#[tokio::main]
async fn main() -&gt; Result&lt;()&gt; {
    // 1. Storage
    let storage = Arc::new(MemoryStorage::new(Default::default()));

    // 2. Schema
    let schema = Schema::builder()
        .add_text_field("title", TextOption::default())
        .add_text_field("body", TextOption::default())
        .add_default_field("body")
        .build();

    // 3. Engine
    let engine = Engine::builder(storage, schema).build().await?;

    // 4. Index a document
    let doc = Document::builder()
        .add_text("title", "Hello Laurus")
        .add_text("body", "A fast search library for Rust")
        .build();
    engine.add_document("doc-1", doc).await?;
    engine.commit().await?;

    // 5. Search
    let request = SearchRequestBuilder::new()
        .lexical_search_request(
            laurus::LexicalSearchRequest::new(
                Box::new(TermQuery::new("body", "rust"))
            )
        )
        .limit(10)
        .build();
    let results = engine.search(request).await?;

    for r in &amp;results {
        println!("{}: score={:.4}", r.id, r.score);
    }
    Ok(())
}</code></pre></pre>
<h2 id="license"><a class="header" href="#license">License</a></h2>
<p>Laurus is dual-licensed under <a href="https://opensource.org/licenses/MIT">MIT</a> and <a href="https://www.apache.org/licenses/LICENSE-2.0">Apache 2.0</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="getting-started"><a class="header" href="#getting-started">Getting Started</a></h1>
<p>Welcome to Laurus! This section will help you install the library and run your first search.</p>
<h2 id="what-you-will-build"><a class="header" href="#what-you-will-build">What You Will Build</a></h2>
<p>By the end of this guide, you will have a working search engine that can:</p>
<ul>
<li>Index text documents</li>
<li>Perform keyword (lexical) search</li>
<li>Perform semantic (vector) search</li>
<li>Combine both with hybrid search</li>
</ul>
<h2 id="prerequisites"><a class="header" href="#prerequisites">Prerequisites</a></h2>
<ul>
<li><strong>Rust</strong> 1.85 or later (edition 2024)</li>
<li><strong>Cargo</strong> (included with Rust)</li>
<li><strong>Tokio</strong> runtime (Laurus uses async APIs)</li>
</ul>
<h2 id="steps"><a class="header" href="#steps">Steps</a></h2>
<ol>
<li><strong><a href="getting_started/installation.html">Installation</a></strong> — Add Laurus to your project and choose feature flags</li>
<li><strong><a href="getting_started/quickstart.html">Quick Start</a></strong> — Build a complete search engine in 5 steps</li>
</ol>
<h2 id="workflow-overview"><a class="header" href="#workflow-overview">Workflow Overview</a></h2>
<p>Building a search application with Laurus follows a consistent pattern:</p>
<pre><code class="language-mermaid">graph LR
    A["1. Create\nStorage"] --&gt; B["2. Define\nSchema"]
    B --&gt; C["3. Build\nEngine"]
    C --&gt; D["4. Index\nDocuments"]
    D --&gt; E["5. Search"]
</code></pre>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Step</th><th style="text-align: left">What Happens</th></tr></thead><tbody>
<tr><td style="text-align: left"><strong>Create Storage</strong></td><td style="text-align: left">Choose where data lives — in memory, on disk, or memory-mapped</td></tr>
<tr><td style="text-align: left"><strong>Define Schema</strong></td><td style="text-align: left">Declare fields and their types (text, integer, vector, etc.)</td></tr>
<tr><td style="text-align: left"><strong>Build Engine</strong></td><td style="text-align: left">Attach an analyzer (for text) and an embedder (for vectors)</td></tr>
<tr><td style="text-align: left"><strong>Index Documents</strong></td><td style="text-align: left">Add documents; the engine routes fields to the correct index</td></tr>
<tr><td style="text-align: left"><strong>Search</strong></td><td style="text-align: left">Run lexical, vector, or hybrid queries and get ranked results</td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><h1 id="installation"><a class="header" href="#installation">Installation</a></h1>
<h2 id="add-laurus-to-your-project"><a class="header" href="#add-laurus-to-your-project">Add Laurus to Your Project</a></h2>
<p>Add <code>laurus</code> and <code>tokio</code> (async runtime) to your <code>Cargo.toml</code>:</p>
<pre><code class="language-toml">[dependencies]
laurus = "0.1.0"
tokio = { version = "1", features = ["full"] }
</code></pre>
<h2 id="feature-flags"><a class="header" href="#feature-flags">Feature Flags</a></h2>
<p>Laurus ships with a minimal default feature set. Enable additional features as needed:</p>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Feature</th><th style="text-align: left">Description</th><th style="text-align: left">Use Case</th></tr></thead><tbody>
<tr><td style="text-align: left"><em>(default)</em></td><td style="text-align: left">Core library (lexical search, storage, analyzers — no embedding)</td><td style="text-align: left">Keyword search only</td></tr>
<tr><td style="text-align: left"><code>embeddings-candle</code></td><td style="text-align: left">Local BERT embeddings via Hugging Face Candle</td><td style="text-align: left">Vector search without external API</td></tr>
<tr><td style="text-align: left"><code>embeddings-openai</code></td><td style="text-align: left">OpenAI API embeddings (text-embedding-3-small, etc.)</td><td style="text-align: left">Cloud-based vector search</td></tr>
<tr><td style="text-align: left"><code>embeddings-multimodal</code></td><td style="text-align: left">CLIP embeddings for text + image via Candle</td><td style="text-align: left">Multimodal (text-to-image) search</td></tr>
<tr><td style="text-align: left"><code>embeddings-all</code></td><td style="text-align: left">All embedding features above</td><td style="text-align: left">Full embedding support</td></tr>
</tbody></table>
</div>
<h3 id="examples"><a class="header" href="#examples">Examples</a></h3>
<p><strong>Lexical search only</strong> (no embeddings needed):</p>
<pre><code class="language-toml">[dependencies]
laurus = "0.1.0"
</code></pre>
<p><strong>Vector search with local model</strong> (no API key required):</p>
<pre><code class="language-toml">[dependencies]
laurus = { version = "0.1.0", features = ["embeddings-candle"] }
</code></pre>
<p><strong>Vector search with OpenAI</strong>:</p>
<pre><code class="language-toml">[dependencies]
laurus = { version = "0.1.0", features = ["embeddings-openai"] }
</code></pre>
<p><strong>Everything</strong>:</p>
<pre><code class="language-toml">[dependencies]
laurus = { version = "0.1.0", features = ["embeddings-all"] }
</code></pre>
<h2 id="verify-installation"><a class="header" href="#verify-installation">Verify Installation</a></h2>
<p>Create a minimal program to verify that Laurus compiles:</p>
<pre><pre class="playground"><code class="language-rust">use laurus::Result;

#[tokio::main]
async fn main() -&gt; Result&lt;()&gt; {
    println!("Laurus version: {}", laurus::VERSION);
    Ok(())
}</code></pre></pre>
<pre><code class="language-bash">cargo run
</code></pre>
<p>If you see the version printed, you are ready to proceed to the <a href="getting_started/quickstart.html">Quick Start</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="quick-start"><a class="header" href="#quick-start">Quick Start</a></h1>
<p>This tutorial walks you through building a complete search engine in 5 steps. By the end, you will be able to index documents and search them by keyword.</p>
<h2 id="step-1--create-storage"><a class="header" href="#step-1--create-storage">Step 1 — Create Storage</a></h2>
<p>Storage determines where Laurus persists index data. For development and testing, use <code>MemoryStorage</code>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use std::sync::Arc;
use laurus::storage::memory::MemoryStorage;
use laurus::Storage;

let storage: Arc&lt;dyn Storage&gt; = Arc::new(
    MemoryStorage::new(Default::default())
);
<span class="boring">}</span></code></pre></pre>
<blockquote>
<p><strong>Tip:</strong> For production, consider <code>FileStorage</code> (with optional <code>use_mmap</code> for memory-mapped I/O). See <a href="getting_started/../concepts/storage.html">Storage</a> for details.</p>
</blockquote>
<h2 id="step-2--define-a-schema"><a class="header" href="#step-2--define-a-schema">Step 2 — Define a Schema</a></h2>
<p>A <code>Schema</code> declares the fields in your documents and how each field should be indexed:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::Schema;
use laurus::lexical::TextOption;

let schema = Schema::builder()
    .add_text_field("title", TextOption::default())
    .add_text_field("body", TextOption::default())
    .add_default_field("body")  // used when no field is specified in a query
    .build();
<span class="boring">}</span></code></pre></pre>
<p>Each field has a type. Common types include:</p>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Method</th><th style="text-align: left">Field Type</th><th style="text-align: left">Example Values</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>add_text_field</code></td><td style="text-align: left">Text (full-text searchable)</td><td style="text-align: left"><code>"Hello world"</code></td></tr>
<tr><td style="text-align: left"><code>add_integer_field</code></td><td style="text-align: left">64-bit integer</td><td style="text-align: left"><code>42</code></td></tr>
<tr><td style="text-align: left"><code>add_float_field</code></td><td style="text-align: left">64-bit float</td><td style="text-align: left"><code>3.14</code></td></tr>
<tr><td style="text-align: left"><code>add_boolean_field</code></td><td style="text-align: left">Boolean</td><td style="text-align: left"><code>true</code> / <code>false</code></td></tr>
<tr><td style="text-align: left"><code>add_datetime_field</code></td><td style="text-align: left">UTC datetime</td><td style="text-align: left"><code>2024-01-15T10:30:00Z</code></td></tr>
<tr><td style="text-align: left"><code>add_hnsw_field</code></td><td style="text-align: left">Vector (HNSW index)</td><td style="text-align: left"><code>[0.1, 0.2, ...]</code></td></tr>
<tr><td style="text-align: left"><code>add_flat_field</code></td><td style="text-align: left">Vector (Flat index)</td><td style="text-align: left"><code>[0.1, 0.2, ...]</code></td></tr>
</tbody></table>
</div>
<blockquote>
<p>See <a href="getting_started/../concepts/schema_and_fields.html">Schema &amp; Fields</a> for the full list.</p>
</blockquote>
<h2 id="step-3--build-an-engine"><a class="header" href="#step-3--build-an-engine">Step 3 — Build an Engine</a></h2>
<p>The <code>Engine</code> ties storage, schema, and runtime components together:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::Engine;

let engine = Engine::builder(storage, schema)
    .build()
    .await?;
<span class="boring">}</span></code></pre></pre>
<p>When you only use text fields, the default <code>StandardAnalyzer</code> is used automatically. To customize analysis or add vector embeddings, see <a href="getting_started/../architecture.html">Architecture</a>.</p>
<h2 id="step-4--index-documents"><a class="header" href="#step-4--index-documents">Step 4 — Index Documents</a></h2>
<p>Create documents with the <code>DocumentBuilder</code> and add them to the engine:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::Document;

// Each document needs a unique external ID (string)
let doc = Document::builder()
    .add_text("title", "Introduction to Rust")
    .add_text("body", "Rust is a systems programming language focused on safety and performance.")
    .build();
engine.add_document("doc-1", doc).await?;

let doc = Document::builder()
    .add_text("title", "Python for Data Science")
    .add_text("body", "Python is widely used in machine learning and data analysis.")
    .build();
engine.add_document("doc-2", doc).await?;

let doc = Document::builder()
    .add_text("title", "Web Development with JavaScript")
    .add_text("body", "JavaScript powers interactive web applications and server-side code with Node.js.")
    .build();
engine.add_document("doc-3", doc).await?;

// Commit to make documents searchable
engine.commit().await?;
<span class="boring">}</span></code></pre></pre>
<blockquote>
<p><strong>Important:</strong> Documents are not searchable until <code>commit()</code> is called.</p>
</blockquote>
<h2 id="step-5--search"><a class="header" href="#step-5--search">Step 5 — Search</a></h2>
<p>Use <code>SearchRequestBuilder</code> with a query to search the index:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::{SearchRequestBuilder, LexicalSearchRequest};
use laurus::lexical::TermQuery;

// Search for "rust" in the "body" field
let request = SearchRequestBuilder::new()
    .lexical_search_request(
        LexicalSearchRequest::new(
            Box::new(TermQuery::new("body", "rust"))
        )
    )
    .limit(10)
    .build();

let results = engine.search(request).await?;

for result in &amp;results {
    println!("ID: {}, Score: {:.4}", result.id, result.score);
    if let Some(doc) = &amp;result.document {
        if let Some(title) = doc.get("title") {
            println!("  Title: {:?}", title);
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="complete-example"><a class="header" href="#complete-example">Complete Example</a></h2>
<p>Here is the full program that you can copy, paste, and run:</p>
<pre><pre class="playground"><code class="language-rust">use std::sync::Arc;
use laurus::{
    Document, Engine, LexicalSearchRequest,
    Result, Schema, SearchRequestBuilder,
};
use laurus::lexical::{TextOption, TermQuery};
use laurus::storage::memory::MemoryStorage;

#[tokio::main]
async fn main() -&gt; Result&lt;()&gt; {
    // 1. Storage
    let storage = Arc::new(MemoryStorage::new(Default::default()));

    // 2. Schema
    let schema = Schema::builder()
        .add_text_field("title", TextOption::default())
        .add_text_field("body", TextOption::default())
        .add_default_field("body")
        .build();

    // 3. Engine
    let engine = Engine::builder(storage, schema).build().await?;

    // 4. Index documents
    for (id, title, body) in [
        ("doc-1", "Introduction to Rust", "Rust is a systems programming language focused on safety."),
        ("doc-2", "Python for Data Science", "Python is widely used in machine learning."),
        ("doc-3", "Web Development", "JavaScript powers interactive web applications."),
    ] {
        let doc = Document::builder()
            .add_text("title", title)
            .add_text("body", body)
            .build();
        engine.add_document(id, doc).await?;
    }
    engine.commit().await?;

    // 5. Search
    let request = SearchRequestBuilder::new()
        .lexical_search_request(
            LexicalSearchRequest::new(
                Box::new(TermQuery::new("body", "rust"))
            )
        )
        .limit(10)
        .build();

    let results = engine.search(request).await?;
    for r in &amp;results {
        println!("{}: score={:.4}", r.id, r.score);
    }

    Ok(())
}</code></pre></pre>
<h2 id="next-steps"><a class="header" href="#next-steps">Next Steps</a></h2>
<ul>
<li>Learn how the Engine works internally: <a href="getting_started/../architecture.html">Architecture</a></li>
<li>Understand Schema and field types: <a href="getting_started/../concepts/schema_and_fields.html">Schema &amp; Fields</a></li>
<li>Add vector search: <a href="getting_started/../search/vector_search.html">Vector Search</a></li>
<li>Combine lexical + vector: <a href="getting_started/../search/hybrid_search.html">Hybrid Search</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="core-concepts"><a class="header" href="#core-concepts">Core Concepts</a></h1>
<p>This section covers the foundational building blocks of Laurus. Understanding these concepts will help you design effective schemas and configure your search engine.</p>
<h2 id="topics"><a class="header" href="#topics">Topics</a></h2>
<h3 id="schema--fields"><a class="header" href="#schema--fields"><a href="concepts/schema_and_fields.html">Schema &amp; Fields</a></a></h3>
<p>How to define the structure of your documents. Covers:</p>
<ul>
<li><code>Schema</code> and <code>SchemaBuilder</code></li>
<li>Lexical field types (Text, Integer, Float, Boolean, DateTime, Geo, Bytes)</li>
<li>Vector field types (Flat, HNSW, IVF)</li>
<li><code>Document</code> and <code>DocumentBuilder</code></li>
<li><code>DataValue</code> — the unified value type</li>
</ul>
<h3 id="text-analysis"><a class="header" href="#text-analysis"><a href="concepts/analysis.html">Text Analysis</a></a></h3>
<p>How text is processed before indexing. Covers:</p>
<ul>
<li>The <code>Analyzer</code> trait and the analysis pipeline</li>
<li>Built-in analyzers (Standard, Japanese, Keyword, Pipeline)</li>
<li><code>PerFieldAnalyzer</code> — different analyzers for different fields</li>
<li>Tokenizers and token filters</li>
</ul>
<h3 id="embeddings"><a class="header" href="#embeddings"><a href="concepts/embedding.html">Embeddings</a></a></h3>
<p>How text and images are converted to vectors. Covers:</p>
<ul>
<li>The <code>Embedder</code> trait</li>
<li>Built-in embedders (Candle BERT, OpenAI, CLIP, Precomputed)</li>
<li><code>PerFieldEmbedder</code> — different embedders for different fields</li>
</ul>
<h3 id="storage"><a class="header" href="#storage"><a href="concepts/storage.html">Storage</a></a></h3>
<p>Where index data is stored. Covers:</p>
<ul>
<li>The <code>Storage</code> trait</li>
<li>Storage backends (Memory, File, Mmap)</li>
<li><code>PrefixedStorage</code> for component isolation</li>
<li>Choosing the right backend for your use case</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="schema--fields-1"><a class="header" href="#schema--fields-1">Schema &amp; Fields</a></h1>
<p>The <code>Schema</code> defines the structure of your documents — what fields exist and how each field is indexed. It is the single source of truth for the Engine.</p>
<blockquote>
<p>For the TOML file format used by the CLI, see <a href="concepts/../cli/schema_format.html">Schema Format Reference</a>.</p>
</blockquote>
<h2 id="schema"><a class="header" href="#schema">Schema</a></h2>
<p>A <code>Schema</code> is a collection of named fields. Each field is either a <strong>lexical field</strong> (for keyword search) or a <strong>vector field</strong> (for similarity search).</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::Schema;
use laurus::lexical::TextOption;
use laurus::lexical::core::field::IntegerOption;
use laurus::vector::HnswOption;

let schema = Schema::builder()
    .add_text_field("title", TextOption::default())
    .add_text_field("body", TextOption::default())
    .add_integer_field("year", IntegerOption::default())
    .add_hnsw_field("embedding", HnswOption::default())
    .add_default_field("body")
    .build();
<span class="boring">}</span></code></pre></pre>
<h3 id="default-fields"><a class="header" href="#default-fields">Default Fields</a></h3>
<p><code>add_default_field()</code> specifies which field(s) are searched when a query does not explicitly name a field. This is used by the <a href="concepts/../advanced/query_dsl.html">Query DSL</a> parser.</p>
<h2 id="field-types"><a class="header" href="#field-types">Field Types</a></h2>
<pre><code class="language-mermaid">graph TB
    FO["FieldOption"]

    FO --&gt; T["Text"]
    FO --&gt; I["Integer"]
    FO --&gt; FL["Float"]
    FO --&gt; B["Boolean"]
    FO --&gt; DT["DateTime"]
    FO --&gt; G["Geo"]
    FO --&gt; BY["Bytes"]

    FO --&gt; FLAT["Flat"]
    FO --&gt; HNSW["HNSW"]
    FO --&gt; IVF["IVF"]
</code></pre>
<h3 id="lexical-fields"><a class="header" href="#lexical-fields">Lexical Fields</a></h3>
<p>Lexical fields are indexed using an inverted index and support keyword-based queries.</p>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Type</th><th style="text-align: left">Rust Type</th><th style="text-align: left">SchemaBuilder Method</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><strong>Text</strong></td><td style="text-align: left"><code>TextOption</code></td><td style="text-align: left"><code>add_text_field()</code></td><td style="text-align: left">Full-text searchable; tokenized by the analyzer</td></tr>
<tr><td style="text-align: left"><strong>Integer</strong></td><td style="text-align: left"><code>IntegerOption</code></td><td style="text-align: left"><code>add_integer_field()</code></td><td style="text-align: left">64-bit signed integer; supports range queries</td></tr>
<tr><td style="text-align: left"><strong>Float</strong></td><td style="text-align: left"><code>FloatOption</code></td><td style="text-align: left"><code>add_float_field()</code></td><td style="text-align: left">64-bit floating point; supports range queries</td></tr>
<tr><td style="text-align: left"><strong>Boolean</strong></td><td style="text-align: left"><code>BooleanOption</code></td><td style="text-align: left"><code>add_boolean_field()</code></td><td style="text-align: left"><code>true</code> / <code>false</code></td></tr>
<tr><td style="text-align: left"><strong>DateTime</strong></td><td style="text-align: left"><code>DateTimeOption</code></td><td style="text-align: left"><code>add_datetime_field()</code></td><td style="text-align: left">UTC timestamp; supports range queries</td></tr>
<tr><td style="text-align: left"><strong>Geo</strong></td><td style="text-align: left"><code>GeoOption</code></td><td style="text-align: left"><code>add_geo_field()</code></td><td style="text-align: left">Latitude/longitude pair; supports radius and bounding box queries</td></tr>
<tr><td style="text-align: left"><strong>Bytes</strong></td><td style="text-align: left"><code>BytesOption</code></td><td style="text-align: left"><code>add_bytes_field()</code></td><td style="text-align: left">Raw binary data</td></tr>
</tbody></table>
</div>
<h4 id="text-field-options"><a class="header" href="#text-field-options">Text Field Options</a></h4>
<p><code>TextOption</code> controls how text is indexed:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::lexical::TextOption;

// Default: indexed + stored
let opt = TextOption::default();

// Customize: indexed + stored + term vectors
let opt = TextOption::default()
    .set_indexed(true)
    .set_stored(true)
    .set_term_vectors(true);
<span class="boring">}</span></code></pre></pre>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Option</th><th style="text-align: left">Default</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>indexed</code></td><td style="text-align: left"><code>true</code></td><td style="text-align: left">Whether the field is searchable</td></tr>
<tr><td style="text-align: left"><code>stored</code></td><td style="text-align: left"><code>true</code></td><td style="text-align: left">Whether the original value is stored for retrieval</td></tr>
<tr><td style="text-align: left"><code>term_vectors</code></td><td style="text-align: left"><code>false</code></td><td style="text-align: left">Whether term positions are stored (needed for phrase queries)</td></tr>
</tbody></table>
</div>
<h3 id="vector-fields"><a class="header" href="#vector-fields">Vector Fields</a></h3>
<p>Vector fields are indexed using vector indexes for approximate nearest neighbor (ANN) search.</p>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Type</th><th style="text-align: left">Rust Type</th><th style="text-align: left">SchemaBuilder Method</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><strong>Flat</strong></td><td style="text-align: left"><code>FlatOption</code></td><td style="text-align: left"><code>add_flat_field()</code></td><td style="text-align: left">Brute-force linear scan; exact results</td></tr>
<tr><td style="text-align: left"><strong>HNSW</strong></td><td style="text-align: left"><code>HnswOption</code></td><td style="text-align: left"><code>add_hnsw_field()</code></td><td style="text-align: left">Hierarchical Navigable Small World graph; fast approximate</td></tr>
<tr><td style="text-align: left"><strong>IVF</strong></td><td style="text-align: left"><code>IvfOption</code></td><td style="text-align: left"><code>add_ivf_field()</code></td><td style="text-align: left">Inverted File Index; cluster-based approximate</td></tr>
</tbody></table>
</div>
<h4 id="hnsw-field-options-most-common"><a class="header" href="#hnsw-field-options-most-common">HNSW Field Options (most common)</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::vector::HnswOption;
use laurus::vector::core::distance::DistanceMetric;

let opt = HnswOption {
    dimension: 384,                          // vector dimensions
    distance: DistanceMetric::Cosine,        // distance metric
    m: 16,                                   // max connections per layer
    ef_construction: 200,                    // construction search width
    base_weight: 1.0,                        // default scoring weight
    quantizer: None,                         // optional quantization
};
<span class="boring">}</span></code></pre></pre>
<p>See <a href="concepts/../indexing/vector_indexing.html">Vector Indexing</a> for detailed parameter guidance.</p>
<h2 id="document"><a class="header" href="#document">Document</a></h2>
<p>A <code>Document</code> is a collection of named field values. Use <code>DocumentBuilder</code> to construct documents:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::Document;

let doc = Document::builder()
    .add_text("title", "Introduction to Rust")
    .add_text("body", "Rust is a systems programming language.")
    .add_integer("year", 2024)
    .add_float("rating", 4.8)
    .add_boolean("published", true)
    .build();
<span class="boring">}</span></code></pre></pre>
<h3 id="indexing-documents"><a class="header" href="#indexing-documents">Indexing Documents</a></h3>
<p>The <code>Engine</code> provides two methods for adding documents, each with different semantics:</p>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Method</th><th style="text-align: left">Behavior</th><th style="text-align: left">Use Case</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>put_document(id, doc)</code></td><td style="text-align: left"><strong>Upsert</strong> — if a document with the same ID exists, it is replaced</td><td style="text-align: left">Standard document indexing</td></tr>
<tr><td style="text-align: left"><code>add_document(id, doc)</code></td><td style="text-align: left"><strong>Append</strong> — adds the document as a new chunk; multiple chunks can share the same ID</td><td style="text-align: left">Chunked/split documents (e.g., long articles split into paragraphs)</td></tr>
</tbody></table>
</div>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Upsert: replaces any existing document with id "doc1"
engine.put_document("doc1", doc).await?;

// Append: adds another chunk under the same id "doc1"
engine.add_document("doc1", chunk2).await?;

// Always commit after indexing
engine.commit().await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="retrieving-documents"><a class="header" href="#retrieving-documents">Retrieving Documents</a></h3>
<p>Use <code>get_documents</code> to retrieve all documents (including chunks) by external ID:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let docs = engine.get_documents("doc1").await?;
for doc in &amp;docs {
    if let Some(title) = doc.get("title") {
        println!("Title: {:?}", title);
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="deleting-documents"><a class="header" href="#deleting-documents">Deleting Documents</a></h3>
<p>Delete all documents and chunks sharing an external ID:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>engine.delete_documents("doc1").await?;
engine.commit().await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="document-lifecycle"><a class="header" href="#document-lifecycle">Document Lifecycle</a></h3>
<pre><code class="language-mermaid">graph LR
    A["Build Document"] --&gt; B["put/add_document()"]
    B --&gt; C["WAL"]
    C --&gt; D["commit()"]
    D --&gt; E["Searchable"]
    E --&gt; F["get_documents()"]
    E --&gt; G["delete_documents()"]
</code></pre>
<blockquote>
<p><strong>Important:</strong> Documents are not searchable until <code>commit()</code> is called.</p>
</blockquote>
<h3 id="documentbuilder-methods"><a class="header" href="#documentbuilder-methods">DocumentBuilder Methods</a></h3>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Method</th><th style="text-align: left">Value Type</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>add_text(name, value)</code></td><td style="text-align: left"><code>String</code></td><td style="text-align: left">Add a text field</td></tr>
<tr><td style="text-align: left"><code>add_integer(name, value)</code></td><td style="text-align: left"><code>i64</code></td><td style="text-align: left">Add an integer field</td></tr>
<tr><td style="text-align: left"><code>add_float(name, value)</code></td><td style="text-align: left"><code>f64</code></td><td style="text-align: left">Add a float field</td></tr>
<tr><td style="text-align: left"><code>add_boolean(name, value)</code></td><td style="text-align: left"><code>bool</code></td><td style="text-align: left">Add a boolean field</td></tr>
<tr><td style="text-align: left"><code>add_datetime(name, value)</code></td><td style="text-align: left"><code>DateTime&lt;Utc&gt;</code></td><td style="text-align: left">Add a datetime field</td></tr>
<tr><td style="text-align: left"><code>add_vector(name, value)</code></td><td style="text-align: left"><code>Vec&lt;f32&gt;</code></td><td style="text-align: left">Add a pre-computed vector field</td></tr>
<tr><td style="text-align: left"><code>add_geo(name, lat, lon)</code></td><td style="text-align: left"><code>(f64, f64)</code></td><td style="text-align: left">Add a geographic point</td></tr>
<tr><td style="text-align: left"><code>add_bytes(name, data)</code></td><td style="text-align: left"><code>Vec&lt;u8&gt;</code></td><td style="text-align: left">Add binary data</td></tr>
<tr><td style="text-align: left"><code>add_field(name, value)</code></td><td style="text-align: left"><code>DataValue</code></td><td style="text-align: left">Add any value type</td></tr>
</tbody></table>
</div>
<h2 id="datavalue"><a class="header" href="#datavalue">DataValue</a></h2>
<p><code>DataValue</code> is the unified value enum that represents any field value in Laurus:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub enum DataValue {
    Null,
    Bool(bool),
    Int64(i64),
    Float64(f64),
    Text(String),
    Bytes(Vec&lt;u8&gt;, Option&lt;String&gt;),  // (data, optional MIME type)
    Vector(Vec&lt;f32&gt;),
    DateTime(DateTime&lt;Utc&gt;),
    Geo(f64, f64),          // (latitude, longitude)
}
<span class="boring">}</span></code></pre></pre>
<p><code>DataValue</code> implements <code>From&lt;T&gt;</code> for common types, so you can use <code>.into()</code> conversions:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::DataValue;

let v: DataValue = "hello".into();       // Text
let v: DataValue = 42i64.into();         // Int64
let v: DataValue = 3.14f64.into();       // Float64
let v: DataValue = true.into();          // Bool
let v: DataValue = vec![0.1f32, 0.2].into(); // Vector
<span class="boring">}</span></code></pre></pre>
<h2 id="reserved-fields"><a class="header" href="#reserved-fields">Reserved Fields</a></h2>
<p>The <code>_id</code> field is reserved by Laurus for internal use. It stores the external document ID and is always indexed with <code>KeywordAnalyzer</code> (exact match). You do not need to add it to your schema — it is managed automatically.</p>
<h2 id="schema-design-tips"><a class="header" href="#schema-design-tips">Schema Design Tips</a></h2>
<ol>
<li>
<p><strong>Separate lexical and vector fields</strong> — a field is either lexical or vector, never both. For hybrid search, create separate fields (e.g., <code>body</code> for text, <code>body_vec</code> for vector).</p>
</li>
<li>
<p><strong>Use <code>KeywordAnalyzer</code> for exact-match fields</strong> — category, status, and tag fields should use <code>KeywordAnalyzer</code> via <code>PerFieldAnalyzer</code> to avoid tokenization.</p>
</li>
<li>
<p><strong>Choose the right vector index</strong> — use HNSW for most cases, Flat for small datasets, IVF for very large datasets. See <a href="concepts/../indexing/vector_indexing.html">Vector Indexing</a>.</p>
</li>
<li>
<p><strong>Set default fields</strong> — if you use the Query DSL, set default fields so users can write <code>hello</code> instead of <code>body:hello</code>.</p>
</li>
<li>
<p><strong>Use the schema generator</strong> — run <code>laurus create schema</code> to interactively build a schema TOML file instead of writing it by hand. See <a href="concepts/../cli/commands.html#create-schema">CLI Commands</a>.</p>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="text-analysis-1"><a class="header" href="#text-analysis-1">Text Analysis</a></h1>
<p>Text analysis is the process of converting raw text into searchable tokens. When a document is indexed, the analyzer breaks text fields into individual terms; when a query is executed, the same analyzer processes the query text to ensure consistency.</p>
<h2 id="the-analysis-pipeline"><a class="header" href="#the-analysis-pipeline">The Analysis Pipeline</a></h2>
<pre><code class="language-mermaid">graph LR
    Input["Raw Text\n'The quick brown FOX jumps!'"]
    CF["UnicodeNormalizationCharFilter"]
    T["Tokenizer\nSplit into words"]
    F1["LowercaseFilter"]
    F2["StopFilter"]
    F3["StemFilter"]
    Output["Terms\n'quick', 'brown', 'fox', 'jump'"]

    Input --&gt; CF --&gt; T --&gt; F1 --&gt; F2 --&gt; F3 --&gt; Output
</code></pre>
<p>The analysis pipeline consists of:</p>
<ol>
<li><strong>Char Filters</strong> — normalize raw text at the character level before tokenization</li>
<li><strong>Tokenizer</strong> — splits text into raw tokens (words, characters, n-grams)</li>
<li><strong>Token Filters</strong> — transform, remove, or expand tokens (lowercase, stop words, stemming, synonyms)</li>
</ol>
<h2 id="the-analyzer-trait"><a class="header" href="#the-analyzer-trait">The Analyzer Trait</a></h2>
<p>All analyzers implement the <code>Analyzer</code> trait:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub trait Analyzer: Send + Sync + Debug {
    fn analyze(&amp;self, text: &amp;str) -&gt; Result&lt;TokenStream&gt;;
    fn name(&amp;self) -&gt; &amp;str;
    fn as_any(&amp;self) -&gt; &amp;dyn Any;
}
<span class="boring">}</span></code></pre></pre>
<p><code>TokenStream</code> is a <code>Box&lt;dyn Iterator&lt;Item = Token&gt; + Send&gt;</code> — a lazy iterator over tokens.</p>
<p>A <code>Token</code> contains:</p>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Field</th><th style="text-align: left">Type</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>text</code></td><td style="text-align: left"><code>String</code></td><td style="text-align: left">The token text</td></tr>
<tr><td style="text-align: left"><code>position</code></td><td style="text-align: left"><code>usize</code></td><td style="text-align: left">Position in the original text</td></tr>
<tr><td style="text-align: left"><code>start_offset</code></td><td style="text-align: left"><code>usize</code></td><td style="text-align: left">Start byte offset in original text</td></tr>
<tr><td style="text-align: left"><code>end_offset</code></td><td style="text-align: left"><code>usize</code></td><td style="text-align: left">End byte offset in original text</td></tr>
<tr><td style="text-align: left"><code>position_increment</code></td><td style="text-align: left"><code>usize</code></td><td style="text-align: left">Distance from previous token</td></tr>
<tr><td style="text-align: left"><code>position_length</code></td><td style="text-align: left"><code>usize</code></td><td style="text-align: left">Span of the token (&gt;1 for synonyms)</td></tr>
<tr><td style="text-align: left"><code>boost</code></td><td style="text-align: left"><code>f32</code></td><td style="text-align: left">Token-level scoring weight</td></tr>
<tr><td style="text-align: left"><code>stopped</code></td><td style="text-align: left"><code>bool</code></td><td style="text-align: left">Whether marked as a stop word</td></tr>
<tr><td style="text-align: left"><code>metadata</code></td><td style="text-align: left"><code>Option&lt;TokenMetadata&gt;</code></td><td style="text-align: left">Additional token metadata</td></tr>
</tbody></table>
</div>
<h2 id="built-in-analyzers"><a class="header" href="#built-in-analyzers">Built-in Analyzers</a></h2>
<h3 id="standardanalyzer"><a class="header" href="#standardanalyzer">StandardAnalyzer</a></h3>
<p>The default analyzer. Suitable for most Western languages.</p>
<p>Pipeline: <code>RegexTokenizer</code> (Unicode word boundaries) → <code>LowercaseFilter</code> → <code>StopFilter</code> (128 common English stop words)</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::analysis::analyzer::standard::StandardAnalyzer;

let analyzer = StandardAnalyzer::default();
// "The Quick Brown Fox" → ["quick", "brown", "fox"]
// ("The" is removed by stop word filtering)
<span class="boring">}</span></code></pre></pre>
<h3 id="japaneseanalyzer"><a class="header" href="#japaneseanalyzer">JapaneseAnalyzer</a></h3>
<p>Uses morphological analysis for Japanese text segmentation.</p>
<p>Pipeline: <code>UnicodeNormalizationCharFilter</code> (NFKC) → <code>JapaneseIterationMarkCharFilter</code> → <code>LinderaTokenizer</code> → <code>LowercaseFilter</code> → <code>StopFilter</code> (Japanese stop words)</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::analysis::analyzer::japanese::JapaneseAnalyzer;

let analyzer = JapaneseAnalyzer::new()?;
// "東京都に住んでいる" → ["東京", "都", "に", "住ん", "で", "いる"]
<span class="boring">}</span></code></pre></pre>
<h3 id="keywordanalyzer"><a class="header" href="#keywordanalyzer">KeywordAnalyzer</a></h3>
<p>Treats the entire input as a single token. No tokenization or normalization.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::analysis::analyzer::keyword::KeywordAnalyzer;

let analyzer = KeywordAnalyzer::new();
// "Hello World" → ["Hello World"]
<span class="boring">}</span></code></pre></pre>
<p>Use this for fields that should match exactly (categories, tags, status codes).</p>
<h3 id="simpleanalyzer"><a class="header" href="#simpleanalyzer">SimpleAnalyzer</a></h3>
<p>Tokenizes text without any filtering. The original case and all tokens are preserved. Useful when you need complete control over the analysis pipeline or want to test a tokenizer in isolation.</p>
<p>Pipeline: User-specified <code>Tokenizer</code> only (no char filters, no token filters)</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::analysis::analyzer::simple::SimpleAnalyzer;
use laurus::analysis::tokenizer::regex::RegexTokenizer;
use std::sync::Arc;

let tokenizer = Arc::new(RegexTokenizer::new()?);
let analyzer = SimpleAnalyzer::new(tokenizer);
// "Hello World" → ["Hello", "World"]
// (no lowercasing, no stop word removal)
<span class="boring">}</span></code></pre></pre>
<p>Use this for testing tokenizers, or when you want to apply token filters manually in a separate step.</p>
<h3 id="englishanalyzer"><a class="header" href="#englishanalyzer">EnglishAnalyzer</a></h3>
<p>An English-specific analyzer. Tokenizes, lowercases, and removes common English stop words.</p>
<p>Pipeline: <code>RegexTokenizer</code> (Unicode word boundaries) → <code>LowercaseFilter</code> → <code>StopFilter</code> (128 common English stop words)</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::analysis::analyzer::language::english::EnglishAnalyzer;

let analyzer = EnglishAnalyzer::new()?;
// "The Quick Brown Fox" → ["quick", "brown", "fox"]
// ("The" is removed by stop word filtering, remaining tokens are lowercased)
<span class="boring">}</span></code></pre></pre>
<h3 id="pipelineanalyzer"><a class="header" href="#pipelineanalyzer">PipelineAnalyzer</a></h3>
<p>Build a custom pipeline by combining any char filters, a tokenizer, and any sequence of token filters:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::analysis::analyzer::pipeline::PipelineAnalyzer;
use laurus::analysis::char_filter::unicode_normalize::{
    NormalizationForm, UnicodeNormalizationCharFilter,
};
use laurus::analysis::tokenizer::regex::RegexTokenizer;
use laurus::analysis::token_filter::lowercase::LowercaseFilter;
use laurus::analysis::token_filter::stop::StopFilter;
use laurus::analysis::token_filter::stem::StemFilter;

let analyzer = PipelineAnalyzer::new(Arc::new(RegexTokenizer::new()?))
    .add_char_filter(Arc::new(UnicodeNormalizationCharFilter::new(NormalizationForm::NFKC)))
    .add_filter(Arc::new(LowercaseFilter::new()))
    .add_filter(Arc::new(StopFilter::new()))
    .add_filter(Arc::new(StemFilter::new()));  // Porter stemmer
<span class="boring">}</span></code></pre></pre>
<h2 id="perfieldanalyzer"><a class="header" href="#perfieldanalyzer">PerFieldAnalyzer</a></h2>
<p><code>PerFieldAnalyzer</code> lets you assign different analyzers to different fields within the same engine:</p>
<pre><code class="language-mermaid">graph LR
    PFA["PerFieldAnalyzer"]
    PFA --&gt;|"title"| KW["KeywordAnalyzer"]
    PFA --&gt;|"body"| STD["StandardAnalyzer"]
    PFA --&gt;|"description_ja"| JP["JapaneseAnalyzer"]
    PFA --&gt;|other fields| DEF["Default\n(StandardAnalyzer)"]
</code></pre>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use std::sync::Arc;
use laurus::analysis::analyzer::standard::StandardAnalyzer;
use laurus::analysis::analyzer::keyword::KeywordAnalyzer;
use laurus::analysis::analyzer::per_field::PerFieldAnalyzer;

// Default analyzer for fields not explicitly configured
let mut per_field = PerFieldAnalyzer::new(
    Arc::new(StandardAnalyzer::default())
);

// Use KeywordAnalyzer for exact-match fields
per_field.add_analyzer("category", Arc::new(KeywordAnalyzer::new()));
per_field.add_analyzer("status", Arc::new(KeywordAnalyzer::new()));

let engine = Engine::builder(storage, schema)
    .analyzer(Arc::new(per_field))
    .build()
    .await?;
<span class="boring">}</span></code></pre></pre>
<blockquote>
<p><strong>Note:</strong> The <code>_id</code> field is always analyzed with <code>KeywordAnalyzer</code> regardless of configuration.</p>
</blockquote>
<h2 id="char-filters"><a class="header" href="#char-filters">Char Filters</a></h2>
<p>Char filters operate on the raw input text <strong>before</strong> it reaches the tokenizer. They perform character-level normalization such as Unicode normalization, character mapping, and pattern-based replacement. This ensures that the tokenizer receives clean, normalized text.</p>
<p>All char filters implement the <code>CharFilter</code> trait:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub trait CharFilter: Send + Sync {
    fn filter(&amp;self, input: &amp;str) -&gt; (String, Vec&lt;Transformation&gt;);
    fn name(&amp;self) -&gt; &amp;'static str;
}
<span class="boring">}</span></code></pre></pre>
<p>The <code>Transformation</code> records describe how character positions shifted, allowing the engine to map token positions back to the original text.</p>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Char Filter</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>UnicodeNormalizationCharFilter</code></td><td style="text-align: left">Unicode normalization (NFC, NFD, NFKC, NFKD)</td></tr>
<tr><td style="text-align: left"><code>MappingCharFilter</code></td><td style="text-align: left">Replaces character sequences based on a mapping dictionary</td></tr>
<tr><td style="text-align: left"><code>PatternReplaceCharFilter</code></td><td style="text-align: left">Replaces characters matching a regex pattern</td></tr>
<tr><td style="text-align: left"><code>JapaneseIterationMarkCharFilter</code></td><td style="text-align: left">Expands Japanese iteration marks (踊り字) to their base characters</td></tr>
</tbody></table>
</div>
<h3 id="unicodenormalizationcharfilter"><a class="header" href="#unicodenormalizationcharfilter">UnicodeNormalizationCharFilter</a></h3>
<p>Applies Unicode normalization to the input text. NFKC is recommended for search use cases because it normalizes both compatibility characters and composed forms.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::analysis::char_filter::unicode_normalize::{
    NormalizationForm, UnicodeNormalizationCharFilter,
};

let filter = UnicodeNormalizationCharFilter::new(NormalizationForm::NFKC);
// "Ｓｏｎｙ" (fullwidth) → "Sony" (halfwidth)
// "㌂" → "アンペア"
<span class="boring">}</span></code></pre></pre>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Form</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left">NFC</td><td style="text-align: left">Canonical decomposition followed by canonical composition</td></tr>
<tr><td style="text-align: left">NFD</td><td style="text-align: left">Canonical decomposition</td></tr>
<tr><td style="text-align: left">NFKC</td><td style="text-align: left">Compatibility decomposition followed by canonical composition</td></tr>
<tr><td style="text-align: left">NFKD</td><td style="text-align: left">Compatibility decomposition</td></tr>
</tbody></table>
</div>
<h3 id="mappingcharfilter"><a class="header" href="#mappingcharfilter">MappingCharFilter</a></h3>
<p>Replaces character sequences using a dictionary. Matches are found using the Aho-Corasick algorithm (leftmost-longest match).</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use std::collections::HashMap;
use laurus::analysis::char_filter::mapping::MappingCharFilter;

let mut mapping = HashMap::new();
mapping.insert("ph".to_string(), "f".to_string());
mapping.insert("qu".to_string(), "k".to_string());

let filter = MappingCharFilter::new(mapping)?;
// "phone queue" → "fone keue"
<span class="boring">}</span></code></pre></pre>
<h3 id="patternreplacecharfilter"><a class="header" href="#patternreplacecharfilter">PatternReplaceCharFilter</a></h3>
<p>Replaces all occurrences of a regex pattern with a fixed string.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::analysis::char_filter::pattern_replace::PatternReplaceCharFilter;

// Remove hyphens
let filter = PatternReplaceCharFilter::new(r"-", "")?;
// "123-456-789" → "123456789"

// Normalize numbers
let filter = PatternReplaceCharFilter::new(r"\d+", "NUM")?;
// "Year 2024" → "Year NUM"
<span class="boring">}</span></code></pre></pre>
<h3 id="japaneseiterationmarkcharfilter"><a class="header" href="#japaneseiterationmarkcharfilter">JapaneseIterationMarkCharFilter</a></h3>
<p>Expands Japanese iteration marks (踊り字) to their base characters. Supports kanji (<code>々</code>), hiragana (<code>ゝ</code>, <code>ゞ</code>), and katakana (<code>ヽ</code>, <code>ヾ</code>) iteration marks.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::analysis::char_filter::japanese_iteration_mark::JapaneseIterationMarkCharFilter;

let filter = JapaneseIterationMarkCharFilter::new(
    true,  // normalize kanji iteration marks
    true,  // normalize kana iteration marks
);
// "佐々木" → "佐佐木"
// "いすゞ" → "いすず"
<span class="boring">}</span></code></pre></pre>
<h3 id="using-char-filters-in-a-pipeline"><a class="header" href="#using-char-filters-in-a-pipeline">Using Char Filters in a Pipeline</a></h3>
<p>Add char filters to a <code>PipelineAnalyzer</code> with <code>add_char_filter()</code>. Multiple char filters are applied in the order they are added, all before the tokenizer runs.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use std::sync::Arc;
use laurus::analysis::analyzer::pipeline::PipelineAnalyzer;
use laurus::analysis::char_filter::unicode_normalize::{
    NormalizationForm, UnicodeNormalizationCharFilter,
};
use laurus::analysis::char_filter::pattern_replace::PatternReplaceCharFilter;
use laurus::analysis::tokenizer::regex::RegexTokenizer;
use laurus::analysis::token_filter::lowercase::LowercaseFilter;

let analyzer = PipelineAnalyzer::new(Arc::new(RegexTokenizer::new()?))
    .add_char_filter(Arc::new(
        UnicodeNormalizationCharFilter::new(NormalizationForm::NFKC),
    ))
    .add_char_filter(Arc::new(
        PatternReplaceCharFilter::new(r"-", "")?,
    ))
    .add_filter(Arc::new(LowercaseFilter::new()));
// "Ｔｏｋｙｏ-2024" → NFKC → "Tokyo-2024" → remove hyphens → "Tokyo2024" → tokenize → lowercase → ["tokyo2024"]
<span class="boring">}</span></code></pre></pre>
<h2 id="tokenizers"><a class="header" href="#tokenizers">Tokenizers</a></h2>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Tokenizer</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>RegexTokenizer</code></td><td style="text-align: left">Unicode word boundaries; splits on whitespace and punctuation</td></tr>
<tr><td style="text-align: left"><code>UnicodeWordTokenizer</code></td><td style="text-align: left">Splits on Unicode word boundaries</td></tr>
<tr><td style="text-align: left"><code>WhitespaceTokenizer</code></td><td style="text-align: left">Splits on whitespace only</td></tr>
<tr><td style="text-align: left"><code>WholeTokenizer</code></td><td style="text-align: left">Returns the entire input as a single token</td></tr>
<tr><td style="text-align: left"><code>LinderaTokenizer</code></td><td style="text-align: left">Japanese morphological analysis (Lindera/MeCab)</td></tr>
<tr><td style="text-align: left"><code>NgramTokenizer</code></td><td style="text-align: left">Generates n-gram tokens of configurable size</td></tr>
</tbody></table>
</div>
<h2 id="token-filters"><a class="header" href="#token-filters">Token Filters</a></h2>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Filter</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>LowercaseFilter</code></td><td style="text-align: left">Converts tokens to lowercase</td></tr>
<tr><td style="text-align: left"><code>StopFilter</code></td><td style="text-align: left">Removes common words ("the", "is", "a")</td></tr>
<tr><td style="text-align: left"><code>StemFilter</code></td><td style="text-align: left">Reduces words to their root form ("running" → "run")</td></tr>
<tr><td style="text-align: left"><code>SynonymGraphFilter</code></td><td style="text-align: left">Expands tokens with synonyms from a dictionary</td></tr>
<tr><td style="text-align: left"><code>BoostFilter</code></td><td style="text-align: left">Adjusts token boost values</td></tr>
<tr><td style="text-align: left"><code>LimitFilter</code></td><td style="text-align: left">Limits the number of tokens</td></tr>
<tr><td style="text-align: left"><code>StripFilter</code></td><td style="text-align: left">Strips leading/trailing whitespace from tokens</td></tr>
<tr><td style="text-align: left"><code>FlattenGraphFilter</code></td><td style="text-align: left">Flattens token graphs (for synonym expansion)</td></tr>
<tr><td style="text-align: left"><code>RemoveEmptyFilter</code></td><td style="text-align: left">Removes empty tokens</td></tr>
</tbody></table>
</div>
<h3 id="synonym-expansion"><a class="header" href="#synonym-expansion">Synonym Expansion</a></h3>
<p>The <code>SynonymGraphFilter</code> expands terms using a synonym dictionary:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::analysis::synonym::dictionary::SynonymDictionary;
use laurus::analysis::token_filter::synonym_graph::SynonymGraphFilter;

let mut dict = SynonymDictionary::new(None)?;
dict.add_synonym_group(vec!["ml".into(), "machine learning".into()]);
dict.add_synonym_group(vec!["ai".into(), "artificial intelligence".into()]);

// keep_original=true means original token is preserved alongside synonyms
let filter = SynonymGraphFilter::new(dict, true)
    .with_boost(0.8);  // synonyms get 80% weight
<span class="boring">}</span></code></pre></pre>
<p>The <code>boost</code> parameter controls how much weight synonyms receive relative to original tokens. A value of <code>0.8</code> means synonym matches contribute 80% as much to the score as exact matches.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="embeddings-1"><a class="header" href="#embeddings-1">Embeddings</a></h1>
<p>Embeddings convert text (or images) into dense numeric vectors that capture semantic meaning. Two texts with similar meanings produce vectors that are close together in vector space, enabling similarity-based search.</p>
<h2 id="the-embedder-trait"><a class="header" href="#the-embedder-trait">The Embedder Trait</a></h2>
<p>All embedders implement the <code>Embedder</code> trait:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[async_trait]
pub trait Embedder: Send + Sync + Debug {
    async fn embed(&amp;self, input: &amp;EmbedInput&lt;'_&gt;) -&gt; Result&lt;Vector&gt;;
    async fn embed_batch(&amp;self, inputs: &amp;[EmbedInput&lt;'_&gt;]) -&gt; Result&lt;Vec&lt;Vector&gt;&gt;;
    fn supported_input_types(&amp;self) -&gt; Vec&lt;EmbedInputType&gt;;
    fn name(&amp;self) -&gt; &amp;str;
    fn as_any(&amp;self) -&gt; &amp;dyn Any;
}
<span class="boring">}</span></code></pre></pre>
<p>The <code>embed()</code> method returns a <code>Vector</code> (a struct wrapping <code>Vec&lt;f32&gt;</code>).</p>
<p><code>EmbedInput</code> supports two modalities:</p>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Variant</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>EmbedInput::Text(&amp;str)</code></td><td style="text-align: left">Text input</td></tr>
<tr><td style="text-align: left"><code>EmbedInput::Bytes(&amp;[u8], Option&lt;&amp;str&gt;)</code></td><td style="text-align: left">Binary input with optional MIME type (for images)</td></tr>
</tbody></table>
</div>
<h2 id="built-in-embedders"><a class="header" href="#built-in-embedders">Built-in Embedders</a></h2>
<h3 id="candlebertembedder"><a class="header" href="#candlebertembedder">CandleBertEmbedder</a></h3>
<p>Runs a BERT model locally using Hugging Face Candle. No API key required.</p>
<p><strong>Feature flag:</strong> <code>embeddings-candle</code></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::CandleBertEmbedder;

// Downloads model on first run (~80MB)
let embedder = CandleBertEmbedder::new(
    "sentence-transformers/all-MiniLM-L6-v2"  // model name
)?;
// Output: 384-dimensional vector
<span class="boring">}</span></code></pre></pre>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Property</th><th style="text-align: left">Value</th></tr></thead><tbody>
<tr><td style="text-align: left">Model</td><td style="text-align: left"><code>sentence-transformers/all-MiniLM-L6-v2</code></td></tr>
<tr><td style="text-align: left">Dimensions</td><td style="text-align: left">384</td></tr>
<tr><td style="text-align: left">Runtime</td><td style="text-align: left">Local (CPU)</td></tr>
<tr><td style="text-align: left">First-run download</td><td style="text-align: left">~80 MB</td></tr>
</tbody></table>
</div>
<h3 id="openaiembedder"><a class="header" href="#openaiembedder">OpenAIEmbedder</a></h3>
<p>Calls the OpenAI Embeddings API. Requires an API key.</p>
<p><strong>Feature flag:</strong> <code>embeddings-openai</code></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::OpenAIEmbedder;

let embedder = OpenAIEmbedder::new(
    api_key,
    "text-embedding-3-small".to_string()
).await?;
// Output: 1536-dimensional vector
<span class="boring">}</span></code></pre></pre>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Property</th><th style="text-align: left">Value</th></tr></thead><tbody>
<tr><td style="text-align: left">Model</td><td style="text-align: left"><code>text-embedding-3-small</code> (or any OpenAI model)</td></tr>
<tr><td style="text-align: left">Dimensions</td><td style="text-align: left">1536 (for text-embedding-3-small)</td></tr>
<tr><td style="text-align: left">Runtime</td><td style="text-align: left">Remote API call</td></tr>
<tr><td style="text-align: left">Requires</td><td style="text-align: left"><code>OPENAI_API_KEY</code> environment variable</td></tr>
</tbody></table>
</div>
<h3 id="candleclipembedder"><a class="header" href="#candleclipembedder">CandleClipEmbedder</a></h3>
<p>Runs a CLIP model locally for multimodal (text + image) embeddings.</p>
<p><strong>Feature flag:</strong> <code>embeddings-multimodal</code></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::CandleClipEmbedder;

let embedder = CandleClipEmbedder::new(
    "openai/clip-vit-base-patch32"
)?;
// Text or images → 512-dimensional vector
<span class="boring">}</span></code></pre></pre>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Property</th><th style="text-align: left">Value</th></tr></thead><tbody>
<tr><td style="text-align: left">Model</td><td style="text-align: left"><code>openai/clip-vit-base-patch32</code></td></tr>
<tr><td style="text-align: left">Dimensions</td><td style="text-align: left">512</td></tr>
<tr><td style="text-align: left">Input types</td><td style="text-align: left">Text AND images</td></tr>
<tr><td style="text-align: left">Use case</td><td style="text-align: left">Text-to-image search, image-to-image search</td></tr>
</tbody></table>
</div>
<h3 id="precomputedembedder"><a class="header" href="#precomputedembedder">PrecomputedEmbedder</a></h3>
<p>Use pre-computed vectors directly without any embedding computation. Useful when vectors are generated externally.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::PrecomputedEmbedder;

let embedder = PrecomputedEmbedder::new();  // no parameters needed
<span class="boring">}</span></code></pre></pre>
<p>When using <code>PrecomputedEmbedder</code>, you provide vectors directly in documents instead of text for embedding:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let doc = Document::builder()
    .add_vector("embedding", vec![0.1, 0.2, 0.3, ...])
    .build();
<span class="boring">}</span></code></pre></pre>
<h2 id="perfieldembedder"><a class="header" href="#perfieldembedder">PerFieldEmbedder</a></h2>
<p><code>PerFieldEmbedder</code> routes embedding requests to field-specific embedders:</p>
<pre><code class="language-mermaid">graph LR
    PFE["PerFieldEmbedder"]
    PFE --&gt;|"text_vec"| BERT["CandleBertEmbedder\n(384 dim)"]
    PFE --&gt;|"image_vec"| CLIP["CandleClipEmbedder\n(512 dim)"]
    PFE --&gt;|other fields| DEF["Default Embedder"]
</code></pre>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use std::sync::Arc;
use laurus::PerFieldEmbedder;

let bert = Arc::new(CandleBertEmbedder::new("...")?);
let clip = Arc::new(CandleClipEmbedder::new("...")?);


let mut per_field = PerFieldEmbedder::new(bert.clone());
per_field.add_embedder("text_vec", bert.clone());
per_field.add_embedder("image_vec", clip.clone());

let engine = Engine::builder(storage, schema)
    .embedder(Arc::new(per_field))
    .build()
    .await?;
<span class="boring">}</span></code></pre></pre>
<p>This is especially useful when:</p>
<ul>
<li>Different vector fields need different models (e.g., BERT for text, CLIP for images)</li>
<li>Different fields have different vector dimensions</li>
<li>You want to mix local and remote embedders</li>
</ul>
<h2 id="how-embeddings-are-used"><a class="header" href="#how-embeddings-are-used">How Embeddings Are Used</a></h2>
<h3 id="at-index-time"><a class="header" href="#at-index-time">At Index Time</a></h3>
<p>When you add a text value to a vector field, the engine automatically embeds it:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let doc = Document::builder()
    .add_text("text_vec", "Rust is a systems programming language")
    .build();
engine.add_document("doc-1", doc).await?;
// The embedder converts the text to a vector before indexing
<span class="boring">}</span></code></pre></pre>
<h3 id="at-search-time"><a class="header" href="#at-search-time">At Search Time</a></h3>
<p>When you search with text, the engine embeds the query text as well:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Builder API
let request = VectorSearchRequestBuilder::new()
    .add_text("text_vec", "systems programming")
    .build();

// Query DSL
let request = vector_parser.parse(r#"text_vec:~"systems programming""#).await?;
<span class="boring">}</span></code></pre></pre>
<p>Both approaches embed the query text using the same embedder that was used at index time, ensuring consistent vector spaces.</p>
<h2 id="choosing-an-embedder"><a class="header" href="#choosing-an-embedder">Choosing an Embedder</a></h2>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Scenario</th><th style="text-align: left">Recommended Embedder</th></tr></thead><tbody>
<tr><td style="text-align: left">Quick prototyping, offline use</td><td style="text-align: left"><code>CandleBertEmbedder</code></td></tr>
<tr><td style="text-align: left">Production with high accuracy</td><td style="text-align: left"><code>OpenAIEmbedder</code></td></tr>
<tr><td style="text-align: left">Text + image search</td><td style="text-align: left"><code>CandleClipEmbedder</code></td></tr>
<tr><td style="text-align: left">Pre-computed vectors from external pipeline</td><td style="text-align: left"><code>PrecomputedEmbedder</code></td></tr>
<tr><td style="text-align: left">Multiple models per field</td><td style="text-align: left"><code>PerFieldEmbedder</code> wrapping others</td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><h1 id="storage-1"><a class="header" href="#storage-1">Storage</a></h1>
<p>Laurus uses a pluggable storage layer that abstracts how and where index data is persisted. All components — lexical index, vector index, and document log — share a single storage backend.</p>
<h2 id="the-storage-trait"><a class="header" href="#the-storage-trait">The Storage Trait</a></h2>
<p>All backends implement the <code>Storage</code> trait:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub trait Storage: Send + Sync + Debug {
    fn loading_mode(&amp;self) -&gt; LoadingMode;
    fn open_input(&amp;self, name: &amp;str) -&gt; Result&lt;Box&lt;dyn StorageInput&gt;&gt;;
    fn create_output(&amp;self, name: &amp;str) -&gt; Result&lt;Box&lt;dyn StorageOutput&gt;&gt;;
    fn file_exists(&amp;self, name: &amp;str) -&gt; bool;
    fn delete_file(&amp;self, name: &amp;str) -&gt; Result&lt;()&gt;;
    fn list_files(&amp;self) -&gt; Result&lt;Vec&lt;String&gt;&gt;;
    fn file_size(&amp;self, name: &amp;str) -&gt; Result&lt;u64&gt;;
    // ... additional methods
}
<span class="boring">}</span></code></pre></pre>
<p>This interface is file-oriented: all data (index segments, metadata, WAL entries, documents) is stored as named files accessed through streaming <code>StorageInput</code> / <code>StorageOutput</code> handles.</p>
<h2 id="storage-backends"><a class="header" href="#storage-backends">Storage Backends</a></h2>
<h3 id="memorystorage"><a class="header" href="#memorystorage">MemoryStorage</a></h3>
<p>All data lives in memory. Fast and simple, but not durable.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use std::sync::Arc;
use laurus::Storage;
use laurus::storage::memory::MemoryStorage;

let storage: Arc&lt;dyn Storage&gt; = Arc::new(
    MemoryStorage::new(Default::default())
);
<span class="boring">}</span></code></pre></pre>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Property</th><th style="text-align: left">Value</th></tr></thead><tbody>
<tr><td style="text-align: left">Durability</td><td style="text-align: left">None (data lost on process exit)</td></tr>
<tr><td style="text-align: left">Speed</td><td style="text-align: left">Fastest</td></tr>
<tr><td style="text-align: left">Use case</td><td style="text-align: left">Testing, prototyping, ephemeral data</td></tr>
</tbody></table>
</div>
<h3 id="filestorage"><a class="header" href="#filestorage">FileStorage</a></h3>
<p>Standard file-system based persistence. Each key maps to a file on disk.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use std::sync::Arc;
use laurus::Storage;
use laurus::storage::file::{FileStorage, FileStorageConfig};

let config = FileStorageConfig::new("/tmp/laurus-data");
let storage: Arc&lt;dyn Storage&gt; = Arc::new(FileStorage::new("/tmp/laurus-data", config)?);
<span class="boring">}</span></code></pre></pre>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Property</th><th style="text-align: left">Value</th></tr></thead><tbody>
<tr><td style="text-align: left">Durability</td><td style="text-align: left">Full (persisted to disk)</td></tr>
<tr><td style="text-align: left">Speed</td><td style="text-align: left">Moderate (disk I/O)</td></tr>
<tr><td style="text-align: left">Use case</td><td style="text-align: left">General production use</td></tr>
</tbody></table>
</div>
<h3 id="filestorage-with-memory-mapping"><a class="header" href="#filestorage-with-memory-mapping">FileStorage with Memory Mapping</a></h3>
<p><code>FileStorage</code> supports memory-mapped file access via the <code>use_mmap</code> configuration flag. When enabled, the OS manages paging between memory and disk.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use std::sync::Arc;
use laurus::Storage;
use laurus::storage::file::{FileStorage, FileStorageConfig};

let mut config = FileStorageConfig::new("/tmp/laurus-data");
config.use_mmap = true;  // enable memory-mapped I/O
let storage: Arc&lt;dyn Storage&gt; = Arc::new(FileStorage::new("/tmp/laurus-data", config)?);
<span class="boring">}</span></code></pre></pre>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Property</th><th style="text-align: left">Value</th></tr></thead><tbody>
<tr><td style="text-align: left">Durability</td><td style="text-align: left">Full (persisted to disk)</td></tr>
<tr><td style="text-align: left">Speed</td><td style="text-align: left">Fast (OS-managed memory mapping)</td></tr>
<tr><td style="text-align: left">Use case</td><td style="text-align: left">Large datasets, read-heavy workloads</td></tr>
</tbody></table>
</div>
<h2 id="storagefactory"><a class="header" href="#storagefactory">StorageFactory</a></h2>
<p>You can also create storage via configuration:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::storage::{StorageConfig, StorageFactory};
use laurus::storage::memory::MemoryStorageConfig;

let storage = StorageFactory::create(
    StorageConfig::Memory(MemoryStorageConfig::default())
)?;
<span class="boring">}</span></code></pre></pre>
<h2 id="prefixedstorage"><a class="header" href="#prefixedstorage">PrefixedStorage</a></h2>
<p>The engine uses <code>PrefixedStorage</code> to isolate components within a single storage backend:</p>
<pre><code class="language-mermaid">graph TB
    E["Engine"]
    E --&gt; P1["PrefixedStorage\nprefix = 'lexical/'"]
    E --&gt; P2["PrefixedStorage\nprefix = 'vector/'"]
    E --&gt; P3["PrefixedStorage\nprefix = 'documents/'"]
    P1 --&gt; S["Storage Backend"]
    P2 --&gt; S
    P3 --&gt; S
</code></pre>
<p>When the lexical store writes a key <code>segments/seg-001.dict</code>, it is actually stored as <code>lexical/segments/seg-001.dict</code> in the underlying backend. This ensures no key collisions between components.</p>
<p>You do not need to create <code>PrefixedStorage</code> yourself — the <code>EngineBuilder</code> handles this automatically.</p>
<h2 id="choosing-a-backend"><a class="header" href="#choosing-a-backend">Choosing a Backend</a></h2>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Factor</th><th style="text-align: left">MemoryStorage</th><th style="text-align: left">FileStorage</th><th style="text-align: left">FileStorage (mmap)</th></tr></thead><tbody>
<tr><td style="text-align: left"><strong>Durability</strong></td><td style="text-align: left">None</td><td style="text-align: left">Full</td><td style="text-align: left">Full</td></tr>
<tr><td style="text-align: left"><strong>Read speed</strong></td><td style="text-align: left">Fastest</td><td style="text-align: left">Moderate</td><td style="text-align: left">Fast</td></tr>
<tr><td style="text-align: left"><strong>Write speed</strong></td><td style="text-align: left">Fastest</td><td style="text-align: left">Moderate</td><td style="text-align: left">Moderate</td></tr>
<tr><td style="text-align: left"><strong>Memory usage</strong></td><td style="text-align: left">Proportional to data size</td><td style="text-align: left">Low</td><td style="text-align: left">OS-managed</td></tr>
<tr><td style="text-align: left"><strong>Max data size</strong></td><td style="text-align: left">Limited by RAM</td><td style="text-align: left">Limited by disk</td><td style="text-align: left">Limited by disk + address space</td></tr>
<tr><td style="text-align: left"><strong>Best for</strong></td><td style="text-align: left">Tests, small datasets</td><td style="text-align: left">General use</td><td style="text-align: left">Large read-heavy datasets</td></tr>
</tbody></table>
</div>
<h3 id="recommendations"><a class="header" href="#recommendations">Recommendations</a></h3>
<ul>
<li><strong>Development / Testing</strong>: Use <code>MemoryStorage</code> for fast iteration without file cleanup</li>
<li><strong>Production (general)</strong>: Use <code>FileStorage</code> for reliable persistence</li>
<li><strong>Production (large scale)</strong>: Use <code>FileStorage</code> with <code>use_mmap = true</code> when you have large indexes and want to leverage OS page cache</li>
</ul>
<h2 id="next-steps-1"><a class="header" href="#next-steps-1">Next Steps</a></h2>
<ul>
<li>Learn how the lexical index works: <a href="concepts/../indexing/lexical_indexing.html">Lexical Indexing</a></li>
<li>Learn how the vector index works: <a href="concepts/../indexing/vector_indexing.html">Vector Indexing</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="indexing"><a class="header" href="#indexing">Indexing</a></h1>
<p>This section explains how Laurus stores and organizes data internally. Understanding the indexing layer will help you choose the right field types and tune performance.</p>
<h2 id="topics-1"><a class="header" href="#topics-1">Topics</a></h2>
<h3 id="lexical-indexing"><a class="header" href="#lexical-indexing"><a href="indexing/lexical_indexing.html">Lexical Indexing</a></a></h3>
<p>How text, numeric, and geographic fields are indexed using an inverted index. Covers:</p>
<ul>
<li>The inverted index structure (term dictionary, posting lists)</li>
<li>BKD trees for numeric range queries</li>
<li>Segment files and their formats</li>
<li>BM25 scoring</li>
</ul>
<h3 id="vector-indexing"><a class="header" href="#vector-indexing"><a href="indexing/vector_indexing.html">Vector Indexing</a></a></h3>
<p>How vector fields are indexed for approximate nearest neighbor search. Covers:</p>
<ul>
<li>Index types: Flat, HNSW, IVF</li>
<li>Parameter tuning (m, ef_construction, n_clusters, n_probe)</li>
<li>Distance metrics (Cosine, Euclidean, DotProduct)</li>
<li>Quantization (SQ8, PQ)</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="lexical-indexing-1"><a class="header" href="#lexical-indexing-1">Lexical Indexing</a></h1>
<p>Lexical indexing powers keyword-based search. When a document's text field is indexed, Laurus builds an <strong>inverted index</strong> — a data structure that maps terms to the documents containing them.</p>
<h2 id="how-lexical-indexing-works"><a class="header" href="#how-lexical-indexing-works">How Lexical Indexing Works</a></h2>
<pre><code class="language-mermaid">sequenceDiagram
    participant Doc as Document
    participant Analyzer
    participant Writer as IndexWriter
    participant Seg as Segment

    Doc-&gt;&gt;Analyzer: "The quick brown fox"
    Analyzer-&gt;&gt;Analyzer: Tokenize + Filter
    Analyzer--&gt;&gt;Writer: ["quick", "brown", "fox"]
    Writer-&gt;&gt;Writer: Buffer in memory
    Writer-&gt;&gt;Seg: Flush to segment on commit()
</code></pre>
<h3 id="step-by-step"><a class="header" href="#step-by-step">Step by Step</a></h3>
<ol>
<li><strong>Analyze</strong>: The text passes through the configured analyzer (tokenizer + filters), producing a stream of normalized terms</li>
<li><strong>Buffer</strong>: Terms are stored in an in-memory write buffer, organized by field</li>
<li><strong>Commit</strong>: On <code>commit()</code>, the buffer is flushed to a new segment on storage</li>
</ol>
<h2 id="the-inverted-index"><a class="header" href="#the-inverted-index">The Inverted Index</a></h2>
<p>An inverted index is essentially a map from terms to document lists:</p>
<pre><code class="language-mermaid">graph LR
    subgraph "Term Dictionary"
        T1["'brown'"]
        T2["'fox'"]
        T3["'quick'"]
        T4["'rust'"]
    end

    subgraph "Posting Lists"
        P1["doc_1, doc_3"]
        P2["doc_1"]
        P3["doc_1, doc_2"]
        P4["doc_2, doc_3"]
    end

    T1 --&gt; P1
    T2 --&gt; P2
    T3 --&gt; P3
    T4 --&gt; P4
</code></pre>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Component</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><strong>Term Dictionary</strong></td><td style="text-align: left">Sorted list of all unique terms in the index; supports fast prefix lookup</td></tr>
<tr><td style="text-align: left"><strong>Posting Lists</strong></td><td style="text-align: left">For each term, a list of document IDs and metadata (term frequency, positions)</td></tr>
<tr><td style="text-align: left"><strong>Doc Values</strong></td><td style="text-align: left">Column-oriented storage for sort/filter operations on numeric and date fields</td></tr>
</tbody></table>
</div>
<h3 id="posting-list-contents"><a class="header" href="#posting-list-contents">Posting List Contents</a></h3>
<p>Each entry in a posting list contains:</p>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Field</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left">Document ID</td><td style="text-align: left">Internal <code>u64</code> identifier</td></tr>
<tr><td style="text-align: left">Term Frequency</td><td style="text-align: left">How many times the term appears in this document</td></tr>
<tr><td style="text-align: left">Positions (optional)</td><td style="text-align: left">Where in the document the term appears (needed for phrase queries)</td></tr>
<tr><td style="text-align: left">Weight</td><td style="text-align: left">Score weight for this posting</td></tr>
</tbody></table>
</div>
<h2 id="numeric-and-date-fields"><a class="header" href="#numeric-and-date-fields">Numeric and Date Fields</a></h2>
<p>Integer, float, and datetime fields are indexed using a <strong>BKD tree</strong> — a space-partitioning data structure optimized for range queries:</p>
<pre><code class="language-mermaid">graph TB
    Root["BKD Root"]
    Root --&gt; L["values &lt; 50"]
    Root --&gt; R["values &gt;= 50"]
    L --&gt; LL["values &lt; 25"]
    L --&gt; LR["25 &lt;= values &lt; 50"]
    R --&gt; RL["50 &lt;= values &lt; 75"]
    R --&gt; RR["values &gt;= 75"]
</code></pre>
<p>BKD trees allow efficient evaluation of range queries like <code>price:[10 TO 100]</code> or <code>date:[2024-01-01 TO 2024-12-31]</code>.</p>
<h2 id="geo-fields"><a class="header" href="#geo-fields">Geo Fields</a></h2>
<p>Geographic fields store latitude/longitude pairs. They are indexed using a spatial data structure that supports:</p>
<ul>
<li><strong>Radius queries</strong>: find all points within N kilometers of a center point</li>
<li><strong>Bounding box queries</strong>: find all points within a rectangular area</li>
</ul>
<h2 id="segments"><a class="header" href="#segments">Segments</a></h2>
<p>The lexical index is organized into <strong>segments</strong>. Each segment is an immutable, self-contained mini-index:</p>
<pre><code class="language-mermaid">graph TB
    LI["Lexical Index"]
    LI --&gt; S1["Segment 0"]
    LI --&gt; S2["Segment 1"]
    LI --&gt; S3["Segment 2"]

    S1 --- F1[".dict (terms)"]
    S1 --- F2[".post (postings)"]
    S1 --- F3[".bkd (numerics)"]
    S1 --- F4[".docs (doc store)"]
    S1 --- F5[".dv (doc values)"]
    S1 --- F6[".meta (metadata)"]
    S1 --- F7[".lens (field lengths)"]
</code></pre>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">File Extension</th><th style="text-align: left">Contents</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>.dict</code></td><td style="text-align: left">Term dictionary (sorted terms + metadata offsets)</td></tr>
<tr><td style="text-align: left"><code>.post</code></td><td style="text-align: left">Posting lists (document IDs, term frequencies, positions)</td></tr>
<tr><td style="text-align: left"><code>.bkd</code></td><td style="text-align: left">BKD tree data for numeric and date fields</td></tr>
<tr><td style="text-align: left"><code>.docs</code></td><td style="text-align: left">Stored field values (the original document content)</td></tr>
<tr><td style="text-align: left"><code>.dv</code></td><td style="text-align: left">Doc values for sorting and filtering</td></tr>
<tr><td style="text-align: left"><code>.meta</code></td><td style="text-align: left">Segment metadata (doc count, term count, etc.)</td></tr>
<tr><td style="text-align: left"><code>.lens</code></td><td style="text-align: left">Field length norms (for BM25 scoring)</td></tr>
</tbody></table>
</div>
<h3 id="segment-lifecycle"><a class="header" href="#segment-lifecycle">Segment Lifecycle</a></h3>
<ol>
<li><strong>Create</strong>: A new segment is created each time <code>commit()</code> is called</li>
<li><strong>Search</strong>: All segments are searched in parallel and results are merged</li>
<li><strong>Merge</strong>: Periodically, multiple small segments are merged into larger ones to improve query performance</li>
<li><strong>Delete</strong>: When a document is deleted, its ID is added to a deletion bitmap rather than physically removed (see <a href="indexing/../advanced/deletions.html">Deletions &amp; Compaction</a>)</li>
</ol>
<h2 id="bm25-scoring"><a class="header" href="#bm25-scoring">BM25 Scoring</a></h2>
<p>Laurus uses the BM25 algorithm to score lexical search results. BM25 considers:</p>
<ul>
<li><strong>Term Frequency (TF)</strong>: how often the term appears in the document (more = better, with diminishing returns)</li>
<li><strong>Inverse Document Frequency (IDF)</strong>: how rare the term is across all documents (rarer = more important)</li>
<li><strong>Field Length Normalization</strong>: shorter fields are boosted relative to longer ones</li>
</ul>
<p>The formula:</p>
<pre><code>score(q, d) = IDF(q) * (TF(q, d) * (k1 + 1)) / (TF(q, d) + k1 * (1 - b + b * |d| / avgdl))
</code></pre>
<p>Where <code>k1 = 1.2</code> and <code>b = 0.75</code> are the default tuning parameters.</p>
<h2 id="simd-optimization"><a class="header" href="#simd-optimization">SIMD Optimization</a></h2>
<p>Vector distance calculations leverage SIMD (Single Instruction, Multiple Data) instructions when available, providing significant speedups for similarity computations in vector search.</p>
<h2 id="code-example"><a class="header" href="#code-example">Code Example</a></h2>
<pre><pre class="playground"><code class="language-rust">use std::sync::Arc;
use laurus::{Document, Engine, Schema};
use laurus::lexical::TextOption;
use laurus::lexical::core::field::IntegerOption;
use laurus::storage::memory::MemoryStorage;

#[tokio::main]
async fn main() -&gt; laurus::Result&lt;()&gt; {
    let storage = Arc::new(MemoryStorage::new(Default::default()));
    let schema = Schema::builder()
        .add_text_field("title", TextOption::default())
        .add_text_field("body", TextOption::default())
        .add_integer_field("year", IntegerOption::default())
        .build();

    let engine = Engine::builder(storage, schema).build().await?;

    // Index documents
    engine.add_document("doc-1", Document::builder()
        .add_text("title", "Rust Programming")
        .add_text("body", "Rust is a systems programming language.")
        .add_integer("year", 2024)
        .build()
    ).await?;

    // Commit to flush segments to storage
    engine.commit().await?;

    Ok(())
}</code></pre></pre>
<h2 id="next-steps-2"><a class="header" href="#next-steps-2">Next Steps</a></h2>
<ul>
<li>Learn how vector indexes work: <a href="indexing/vector_indexing.html">Vector Indexing</a></li>
<li>Run queries against the lexical index: <a href="indexing/../search/lexical_search.html">Lexical Search</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="vector-indexing-1"><a class="header" href="#vector-indexing-1">Vector Indexing</a></h1>
<p>Vector indexing powers similarity-based search. When a document's vector field is indexed, Laurus stores the embedding vector in a specialized index structure that enables fast approximate nearest neighbor (ANN) retrieval.</p>
<h2 id="how-vector-indexing-works"><a class="header" href="#how-vector-indexing-works">How Vector Indexing Works</a></h2>
<pre><code class="language-mermaid">sequenceDiagram
    participant Doc as Document
    participant Embedder
    participant Normalize as Normalizer
    participant Index as Vector Index

    Doc-&gt;&gt;Embedder: "Rust is a systems language"
    Embedder--&gt;&gt;Normalize: [0.12, -0.45, 0.78, ...]
    Normalize-&gt;&gt;Normalize: L2 normalize
    Normalize--&gt;&gt;Index: [0.14, -0.52, 0.90, ...]
    Index-&gt;&gt;Index: Insert into index structure
</code></pre>
<h3 id="step-by-step-1"><a class="header" href="#step-by-step-1">Step by Step</a></h3>
<ol>
<li><strong>Embed</strong>: The text (or image) is converted to a vector by the configured embedder</li>
<li><strong>Normalize</strong>: The vector is L2-normalized (for cosine similarity)</li>
<li><strong>Index</strong>: The vector is inserted into the configured index structure (Flat, HNSW, or IVF)</li>
<li><strong>Commit</strong>: On <code>commit()</code>, the index is flushed to persistent storage</li>
</ol>
<h2 id="index-types"><a class="header" href="#index-types">Index Types</a></h2>
<p>Laurus supports three vector index types, each with different performance characteristics:</p>
<h3 id="comparison"><a class="header" href="#comparison">Comparison</a></h3>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Property</th><th style="text-align: left">Flat</th><th style="text-align: left">HNSW</th><th style="text-align: left">IVF</th></tr></thead><tbody>
<tr><td style="text-align: left"><strong>Accuracy</strong></td><td style="text-align: left">100% (exact)</td><td style="text-align: left">~95-99% (approximate)</td><td style="text-align: left">~90-98% (approximate)</td></tr>
<tr><td style="text-align: left"><strong>Search speed</strong></td><td style="text-align: left">O(n) linear scan</td><td style="text-align: left">O(log n) graph walk</td><td style="text-align: left">O(n/k) cluster scan</td></tr>
<tr><td style="text-align: left"><strong>Memory usage</strong></td><td style="text-align: left">Low</td><td style="text-align: left">Higher (graph edges)</td><td style="text-align: left">Moderate (centroids)</td></tr>
<tr><td style="text-align: left"><strong>Index build time</strong></td><td style="text-align: left">Fast</td><td style="text-align: left">Moderate</td><td style="text-align: left">Slower (clustering)</td></tr>
<tr><td style="text-align: left"><strong>Best for</strong></td><td style="text-align: left">&lt; 10K vectors</td><td style="text-align: left">10K - 10M vectors</td><td style="text-align: left">&gt; 1M vectors</td></tr>
</tbody></table>
</div>
<h3 id="flat-index"><a class="header" href="#flat-index">Flat Index</a></h3>
<p>The simplest index. Compares the query vector against every stored vector (brute-force).</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::vector::FlatOption;
use laurus::vector::core::distance::DistanceMetric;

let opt = FlatOption {
    dimension: 384,
    distance: DistanceMetric::Cosine,
    ..Default::default()
};
<span class="boring">}</span></code></pre></pre>
<ul>
<li><strong>Pros</strong>: 100% recall (exact results), simple, low memory</li>
<li><strong>Cons</strong>: Slow for large datasets (linear scan)</li>
<li><strong>Use when</strong>: You have fewer than ~10,000 vectors, or you need exact results</li>
</ul>
<h3 id="hnsw-index"><a class="header" href="#hnsw-index">HNSW Index</a></h3>
<p><strong>Hierarchical Navigable Small World</strong> graph. The default and most commonly used index type.</p>
<pre><code class="language-mermaid">graph TB
    subgraph "Layer 2 (sparse)"
        A2["A"] --- C2["C"]
    end

    subgraph "Layer 1 (medium)"
        A1["A"] --- B1["B"]
        A1 --- C1["C"]
        B1 --- D1["D"]
        C1 --- D1
    end

    subgraph "Layer 0 (dense - all vectors)"
        A0["A"] --- B0["B"]
        A0 --- C0["C"]
        B0 --- D0["D"]
        B0 --- E0["E"]
        C0 --- D0
        C0 --- F0["F"]
        D0 --- E0
        E0 --- F0
    end

    A2 -.-&gt;|"entry point"| A1
    A1 -.-&gt; A0
    C2 -.-&gt; C1
    C1 -.-&gt; C0
    B1 -.-&gt; B0
    D1 -.-&gt; D0
</code></pre>
<p>The HNSW algorithm searches from the top (sparse) layer down to the bottom (dense) layer, narrowing the search space at each level.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::vector::HnswOption;
use laurus::vector::core::distance::DistanceMetric;

let opt = HnswOption {
    dimension: 384,
    distance: DistanceMetric::Cosine,
    m: 16,                  // max connections per node per layer
    ef_construction: 200,   // search width during index building
    ..Default::default()
};
<span class="boring">}</span></code></pre></pre>
<h4 id="hnsw-parameters"><a class="header" href="#hnsw-parameters">HNSW Parameters</a></h4>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Parameter</th><th style="text-align: left">Default</th><th style="text-align: left">Description</th><th style="text-align: left">Impact</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>m</code></td><td style="text-align: left">16</td><td style="text-align: left">Max bi-directional connections per layer</td><td style="text-align: left">Higher = better recall, more memory</td></tr>
<tr><td style="text-align: left"><code>ef_construction</code></td><td style="text-align: left">200</td><td style="text-align: left">Search width during index building</td><td style="text-align: left">Higher = better recall, slower build</td></tr>
<tr><td style="text-align: left"><code>dimension</code></td><td style="text-align: left">128</td><td style="text-align: left">Vector dimensions</td><td style="text-align: left">Must match embedder output</td></tr>
<tr><td style="text-align: left"><code>distance</code></td><td style="text-align: left">Cosine</td><td style="text-align: left">Distance metric</td><td style="text-align: left">See Distance Metrics below</td></tr>
</tbody></table>
</div>
<p><strong>Tuning tips:</strong></p>
<ul>
<li>Increase <code>m</code> (e.g., 32 or 64) for higher recall at the cost of memory</li>
<li>Increase <code>ef_construction</code> (e.g., 400) for better index quality at the cost of build time</li>
<li>At search time, the <code>ef_search</code> parameter (set in the search request) controls the search width</li>
</ul>
<h3 id="ivf-index"><a class="header" href="#ivf-index">IVF Index</a></h3>
<p><strong>Inverted File Index</strong>. Partitions vectors into clusters, then only searches relevant clusters.</p>
<pre><code class="language-mermaid">graph TB
    Q["Query Vector"]
    Q --&gt; C1["Cluster 1\n(centroid)"]
    Q --&gt; C2["Cluster 2\n(centroid)"]

    C1 --&gt; V1["vec_3"]
    C1 --&gt; V2["vec_7"]
    C1 --&gt; V3["vec_12"]

    C2 --&gt; V4["vec_1"]
    C2 --&gt; V5["vec_9"]
    C2 --&gt; V6["vec_15"]

    style C1 fill:#f9f,stroke:#333
    style C2 fill:#f9f,stroke:#333
</code></pre>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::vector::IvfOption;
use laurus::vector::core::distance::DistanceMetric;

let opt = IvfOption {
    dimension: 384,
    distance: DistanceMetric::Cosine,
    n_clusters: 100,   // number of clusters
    n_probe: 10,       // clusters to search at query time
    ..Default::default()
};
<span class="boring">}</span></code></pre></pre>
<h4 id="ivf-parameters"><a class="header" href="#ivf-parameters">IVF Parameters</a></h4>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Parameter</th><th style="text-align: left">Default</th><th style="text-align: left">Description</th><th style="text-align: left">Impact</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>n_clusters</code></td><td style="text-align: left">100</td><td style="text-align: left">Number of Voronoi cells</td><td style="text-align: left">More clusters = faster search, lower recall</td></tr>
<tr><td style="text-align: left"><code>n_probe</code></td><td style="text-align: left">1</td><td style="text-align: left">Clusters to search at query time</td><td style="text-align: left">Higher = better recall, slower search</td></tr>
<tr><td style="text-align: left"><code>dimension</code></td><td style="text-align: left">(required)</td><td style="text-align: left">Vector dimensions</td><td style="text-align: left">Must match embedder output</td></tr>
<tr><td style="text-align: left"><code>distance</code></td><td style="text-align: left">Cosine</td><td style="text-align: left">Distance metric</td><td style="text-align: left">See Distance Metrics below</td></tr>
</tbody></table>
</div>
<p><strong>Tuning tips:</strong></p>
<ul>
<li>Set <code>n_clusters</code> to roughly <code>sqrt(n)</code> where <code>n</code> is the number of vectors</li>
<li>Set <code>n_probe</code> to 5-20% of <code>n_clusters</code> for a good recall/speed trade-off</li>
<li>IVF requires a training phase — initial indexing may be slower</li>
</ul>
<h2 id="distance-metrics"><a class="header" href="#distance-metrics">Distance Metrics</a></h2>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Metric</th><th style="text-align: left">Description</th><th style="text-align: left">Range</th><th style="text-align: left">Best For</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>Cosine</code></td><td style="text-align: left">1 - cosine similarity</td><td style="text-align: left">[0, 2]</td><td style="text-align: left">Text embeddings (most common)</td></tr>
<tr><td style="text-align: left"><code>Euclidean</code></td><td style="text-align: left">L2 distance</td><td style="text-align: left">[0, +inf)</td><td style="text-align: left">Spatial data</td></tr>
<tr><td style="text-align: left"><code>Manhattan</code></td><td style="text-align: left">L1 distance</td><td style="text-align: left">[0, +inf)</td><td style="text-align: left">Feature vectors</td></tr>
<tr><td style="text-align: left"><code>DotProduct</code></td><td style="text-align: left">Negative inner product</td><td style="text-align: left">(-inf, +inf)</td><td style="text-align: left">Pre-normalized vectors</td></tr>
<tr><td style="text-align: left"><code>Angular</code></td><td style="text-align: left">Angular distance</td><td style="text-align: left">[0, pi]</td><td style="text-align: left">Directional similarity</td></tr>
</tbody></table>
</div>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::vector::core::distance::DistanceMetric;

let metric = DistanceMetric::Cosine;      // Default for text
let metric = DistanceMetric::Euclidean;    // For spatial data
let metric = DistanceMetric::Manhattan;    // L1 distance
let metric = DistanceMetric::DotProduct;   // For pre-normalized vectors
let metric = DistanceMetric::Angular;      // Angular distance
<span class="boring">}</span></code></pre></pre>
<blockquote>
<p><strong>Note:</strong> For cosine similarity, vectors are automatically L2-normalized before indexing. Lower distance = more similar.</p>
</blockquote>
<h2 id="quantization"><a class="header" href="#quantization">Quantization</a></h2>
<p>Quantization reduces memory usage by compressing vectors at the cost of some accuracy:</p>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Method</th><th style="text-align: left">Enum Variant</th><th style="text-align: left">Description</th><th style="text-align: left">Memory Reduction</th></tr></thead><tbody>
<tr><td style="text-align: left"><strong>Scalar 8-bit</strong></td><td style="text-align: left"><code>Scalar8Bit</code></td><td style="text-align: left">Scalar quantization to 8-bit integers</td><td style="text-align: left">~4x</td></tr>
<tr><td style="text-align: left"><strong>Product Quantization</strong></td><td style="text-align: left"><code>ProductQuantization { subvector_count }</code></td><td style="text-align: left">Splits vectors into sub-vectors and quantizes each</td><td style="text-align: left">~16-64x</td></tr>
</tbody></table>
</div>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::vector::HnswOption;
use laurus::vector::core::quantization::QuantizationMethod;

let opt = HnswOption {
    dimension: 384,
    quantizer: Some(QuantizationMethod::Scalar8Bit),
    ..Default::default()
};
<span class="boring">}</span></code></pre></pre>
<h2 id="segment-files"><a class="header" href="#segment-files">Segment Files</a></h2>
<p>Each vector index type stores its data in a single segment file:</p>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Index Type</th><th style="text-align: left">File Extension</th><th style="text-align: left">Contents</th></tr></thead><tbody>
<tr><td style="text-align: left">HNSW</td><td style="text-align: left"><code>.hnsw</code></td><td style="text-align: left">Graph structure, vectors, and metadata</td></tr>
<tr><td style="text-align: left">Flat</td><td style="text-align: left"><code>.flat</code></td><td style="text-align: left">Raw vectors and metadata</td></tr>
<tr><td style="text-align: left">IVF</td><td style="text-align: left"><code>.ivf</code></td><td style="text-align: left">Cluster centroids, assigned vectors, and metadata</td></tr>
</tbody></table>
</div>
<h2 id="code-example-1"><a class="header" href="#code-example-1">Code Example</a></h2>
<pre><pre class="playground"><code class="language-rust">use std::sync::Arc;
use laurus::{Document, Engine, Schema};
use laurus::lexical::TextOption;
use laurus::vector::HnswOption;
use laurus::vector::core::distance::DistanceMetric;
use laurus::storage::memory::MemoryStorage;

#[tokio::main]
async fn main() -&gt; laurus::Result&lt;()&gt; {
    let storage = Arc::new(MemoryStorage::new(Default::default()));
    let schema = Schema::builder()
        .add_text_field("title", TextOption::default())
        .add_hnsw_field("embedding", HnswOption {
            dimension: 384,
            distance: DistanceMetric::Cosine,
            m: 16,
            ef_construction: 200,
            ..Default::default()
        })
        .build();

    // With an embedder, text in vector fields is automatically embedded
    let engine = Engine::builder(storage, schema)
        .embedder(my_embedder)
        .build()
        .await?;

    // Add text to the vector field — it will be embedded automatically
    engine.add_document("doc-1", Document::builder()
        .add_text("title", "Rust Programming")
        .add_text("embedding", "Rust is a systems programming language.")
        .build()
    ).await?;

    engine.commit().await?;

    Ok(())
}</code></pre></pre>
<h2 id="next-steps-3"><a class="header" href="#next-steps-3">Next Steps</a></h2>
<ul>
<li>Search the vector index: <a href="indexing/../search/vector_search.html">Vector Search</a></li>
<li>Combine with lexical search: <a href="indexing/../search/hybrid_search.html">Hybrid Search</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="search"><a class="header" href="#search">Search</a></h1>
<p>This section covers how to query your indexed data. Laurus supports three search modes that can be used independently or combined.</p>
<h2 id="topics-2"><a class="header" href="#topics-2">Topics</a></h2>
<h3 id="lexical-search"><a class="header" href="#lexical-search"><a href="search/lexical_search.html">Lexical Search</a></a></h3>
<p>Keyword-based search using an inverted index. Covers:</p>
<ul>
<li>All query types: Term, Phrase, Boolean, Fuzzy, Wildcard, Range, Geo, Span</li>
<li>BM25 scoring and field boosts</li>
<li>Using the Query DSL for text-based queries</li>
</ul>
<h3 id="vector-search"><a class="header" href="#vector-search"><a href="search/vector_search.html">Vector Search</a></a></h3>
<p>Semantic similarity search using vector embeddings. Covers:</p>
<ul>
<li>VectorSearchRequestBuilder API</li>
<li>Multi-field vector search and score modes</li>
<li>Filtered vector search</li>
</ul>
<h3 id="hybrid-search"><a class="header" href="#hybrid-search"><a href="search/hybrid_search.html">Hybrid Search</a></a></h3>
<p>Combining lexical and vector search for best-of-both-worlds results. Covers:</p>
<ul>
<li>SearchRequestBuilder API</li>
<li>Fusion algorithms (RRF, WeightedSum)</li>
<li>Filtered hybrid search</li>
<li>Pagination with offset/limit</li>
</ul>
<h3 id="spelling-correction"><a class="header" href="#spelling-correction"><a href="search/spelling_correction.html">Spelling Correction</a></a></h3>
<p>Suggest corrections for misspelled query terms. Covers:</p>
<ul>
<li>SpellingCorrector and "Did you mean?" features</li>
<li>Custom dictionaries and configuration</li>
<li>Learning from index terms and user queries</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="lexical-search-1"><a class="header" href="#lexical-search-1">Lexical Search</a></h1>
<p>Lexical search finds documents by matching keywords against an inverted index. Laurus provides a rich set of query types that cover exact matching, phrase matching, fuzzy matching, and more.</p>
<h2 id="basic-usage"><a class="header" href="#basic-usage">Basic Usage</a></h2>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::{SearchRequestBuilder, LexicalSearchRequest};
use laurus::lexical::TermQuery;

let request = SearchRequestBuilder::new()
    .lexical_search_request(
        LexicalSearchRequest::new(
            Box::new(TermQuery::new("body", "rust"))
        )
    )
    .limit(10)
    .build();

let results = engine.search(request).await?;
<span class="boring">}</span></code></pre></pre>
<h2 id="query-types"><a class="header" href="#query-types">Query Types</a></h2>
<h3 id="termquery"><a class="header" href="#termquery">TermQuery</a></h3>
<p>Matches documents containing an exact term in a specific field.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::lexical::TermQuery;

// Find documents where "body" contains the term "rust"
let query = TermQuery::new("body", "rust");
<span class="boring">}</span></code></pre></pre>
<blockquote>
<p><strong>Note:</strong> Terms are matched after analysis. If the field uses <code>StandardAnalyzer</code>, both the indexed text and the query term are lowercased, so <code>TermQuery::new("body", "rust")</code> will match "Rust" in the original text.</p>
</blockquote>
<h3 id="phrasequery"><a class="header" href="#phrasequery">PhraseQuery</a></h3>
<p>Matches documents containing an exact sequence of terms.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::lexical::query::phrase::PhraseQuery;

// Find documents containing the exact phrase "machine learning"
let query = PhraseQuery::new("body", vec!["machine".to_string(), "learning".to_string()]);

// Or use the convenience method from a phrase string:
let query = PhraseQuery::from_phrase("body", "machine learning");
<span class="boring">}</span></code></pre></pre>
<p>Phrase queries require term positions to be stored (the default for <code>TextOption</code>).</p>
<h3 id="booleanquery"><a class="header" href="#booleanquery">BooleanQuery</a></h3>
<p>Combines multiple queries with boolean logic.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::lexical::query::boolean::{BooleanQuery, BooleanQueryBuilder, Occur};

let query = BooleanQueryBuilder::new()
    .must(Box::new(TermQuery::new("body", "rust")))       // AND
    .must(Box::new(TermQuery::new("body", "programming"))) // AND
    .must_not(Box::new(TermQuery::new("body", "python")))  // NOT
    .build();
<span class="boring">}</span></code></pre></pre>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Occur</th><th style="text-align: left">Meaning</th><th style="text-align: left">DSL Equivalent</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>Must</code></td><td style="text-align: left">Document MUST match</td><td style="text-align: left"><code>+term</code> or <code>AND</code></td></tr>
<tr><td style="text-align: left"><code>Should</code></td><td style="text-align: left">Document SHOULD match (boosts score)</td><td style="text-align: left"><code>term</code> or <code>OR</code></td></tr>
<tr><td style="text-align: left"><code>MustNot</code></td><td style="text-align: left">Document MUST NOT match</td><td style="text-align: left"><code>-term</code> or <code>NOT</code></td></tr>
<tr><td style="text-align: left"><code>Filter</code></td><td style="text-align: left">MUST match, but does not affect score</td><td style="text-align: left">(no DSL equivalent)</td></tr>
</tbody></table>
</div>
<h3 id="fuzzyquery"><a class="header" href="#fuzzyquery">FuzzyQuery</a></h3>
<p>Matches terms within a specified edit distance (Levenshtein distance).</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::lexical::query::fuzzy::FuzzyQuery;

// Find documents matching "programing" within edit distance 2
// This will match "programming", "programing", etc.
let query = FuzzyQuery::new("body", "programing");  // default max_edits = 2
<span class="boring">}</span></code></pre></pre>
<h3 id="wildcardquery"><a class="header" href="#wildcardquery">WildcardQuery</a></h3>
<p>Matches terms using wildcard patterns.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::lexical::query::wildcard::WildcardQuery;

// '?' matches exactly one character, '*' matches zero or more
let query = WildcardQuery::new("filename", "*.pdf")?;
let query = WildcardQuery::new("body", "pro*")?;
let query = WildcardQuery::new("body", "col?r")?;  // matches "color" and "colour"
<span class="boring">}</span></code></pre></pre>
<h3 id="prefixquery"><a class="header" href="#prefixquery">PrefixQuery</a></h3>
<p>Matches documents containing terms that start with a specific prefix.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::lexical::query::prefix::PrefixQuery;

// Find documents where "body" contains terms starting with "pro"
// This matches "programming", "program", "production", etc.
let query = PrefixQuery::new("body", "pro");
<span class="boring">}</span></code></pre></pre>
<h3 id="regexpquery"><a class="header" href="#regexpquery">RegexpQuery</a></h3>
<p>Matches documents containing terms that match a regular expression pattern.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::lexical::query::regexp::RegexpQuery;

// Find documents where "body" contains terms matching the regex
let query = RegexpQuery::new("body", "^pro.*ing$")?;

// Match version-like patterns
let query = RegexpQuery::new("version", r"^v\d+\.\d+")?;
<span class="boring">}</span></code></pre></pre>
<blockquote>
<p><strong>Note:</strong> <code>RegexpQuery::new()</code> returns <code>Result</code> because the regex pattern is validated at construction time. Invalid patterns will produce an error.</p>
</blockquote>
<h3 id="numericrangequery"><a class="header" href="#numericrangequery">NumericRangeQuery</a></h3>
<p>Matches documents with numeric field values within a range.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::lexical::NumericRangeQuery;
use laurus::lexical::core::field::NumericType;

// Find documents where "price" is between 10.0 and 100.0 (inclusive)
let query = NumericRangeQuery::new(
    "price",
    NumericType::Float,
    Some(10.0),   // min
    Some(100.0),  // max
    true,         // include min
    true,         // include max
);

// Open-ended range: price &gt;= 50
let query = NumericRangeQuery::new(
    "price",
    NumericType::Float,
    Some(50.0),
    None,     // no upper bound
    true,
    false,
);
<span class="boring">}</span></code></pre></pre>
<h3 id="geoquery"><a class="header" href="#geoquery">GeoQuery</a></h3>
<p>Matches documents by geographic location.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::lexical::query::geo::GeoQuery;

// Find documents within 10km of Tokyo Station (35.6812, 139.7671)
let query = GeoQuery::within_radius("location", 35.6812, 139.7671, 10.0)?; // radius in kilometers

// Find documents within a bounding box (min_lat, min_lon, max_lat, max_lon)
let query = GeoQuery::within_bounding_box(
    "location",
    35.0, 139.0,  // min (lat, lon)
    36.0, 140.0,  // max (lat, lon)
)?;
<span class="boring">}</span></code></pre></pre>
<h3 id="spanquery"><a class="header" href="#spanquery">SpanQuery</a></h3>
<p>Matches terms based on their proximity within a document. Use <code>SpanTermQuery</code> and <code>SpanNearQuery</code> to build proximity queries:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::lexical::query::span::{SpanQuery, SpanTermQuery, SpanNearQuery};

// Find documents where "quick" appears near "fox" (within 3 positions)
let query = SpanNearQuery::new(
    "body",
    vec![
        Box::new(SpanTermQuery::new("body", "quick")) as Box&lt;dyn SpanQuery&gt;,
        Box::new(SpanTermQuery::new("body", "fox")) as Box&lt;dyn SpanQuery&gt;,
    ],
    3,    // slop (max distance between terms)
    true, // in_order (terms must appear in order)
);
<span class="boring">}</span></code></pre></pre>
<h2 id="scoring"><a class="header" href="#scoring">Scoring</a></h2>
<p>Lexical search results are scored using <strong>BM25</strong>. The score reflects how relevant a document is to the query:</p>
<ul>
<li>Higher term frequency in the document increases the score</li>
<li>Rarer terms across the index increase the score</li>
<li>Shorter documents are boosted relative to longer ones</li>
</ul>
<h3 id="field-boosts"><a class="header" href="#field-boosts">Field Boosts</a></h3>
<p>You can boost specific fields to influence relevance:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::LexicalSearchRequest;

let mut request = LexicalSearchRequest::new(Box::new(query));
request.field_boosts.insert("title".to_string(), 2.0);  // title matches count double
request.field_boosts.insert("body".to_string(), 1.0);
<span class="boring">}</span></code></pre></pre>
<h2 id="lexicalsearchrequest-options"><a class="header" href="#lexicalsearchrequest-options">LexicalSearchRequest Options</a></h2>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Option</th><th style="text-align: left">Default</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>query</code></td><td style="text-align: left">(required)</td><td style="text-align: left">The query to execute</td></tr>
<tr><td style="text-align: left"><code>limit</code></td><td style="text-align: left">10</td><td style="text-align: left">Maximum number of results</td></tr>
<tr><td style="text-align: left"><code>load_documents</code></td><td style="text-align: left">true</td><td style="text-align: left">Whether to load full document content</td></tr>
<tr><td style="text-align: left"><code>min_score</code></td><td style="text-align: left">0.0</td><td style="text-align: left">Minimum score threshold</td></tr>
<tr><td style="text-align: left"><code>timeout_ms</code></td><td style="text-align: left">None</td><td style="text-align: left">Search timeout in milliseconds</td></tr>
<tr><td style="text-align: left"><code>parallel</code></td><td style="text-align: left">false</td><td style="text-align: left">Enable parallel search across segments</td></tr>
<tr><td style="text-align: left"><code>sort_by</code></td><td style="text-align: left"><code>Score</code></td><td style="text-align: left">Sort by relevance score, or by a field (<code>asc</code> / <code>desc</code>)</td></tr>
<tr><td style="text-align: left"><code>field_boosts</code></td><td style="text-align: left">empty</td><td style="text-align: left">Per-field score multipliers</td></tr>
</tbody></table>
</div>
<h3 id="builder-methods"><a class="header" href="#builder-methods">Builder Methods</a></h3>
<p><code>LexicalSearchRequest</code> supports a builder-style API for setting options:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::LexicalSearchRequest;
use laurus::lexical::TermQuery;

let request = LexicalSearchRequest::new(Box::new(TermQuery::new("body", "rust")))
    .limit(20)
    .min_score(0.5)
    .timeout_ms(5000)
    .parallel(true)
    .sort_by_field_desc("date")
    .with_field_boost("title", 2.0)
    .with_field_boost("body", 1.0);
<span class="boring">}</span></code></pre></pre>
<h2 id="using-the-query-dsl"><a class="header" href="#using-the-query-dsl">Using the Query DSL</a></h2>
<p>Instead of building queries programmatically, you can use the text-based Query DSL:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::lexical::QueryParser;
use laurus::analysis::analyzer::standard::StandardAnalyzer;
use std::sync::Arc;

let analyzer = Arc::new(StandardAnalyzer::default());
let parser = QueryParser::new(analyzer).with_default_field("body");

// Simple term
let query = parser.parse("rust")?;

// Boolean
let query = parser.parse("rust AND programming")?;

// Phrase
let query = parser.parse("\"machine learning\"")?;

// Field-specific
let query = parser.parse("title:rust AND body:programming")?;

// Fuzzy
let query = parser.parse("programing~2")?;

// Range
let query = parser.parse("year:[2020 TO 2024]")?;
<span class="boring">}</span></code></pre></pre>
<p>See <a href="search/../advanced/query_dsl.html">Query DSL</a> for the complete syntax reference.</p>
<h2 id="next-steps-4"><a class="header" href="#next-steps-4">Next Steps</a></h2>
<ul>
<li>Semantic similarity search: <a href="search/vector_search.html">Vector Search</a></li>
<li>Combine lexical + vector: <a href="search/hybrid_search.html">Hybrid Search</a></li>
<li>Full DSL syntax reference: <a href="search/../advanced/query_dsl.html">Query DSL</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="vector-search-1"><a class="header" href="#vector-search-1">Vector Search</a></h1>
<p>Vector search finds documents by semantic similarity. Instead of matching keywords, it compares the meaning of the query against document embeddings in vector space.</p>
<h2 id="basic-usage-1"><a class="header" href="#basic-usage-1">Basic Usage</a></h2>
<h3 id="builder-api"><a class="header" href="#builder-api">Builder API</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::SearchRequestBuilder;
use laurus::vector::VectorSearchRequestBuilder;

let request = SearchRequestBuilder::new()
    .vector_search_request(
        VectorSearchRequestBuilder::new()
            .add_text("embedding", "systems programming language")
            .limit(10)
            .build()
    )
    .build();

let results = engine.search(request).await?;
<span class="boring">}</span></code></pre></pre>
<p>The <code>add_text()</code> method stores the text as a query payload. At search time, the engine embeds it using the configured embedder and then searches the vector index.</p>
<h3 id="query-dsl"><a class="header" href="#query-dsl">Query DSL</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::vector::VectorQueryParser;

let parser = VectorQueryParser::new(embedder.clone())
    .with_default_field("embedding");

let request = parser.parse(r#"embedding:~"systems programming""#).await?;
<span class="boring">}</span></code></pre></pre>
<h2 id="vectorsearchrequestbuilder"><a class="header" href="#vectorsearchrequestbuilder">VectorSearchRequestBuilder</a></h2>
<p>The builder API provides fine-grained control:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::vector::VectorSearchRequestBuilder;
use laurus::vector::store::request::QueryVector;

let request = VectorSearchRequestBuilder::new()
    // Text query (will be embedded at search time)
    .add_text("text_vec", "machine learning")

    // Or use a pre-computed vector directly
    .add_vector("embedding", vec![0.1, 0.2, 0.3, /* ... */])

    // Search parameters
    .limit(20)

    .build();
<span class="boring">}</span></code></pre></pre>
<h3 id="methods"><a class="header" href="#methods">Methods</a></h3>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Method</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>add_text(field, text)</code></td><td style="text-align: left">Add a text query for a specific field (embedded at search time)</td></tr>
<tr><td style="text-align: left"><code>add_vector(field, vector)</code></td><td style="text-align: left">Add a pre-computed query vector for a specific field</td></tr>
<tr><td style="text-align: left"><code>add_vector_with_weight(field, vector, weight)</code></td><td style="text-align: left">Add a pre-computed vector with an explicit weight</td></tr>
<tr><td style="text-align: left"><code>add_payload(field, payload)</code></td><td style="text-align: left">Add a generic <code>DataValue</code> payload to be embedded</td></tr>
<tr><td style="text-align: left"><code>add_bytes(field, bytes, mime)</code></td><td style="text-align: left">Add a binary payload (e.g., image bytes for multimodal)</td></tr>
<tr><td style="text-align: left"><code>field(name)</code></td><td style="text-align: left">Restrict search to a specific field</td></tr>
<tr><td style="text-align: left"><code>fields(names)</code></td><td style="text-align: left">Restrict search to multiple fields</td></tr>
<tr><td style="text-align: left"><code>limit(n)</code></td><td style="text-align: left">Maximum number of results (default: 10)</td></tr>
<tr><td style="text-align: left"><code>score_mode(VectorScoreMode)</code></td><td style="text-align: left">Score combination mode (<code>WeightedSum</code>, <code>MaxSim</code>, <code>LateInteraction</code>)</td></tr>
<tr><td style="text-align: left"><code>min_score(f32)</code></td><td style="text-align: left">Minimum score threshold (default: 0.0)</td></tr>
<tr><td style="text-align: left"><code>overfetch(f32)</code></td><td style="text-align: left">Overfetch factor for better result quality (default: 1.0)</td></tr>
<tr><td style="text-align: left"><code>build()</code></td><td style="text-align: left">Build the <code>VectorSearchRequest</code></td></tr>
</tbody></table>
</div>
<h2 id="multi-field-vector-search"><a class="header" href="#multi-field-vector-search">Multi-Field Vector Search</a></h2>
<p>You can search across multiple vector fields in a single request:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let request = VectorSearchRequestBuilder::new()
    .add_text("text_vec", "cute kitten")
    .add_text("image_vec", "fluffy cat")
    .build();
<span class="boring">}</span></code></pre></pre>
<p>Each clause produces a vector that is searched against its respective field. Results are combined using the configured score mode.</p>
<h3 id="score-modes"><a class="header" href="#score-modes">Score Modes</a></h3>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Mode</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>WeightedSum</code> (default)</td><td style="text-align: left">Sum of (similarity * weight) across all clauses</td></tr>
<tr><td style="text-align: left"><code>MaxSim</code></td><td style="text-align: left">Maximum similarity score across clauses</td></tr>
<tr><td style="text-align: left"><code>LateInteraction</code></td><td style="text-align: left">ColBERT-style late interaction scoring</td></tr>
</tbody></table>
</div>
<h3 id="weights"><a class="header" href="#weights">Weights</a></h3>
<p>Use the <code>^</code> boost syntax in DSL or <code>weight</code> in <code>QueryVector</code> to adjust how much each field contributes:</p>
<pre><code>text_vec:~"cute kitten"^1.0 image_vec:~"fluffy cat"^0.5
</code></pre>
<p>This means text similarity counts twice as much as image similarity.</p>
<h2 id="filtered-vector-search"><a class="header" href="#filtered-vector-search">Filtered Vector Search</a></h2>
<p>You can apply lexical filters to narrow the vector search results:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::{SearchRequestBuilder, LexicalSearchRequest};
use laurus::lexical::TermQuery;
use laurus::vector::VectorSearchRequestBuilder;

// Vector search with a category filter
let request = SearchRequestBuilder::new()
    .vector_search_request(
        VectorSearchRequestBuilder::new()
            .add_text("embedding", "machine learning")
            .build()
    )
    .filter_query(Box::new(TermQuery::new("category", "tutorial")))
    .limit(10)
    .build();

let results = engine.search(request).await?;
<span class="boring">}</span></code></pre></pre>
<p>The filter query runs first on the lexical index to identify allowed document IDs, then the vector search is restricted to those IDs.</p>
<h3 id="filter-with-numeric-range"><a class="header" href="#filter-with-numeric-range">Filter with Numeric Range</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::lexical::NumericRangeQuery;
use laurus::lexical::core::field::NumericType;

let request = SearchRequestBuilder::new()
    .vector_search_request(
        VectorSearchRequestBuilder::new()
            .add_text("embedding", "type systems")
            .build()
    )
    .filter_query(Box::new(NumericRangeQuery::new(
        "year", NumericType::Integer,
        Some(2020.0), Some(2024.0), true, true
    )))
    .limit(10)
    .build();
<span class="boring">}</span></code></pre></pre>
<h2 id="distance-metrics-1"><a class="header" href="#distance-metrics-1">Distance Metrics</a></h2>
<p>The distance metric is configured per field in the schema (see <a href="search/../indexing/vector_indexing.html">Vector Indexing</a>):</p>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Metric</th><th style="text-align: left">Description</th><th style="text-align: left">Lower = More Similar</th></tr></thead><tbody>
<tr><td style="text-align: left"><strong>Cosine</strong></td><td style="text-align: left">1 - cosine similarity</td><td style="text-align: left">Yes</td></tr>
<tr><td style="text-align: left"><strong>Euclidean</strong></td><td style="text-align: left">L2 distance</td><td style="text-align: left">Yes</td></tr>
<tr><td style="text-align: left"><strong>Manhattan</strong></td><td style="text-align: left">L1 distance</td><td style="text-align: left">Yes</td></tr>
<tr><td style="text-align: left"><strong>DotProduct</strong></td><td style="text-align: left">Negative inner product</td><td style="text-align: left">Yes</td></tr>
<tr><td style="text-align: left"><strong>Angular</strong></td><td style="text-align: left">Angular distance</td><td style="text-align: left">Yes</td></tr>
</tbody></table>
</div>
<h2 id="code-example-complete-vector-search"><a class="header" href="#code-example-complete-vector-search">Code Example: Complete Vector Search</a></h2>
<pre><pre class="playground"><code class="language-rust">use std::sync::Arc;
use laurus::{Document, Engine, Schema, SearchRequestBuilder, PerFieldEmbedder};
use laurus::lexical::TextOption;
use laurus::vector::HnswOption;
use laurus::vector::VectorSearchRequestBuilder;
use laurus::storage::memory::MemoryStorage;

#[tokio::main]
async fn main() -&gt; laurus::Result&lt;()&gt; {
    let storage = Arc::new(MemoryStorage::new(Default::default()));

    let schema = Schema::builder()
        .add_text_field("title", TextOption::default())
        .add_hnsw_field("text_vec", HnswOption {
            dimension: 384,
            ..Default::default()
        })
        .build();

    // Set up per-field embedder
    let embedder = Arc::new(my_embedder);
    let mut pfe = PerFieldEmbedder::new(embedder.clone());
    pfe.add_embedder("text_vec", embedder.clone());

    let engine = Engine::builder(storage, schema)
        .embedder(Arc::new(pfe))
        .build()
        .await?;

    // Index documents (text in vector field is auto-embedded)
    engine.add_document("doc-1", Document::builder()
        .add_text("title", "Rust Programming")
        .add_text("text_vec", "Rust is a systems programming language.")
        .build()
    ).await?;
    engine.commit().await?;

    // Search by semantic similarity
    let results = engine.search(
        SearchRequestBuilder::new()
            .vector_search_request(
                VectorSearchRequestBuilder::new()
                    .add_text("text_vec", "systems language")
                    .build()
            )
            .limit(5)
            .build()
    ).await?;

    for r in &amp;results {
        println!("{}: score={:.4}", r.id, r.score);
    }

    Ok(())
}</code></pre></pre>
<h2 id="next-steps-5"><a class="header" href="#next-steps-5">Next Steps</a></h2>
<ul>
<li>Combine with keyword search: <a href="search/hybrid_search.html">Hybrid Search</a></li>
<li>DSL syntax for vector queries: <a href="search/../advanced/query_dsl.html">Query DSL</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="hybrid-search-1"><a class="header" href="#hybrid-search-1">Hybrid Search</a></h1>
<p>Hybrid search combines <strong>lexical search</strong> (keyword matching) with <strong>vector search</strong> (semantic similarity) to deliver results that are both precise and semantically relevant. This is Laurus's most powerful search mode.</p>
<h2 id="why-hybrid-search"><a class="header" href="#why-hybrid-search">Why Hybrid Search?</a></h2>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Search Type</th><th style="text-align: left">Strengths</th><th style="text-align: left">Weaknesses</th></tr></thead><tbody>
<tr><td style="text-align: left"><strong>Lexical only</strong></td><td style="text-align: left">Exact keyword matching, handles rare terms well</td><td style="text-align: left">Misses synonyms and paraphrases</td></tr>
<tr><td style="text-align: left"><strong>Vector only</strong></td><td style="text-align: left">Understands meaning, handles synonyms</td><td style="text-align: left">May miss exact keywords, less precise</td></tr>
<tr><td style="text-align: left"><strong>Hybrid</strong></td><td style="text-align: left">Best of both worlds</td><td style="text-align: left">Slightly more complex to configure</td></tr>
</tbody></table>
</div>
<h2 id="how-it-works-1"><a class="header" href="#how-it-works-1">How It Works</a></h2>
<pre><code class="language-mermaid">sequenceDiagram
    participant User
    participant Engine
    participant Lexical as LexicalStore
    participant Vector as VectorStore
    participant Fusion

    User-&gt;&gt;Engine: SearchRequest\n(lexical + vector)

    par Execute in parallel
        Engine-&gt;&gt;Lexical: BM25 keyword search
        Lexical--&gt;&gt;Engine: Ranked hits (by relevance)
    and
        Engine-&gt;&gt;Vector: ANN similarity search
        Vector--&gt;&gt;Engine: Ranked hits (by distance)
    end

    Engine-&gt;&gt;Fusion: Merge two result sets
    Note over Fusion: RRF or WeightedSum
    Fusion--&gt;&gt;Engine: Unified ranked list
    Engine--&gt;&gt;User: Vec of SearchResult
</code></pre>
<h2 id="basic-usage-2"><a class="header" href="#basic-usage-2">Basic Usage</a></h2>
<h3 id="builder-api-1"><a class="header" href="#builder-api-1">Builder API</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::{SearchRequestBuilder, LexicalSearchRequest, FusionAlgorithm};
use laurus::lexical::TermQuery;
use laurus::vector::VectorSearchRequestBuilder;

let request = SearchRequestBuilder::new()
    // Lexical component
    .lexical_search_request(
        LexicalSearchRequest::new(
            Box::new(TermQuery::new("body", "rust"))
        )
    )
    // Vector component
    .vector_search_request(
        VectorSearchRequestBuilder::new()
            .add_text("text_vec", "systems programming")
            .build()
    )
    // Fusion algorithm
    .fusion_algorithm(FusionAlgorithm::RRF { k: 60.0 })
    .limit(10)
    .build();

let results = engine.search(request).await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="query-dsl-1"><a class="header" href="#query-dsl-1">Query DSL</a></h3>
<p>Mix lexical and vector clauses in a single query string:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::UnifiedQueryParser;
use laurus::lexical::QueryParser;
use laurus::vector::VectorQueryParser;

let unified = UnifiedQueryParser::new(
    QueryParser::new(analyzer).with_default_field("body"),
    VectorQueryParser::new(embedder),
);

// Lexical + vector in one query
let request = unified.parse(r#"body:rust text_vec:~"systems programming""#).await?;
let results = engine.search(request).await?;
<span class="boring">}</span></code></pre></pre>
<p>The <code>~"..."</code> syntax identifies vector clauses. Everything else is parsed as lexical.</p>
<h2 id="fusion-algorithms"><a class="header" href="#fusion-algorithms">Fusion Algorithms</a></h2>
<p>When both lexical and vector results exist, they must be merged into a single ranked list. Laurus supports two fusion algorithms:</p>
<h3 id="rrf-reciprocal-rank-fusion"><a class="header" href="#rrf-reciprocal-rank-fusion">RRF (Reciprocal Rank Fusion)</a></h3>
<p>The default algorithm. Combines results based on their rank positions rather than raw scores.</p>
<pre><code>score(doc) = sum( 1 / (k + rank_i) )
</code></pre>
<p>Where <code>rank_i</code> is the position of the document in each result list, and <code>k</code> is a smoothing parameter (default 60).</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::FusionAlgorithm;

let fusion = FusionAlgorithm::RRF { k: 60.0 };
<span class="boring">}</span></code></pre></pre>
<p><strong>Advantages:</strong></p>
<ul>
<li>Robust to different score distributions between lexical and vector results</li>
<li>No need to tune weights</li>
<li>Works well out of the box</li>
</ul>
<h3 id="weightedsum"><a class="header" href="#weightedsum">WeightedSum</a></h3>
<p>Linearly combines normalized lexical and vector scores:</p>
<pre><code>score(doc) = lexical_weight * lexical_score + vector_weight * vector_score
</code></pre>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::FusionAlgorithm;

let fusion = FusionAlgorithm::WeightedSum {
    lexical_weight: 0.3,
    vector_weight: 0.7,
};
<span class="boring">}</span></code></pre></pre>
<p><strong>When to use:</strong></p>
<ul>
<li>When you want explicit control over the balance between lexical and vector relevance</li>
<li>When you know one signal is more important than the other</li>
</ul>
<h2 id="searchrequest-options"><a class="header" href="#searchrequest-options">SearchRequest Options</a></h2>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Option</th><th style="text-align: left">Default</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>lexical_search_request</code></td><td style="text-align: left">None</td><td style="text-align: left">Lexical query component</td></tr>
<tr><td style="text-align: left"><code>vector_search_request</code></td><td style="text-align: left">None</td><td style="text-align: left">Vector query component</td></tr>
<tr><td style="text-align: left"><code>filter_query</code></td><td style="text-align: left">None</td><td style="text-align: left">Pre-filter using a lexical query (restricts both lexical and vector results)</td></tr>
<tr><td style="text-align: left"><code>fusion_algorithm</code></td><td style="text-align: left"><code>None</code> (uses <code>RRF { k: 60.0 }</code> when both results exist)</td><td style="text-align: left">How to merge lexical and vector results</td></tr>
<tr><td style="text-align: left"><code>limit</code></td><td style="text-align: left">10</td><td style="text-align: left">Maximum number of results to return</td></tr>
<tr><td style="text-align: left"><code>offset</code></td><td style="text-align: left">0</td><td style="text-align: left">Number of results to skip (for pagination)</td></tr>
</tbody></table>
</div>
<h2 id="searchresult"><a class="header" href="#searchresult">SearchResult</a></h2>
<p>Each result contains:</p>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Field</th><th style="text-align: left">Type</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>id</code></td><td style="text-align: left"><code>String</code></td><td style="text-align: left">External document ID</td></tr>
<tr><td style="text-align: left"><code>score</code></td><td style="text-align: left"><code>f32</code></td><td style="text-align: left">Fused relevance score</td></tr>
<tr><td style="text-align: left"><code>document</code></td><td style="text-align: left"><code>Option&lt;Document&gt;</code></td><td style="text-align: left">Full document content (if loaded)</td></tr>
</tbody></table>
</div>
<h2 id="filtered-hybrid-search"><a class="header" href="#filtered-hybrid-search">Filtered Hybrid Search</a></h2>
<p>Apply a filter to restrict both lexical and vector results:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let request = SearchRequestBuilder::new()
    .lexical_search_request(
        LexicalSearchRequest::new(Box::new(TermQuery::new("body", "rust")))
    )
    .vector_search_request(
        VectorSearchRequestBuilder::new()
            .add_text("text_vec", "systems programming")
            .build()
    )
    // Only search within "tutorial" category
    .filter_query(Box::new(TermQuery::new("category", "tutorial")))
    .fusion_algorithm(FusionAlgorithm::RRF { k: 60.0 })
    .limit(10)
    .build();
<span class="boring">}</span></code></pre></pre>
<h3 id="how-filtering-works"><a class="header" href="#how-filtering-works">How Filtering Works</a></h3>
<ol>
<li>The filter query runs on the lexical index to produce a set of allowed document IDs</li>
<li>For lexical search: the filter is combined with the user query as a boolean AND</li>
<li>For vector search: the allowed IDs are passed to restrict the ANN search</li>
</ol>
<h2 id="pagination"><a class="header" href="#pagination">Pagination</a></h2>
<p>Use <code>offset</code> and <code>limit</code> for pagination:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Page 1: results 0-9
let page1 = SearchRequestBuilder::new()
    .lexical_search_request(/* ... */)
    .vector_search_request(/* ... */)
    .offset(0)
    .limit(10)
    .build();

// Page 2: results 10-19
let page2 = SearchRequestBuilder::new()
    .lexical_search_request(/* ... */)
    .vector_search_request(/* ... */)
    .offset(10)
    .limit(10)
    .build();
<span class="boring">}</span></code></pre></pre>
<h2 id="complete-example-1"><a class="header" href="#complete-example-1">Complete Example</a></h2>
<pre><pre class="playground"><code class="language-rust">use std::sync::Arc;
use laurus::{
    Document, Engine, Schema, SearchRequestBuilder,
    LexicalSearchRequest, FusionAlgorithm, PerFieldEmbedder,
};
use laurus::lexical::{TextOption, TermQuery};
use laurus::lexical::core::field::IntegerOption;
use laurus::vector::{HnswOption, VectorSearchRequestBuilder};
use laurus::storage::memory::MemoryStorage;

#[tokio::main]
async fn main() -&gt; laurus::Result&lt;()&gt; {
    let storage = Arc::new(MemoryStorage::new(Default::default()));

    // Schema with both lexical and vector fields
    let schema = Schema::builder()
        .add_text_field("title", TextOption::default())
        .add_text_field("body", TextOption::default())
        .add_text_field("category", TextOption::default())
        .add_integer_field("year", IntegerOption::default())
        .add_hnsw_field("body_vec", HnswOption {
            dimension: 384,
            ..Default::default()
        })
        .build();

    // Configure analyzer and embedder (see Text Analysis and Embeddings docs)
    // let analyzer = Arc::new(StandardAnalyzer::new()?);
    // let embedder = Arc::new(CandleBertEmbedder::new("sentence-transformers/all-MiniLM-L6-v2")?);
    let engine = Engine::builder(storage, schema)
        // .analyzer(analyzer)
        // .embedder(embedder)
        .build()
        .await?;

    // Index documents with both text and vector fields
    engine.add_document("doc-1", Document::builder()
        .add_text("title", "Rust Programming Guide")
        .add_text("body", "Rust is a systems programming language.")
        .add_text("category", "programming")
        .add_integer("year", 2024)
        .add_text("body_vec", "Rust is a systems programming language.")
        .build()
    ).await?;
    engine.commit().await?;

    // Hybrid search: keyword "rust" + semantic "systems language"
    let results = engine.search(
        SearchRequestBuilder::new()
            .lexical_search_request(
                LexicalSearchRequest::new(Box::new(TermQuery::new("body", "rust")))
            )
            .vector_search_request(
                VectorSearchRequestBuilder::new()
                    .add_text("body_vec", "systems language")
                    .build()
            )
            .fusion_algorithm(FusionAlgorithm::RRF { k: 60.0 })
            .limit(10)
            .build()
    ).await?;

    for r in &amp;results {
        println!("{}: score={:.4}", r.id, r.score);
    }

    Ok(())
}</code></pre></pre>
<h2 id="next-steps-6"><a class="header" href="#next-steps-6">Next Steps</a></h2>
<ul>
<li>Full query syntax reference: <a href="search/../advanced/query_dsl.html">Query DSL</a></li>
<li>Understand ID resolution: <a href="search/../advanced/id_management.html">ID Management</a></li>
<li>Data durability: <a href="search/../advanced/persistence.html">Persistence &amp; WAL</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="spelling-correction-1"><a class="header" href="#spelling-correction-1">Spelling Correction</a></h1>
<p>Laurus includes a built-in spelling correction system that can suggest corrections for misspelled query terms and provide "Did you mean?" functionality.</p>
<h2 id="overview"><a class="header" href="#overview">Overview</a></h2>
<p>The spelling corrector uses edit distance (Levenshtein distance) combined with word frequency data to suggest corrections. It supports:</p>
<ul>
<li><strong>Word-level suggestions</strong> — correct individual misspelled words</li>
<li><strong>Auto-correction</strong> — automatically apply high-confidence corrections</li>
<li><strong>"Did you mean?"</strong> — suggest alternative queries to the user</li>
<li><strong>Query learning</strong> — improve suggestions by learning from user queries</li>
<li><strong>Custom dictionaries</strong> — use your own word lists</li>
</ul>
<h2 id="basic-usage-3"><a class="header" href="#basic-usage-3">Basic Usage</a></h2>
<h3 id="spellingcorrector"><a class="header" href="#spellingcorrector">SpellingCorrector</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::spelling::corrector::SpellingCorrector;

// Create a corrector with the built-in English dictionary
let mut corrector = SpellingCorrector::new();

// Correct a query
let result = corrector.correct("programing langauge");

// Check if suggestions are available
if result.has_suggestions() {
    for (word, suggestions) in &amp;result.word_suggestions {
        println!("'{}' -&gt; {:?}", word, suggestions);
    }
}

// Get the best corrected query
if let Some(corrected) = result.query() {
    println!("Corrected: {}", corrected);
}
<span class="boring">}</span></code></pre></pre>
<h3 id="did-you-mean"><a class="header" href="#did-you-mean">"Did You Mean?"</a></h3>
<p>The <code>DidYouMean</code> wrapper provides a higher-level interface for search UIs:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::spelling::corrector::{SpellingCorrector, DidYouMean};

let corrector = SpellingCorrector::new();
let mut did_you_mean = DidYouMean::new(corrector);

if let Some(suggestion) = did_you_mean.suggest("programing") {
    println!("Did you mean: {}?", suggestion);
}
<span class="boring">}</span></code></pre></pre>
<h2 id="configuration"><a class="header" href="#configuration">Configuration</a></h2>
<p>Use <code>CorrectorConfig</code> to customize behavior:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::spelling::corrector::{CorrectorConfig, SpellingCorrector};

let config = CorrectorConfig {
    max_distance: 2,              // Maximum edit distance (default: 2)
    max_suggestions: 5,           // Max suggestions per word (default: 5)
    min_frequency: 1,             // Minimum word frequency threshold (default: 1)
    auto_correct: false,          // Enable auto-correction (default: false)
    auto_correct_threshold: 0.8,  // Confidence threshold for auto-correction (default: 0.8)
    use_index_terms: true,        // Use indexed terms as dictionary (default: true)
    learn_from_queries: true,     // Learn from user queries (default: true)
};
<span class="boring">}</span></code></pre></pre>
<h3 id="configuration-options"><a class="header" href="#configuration-options">Configuration Options</a></h3>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Option</th><th style="text-align: left">Type</th><th style="text-align: left">Default</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>max_distance</code></td><td style="text-align: left"><code>usize</code></td><td style="text-align: left"><code>2</code></td><td style="text-align: left">Maximum Levenshtein edit distance for candidate suggestions</td></tr>
<tr><td style="text-align: left"><code>max_suggestions</code></td><td style="text-align: left"><code>usize</code></td><td style="text-align: left"><code>5</code></td><td style="text-align: left">Maximum number of suggestions returned per word</td></tr>
<tr><td style="text-align: left"><code>min_frequency</code></td><td style="text-align: left"><code>u32</code></td><td style="text-align: left"><code>1</code></td><td style="text-align: left">Minimum frequency a word must have in the dictionary to be suggested</td></tr>
<tr><td style="text-align: left"><code>auto_correct</code></td><td style="text-align: left"><code>bool</code></td><td style="text-align: left"><code>false</code></td><td style="text-align: left">When true, automatically apply corrections above the threshold</td></tr>
<tr><td style="text-align: left"><code>auto_correct_threshold</code></td><td style="text-align: left"><code>f64</code></td><td style="text-align: left"><code>0.8</code></td><td style="text-align: left">Confidence score (0.0–1.0) required for auto-correction</td></tr>
<tr><td style="text-align: left"><code>use_index_terms</code></td><td style="text-align: left"><code>bool</code></td><td style="text-align: left"><code>true</code></td><td style="text-align: left">Use terms from the search index as dictionary words</td></tr>
<tr><td style="text-align: left"><code>learn_from_queries</code></td><td style="text-align: left"><code>bool</code></td><td style="text-align: left"><code>true</code></td><td style="text-align: left">Learn new words from user search queries</td></tr>
</tbody></table>
</div>
<h2 id="correctionresult"><a class="header" href="#correctionresult">CorrectionResult</a></h2>
<p>The <code>correct()</code> method returns a <code>CorrectionResult</code> with detailed information:</p>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Field</th><th style="text-align: left">Type</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>original</code></td><td style="text-align: left"><code>String</code></td><td style="text-align: left">The original query string</td></tr>
<tr><td style="text-align: left"><code>corrected</code></td><td style="text-align: left"><code>Option&lt;String&gt;</code></td><td style="text-align: left">The corrected query (if auto-correction was applied)</td></tr>
<tr><td style="text-align: left"><code>word_suggestions</code></td><td style="text-align: left"><code>HashMap&lt;String, Vec&lt;Suggestion&gt;&gt;</code></td><td style="text-align: left">Suggestions grouped by misspelled word</td></tr>
<tr><td style="text-align: left"><code>confidence</code></td><td style="text-align: left"><code>f64</code></td><td style="text-align: left">Overall confidence score (0.0–1.0)</td></tr>
<tr><td style="text-align: left"><code>auto_corrected</code></td><td style="text-align: left"><code>bool</code></td><td style="text-align: left">Whether auto-correction was applied</td></tr>
</tbody></table>
</div>
<h3 id="helper-methods"><a class="header" href="#helper-methods">Helper Methods</a></h3>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Method</th><th style="text-align: left">Returns</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>has_suggestions()</code></td><td style="text-align: left"><code>bool</code></td><td style="text-align: left">True if any word has suggestions</td></tr>
<tr><td style="text-align: left"><code>best_suggestion()</code></td><td style="text-align: left"><code>Option&lt;&amp;Suggestion&gt;</code></td><td style="text-align: left">The single highest-scoring suggestion</td></tr>
<tr><td style="text-align: left"><code>query()</code></td><td style="text-align: left"><code>Option&lt;String&gt;</code></td><td style="text-align: left">The corrected query string, if corrections were made</td></tr>
<tr><td style="text-align: left"><code>should_show_did_you_mean()</code></td><td style="text-align: left"><code>bool</code></td><td style="text-align: left">Whether to display a "Did you mean?" prompt</td></tr>
</tbody></table>
</div>
<h2 id="custom-dictionaries"><a class="header" href="#custom-dictionaries">Custom Dictionaries</a></h2>
<p>You can provide your own dictionary instead of using the built-in English one:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::spelling::corrector::SpellingCorrector;
use laurus::spelling::dictionary::SpellingDictionary;

// Build a custom dictionary
let mut dictionary = SpellingDictionary::new();
dictionary.add_word("elasticsearch", 100);
dictionary.add_word("lucene", 80);
dictionary.add_word("laurus", 90);

let corrector = SpellingCorrector::with_dictionary(dictionary);
<span class="boring">}</span></code></pre></pre>
<h2 id="learning-from-index-terms"><a class="header" href="#learning-from-index-terms">Learning from Index Terms</a></h2>
<p>When <code>use_index_terms</code> is enabled, the corrector can learn from terms in your search index:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let mut corrector = SpellingCorrector::new();

// Feed index terms to the corrector
let index_terms = vec!["rust", "programming", "search", "engine"];
corrector.learn_from_terms(&amp;index_terms);
<span class="boring">}</span></code></pre></pre>
<p>This improves suggestion quality by incorporating domain-specific vocabulary.</p>
<h2 id="statistics"><a class="header" href="#statistics">Statistics</a></h2>
<p>Monitor the corrector's state with <code>stats()</code>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let stats = corrector.stats();
println!("Dictionary words: {}", stats.dictionary_words);
println!("Total frequency: {}", stats.dictionary_total_frequency);
println!("Learned queries: {}", stats.queries_learned);
<span class="boring">}</span></code></pre></pre>
<h2 id="next-steps-7"><a class="header" href="#next-steps-7">Next Steps</a></h2>
<ul>
<li><a href="search/lexical_search.html">Lexical Search</a> — full-text search with query types</li>
<li><a href="search/../advanced/query_dsl.html">Query DSL</a> — human-readable query syntax</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="cli-command-line-interface"><a class="header" href="#cli-command-line-interface">CLI (Command-Line Interface)</a></h1>
<p>Laurus provides a command-line tool <code>laurus</code> that lets you create indexes, manage documents, and run search queries without writing code.</p>
<h2 id="features"><a class="header" href="#features">Features</a></h2>
<ul>
<li><strong>Index management</strong> — Create and inspect indexes from TOML schema files, with an interactive schema generator</li>
<li><strong>Document CRUD</strong> — Add, retrieve, and delete documents via JSON</li>
<li><strong>Search</strong> — Execute queries using the <a href="advanced/query_dsl.html">Query DSL</a></li>
<li><strong>Dual output</strong> — Human-readable tables or machine-parseable JSON</li>
<li><strong>Interactive REPL</strong> — Explore your index in a live session</li>
</ul>
<h2 id="getting-started-1"><a class="header" href="#getting-started-1">Getting Started</a></h2>
<pre><code class="language-bash"># Install
cargo install laurus-cli

# Generate a schema interactively
laurus create schema

# Create an index from the schema
laurus --data-dir ./my_index create index --schema schema.toml

# Add a document
laurus --data-dir ./my_index add doc --id doc1 --data '{"title":"Hello","body":"World"}'

# Commit changes
laurus --data-dir ./my_index commit

# Search
laurus --data-dir ./my_index search "body:world"
</code></pre>
<p>See the sub-sections for detailed documentation:</p>
<ul>
<li><a href="cli/installation.html">Installation</a> — How to install the CLI</li>
<li><a href="cli/commands.html">Commands</a> — Full command reference</li>
<li><a href="cli/schema_format.html">Schema Format</a> — Schema TOML format reference</li>
<li><a href="cli/repl.html">REPL</a> — Interactive mode</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="installation-1"><a class="header" href="#installation-1">Installation</a></h1>
<h2 id="from-cratesio"><a class="header" href="#from-cratesio">From crates.io</a></h2>
<pre><code class="language-bash">cargo install laurus-cli
</code></pre>
<p>This installs the <code>laurus</code> binary to <code>~/.cargo/bin/</code>.</p>
<h2 id="from-source"><a class="header" href="#from-source">From source</a></h2>
<pre><code class="language-bash">git clone https://github.com/mosuka/laurus.git
cd laurus
cargo install --path laurus-cli
</code></pre>
<h2 id="verify"><a class="header" href="#verify">Verify</a></h2>
<pre><code class="language-bash">laurus --version
</code></pre>
<h2 id="shell-completion"><a class="header" href="#shell-completion">Shell Completion</a></h2>
<p>Generate completion scripts for your shell:</p>
<pre><code class="language-bash"># Bash
laurus --help

# The CLI uses clap, so shell completions can be generated
# with clap_complete if needed in a future release.
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="command-reference"><a class="header" href="#command-reference">Command Reference</a></h1>
<h2 id="global-options"><a class="header" href="#global-options">Global Options</a></h2>
<p>Every command accepts these options:</p>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Option</th><th style="text-align: left">Environment Variable</th><th style="text-align: left">Default</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>--data-dir &lt;PATH&gt;</code></td><td style="text-align: left"><code>LAURUS_DATA_DIR</code></td><td style="text-align: left"><code>./laurus_data</code></td><td style="text-align: left">Path to the index data directory</td></tr>
<tr><td style="text-align: left"><code>--format &lt;FORMAT&gt;</code></td><td style="text-align: left">—</td><td style="text-align: left"><code>table</code></td><td style="text-align: left">Output format: <code>table</code> or <code>json</code></td></tr>
</tbody></table>
</div>
<pre><code class="language-bash"># Example: use JSON output with a custom data directory
laurus --data-dir /var/data/my_index --format json search "title:rust"
</code></pre>
<hr />
<h2 id="create--create-a-resource"><a class="header" href="#create--create-a-resource"><code>create</code> — Create a Resource</a></h2>
<h3 id="create-index"><a class="header" href="#create-index"><code>create index</code></a></h3>
<p>Create a new index from a schema TOML file.</p>
<pre><code class="language-bash">laurus create index --schema &lt;FILE&gt;
</code></pre>
<p><strong>Arguments:</strong></p>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Flag</th><th style="text-align: left">Required</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>--schema &lt;FILE&gt;</code></td><td style="text-align: left">Yes</td><td style="text-align: left">Path to a TOML file defining the index schema</td></tr>
</tbody></table>
</div>
<p><strong>Schema file format:</strong></p>
<p>The schema file follows the same structure as the <code>Schema</code> type in the Laurus library. See <a href="cli/schema_format.html">Schema Format Reference</a> for full details. Example:</p>
<pre><code class="language-toml">default_fields = ["title", "body"]

[fields.title.Text]
stored = true
indexed = true

[fields.body.Text]
stored = true
indexed = true

[fields.category.Text]
stored = true
indexed = true
</code></pre>
<p><strong>Example:</strong></p>
<pre><code class="language-bash">laurus --data-dir ./my_index create index --schema schema.toml
# Index created at ./my_index.
</code></pre>
<blockquote>
<p><strong>Note:</strong> An error is returned if the index already exists. Delete the data directory to recreate.</p>
</blockquote>
<h3 id="create-schema"><a class="header" href="#create-schema"><code>create schema</code></a></h3>
<p>Interactively generate a schema TOML file through a guided wizard.</p>
<pre><code class="language-bash">laurus create schema [--output &lt;FILE&gt;]
</code></pre>
<p><strong>Arguments:</strong></p>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Flag</th><th style="text-align: left">Required</th><th style="text-align: left">Default</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>--output &lt;FILE&gt;</code></td><td style="text-align: left">No</td><td style="text-align: left"><code>schema.toml</code></td><td style="text-align: left">Output file path for the generated schema</td></tr>
</tbody></table>
</div>
<p>The wizard guides you through:</p>
<ol>
<li><strong>Field definition</strong> — Enter a field name, select the type, and configure type-specific options</li>
<li><strong>Repeat</strong> — Add as many fields as needed</li>
<li><strong>Default fields</strong> — Select which lexical fields to use as default search fields</li>
<li><strong>Preview</strong> — Review the generated TOML before saving</li>
<li><strong>Save</strong> — Write the schema file</li>
</ol>
<p><strong>Supported field types:</strong></p>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Type</th><th style="text-align: left">Category</th><th style="text-align: left">Options</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>Text</code></td><td style="text-align: left">Lexical</td><td style="text-align: left"><code>indexed</code>, <code>stored</code>, <code>term_vectors</code></td></tr>
<tr><td style="text-align: left"><code>Integer</code></td><td style="text-align: left">Lexical</td><td style="text-align: left"><code>indexed</code>, <code>stored</code></td></tr>
<tr><td style="text-align: left"><code>Float</code></td><td style="text-align: left">Lexical</td><td style="text-align: left"><code>indexed</code>, <code>stored</code></td></tr>
<tr><td style="text-align: left"><code>Boolean</code></td><td style="text-align: left">Lexical</td><td style="text-align: left"><code>indexed</code>, <code>stored</code></td></tr>
<tr><td style="text-align: left"><code>DateTime</code></td><td style="text-align: left">Lexical</td><td style="text-align: left"><code>indexed</code>, <code>stored</code></td></tr>
<tr><td style="text-align: left"><code>Geo</code></td><td style="text-align: left">Lexical</td><td style="text-align: left"><code>indexed</code>, <code>stored</code></td></tr>
<tr><td style="text-align: left"><code>Bytes</code></td><td style="text-align: left">Lexical</td><td style="text-align: left"><code>stored</code></td></tr>
<tr><td style="text-align: left"><code>Hnsw</code></td><td style="text-align: left">Vector</td><td style="text-align: left"><code>dimension</code>, <code>distance</code>, <code>m</code>, <code>ef_construction</code></td></tr>
<tr><td style="text-align: left"><code>Flat</code></td><td style="text-align: left">Vector</td><td style="text-align: left"><code>dimension</code>, <code>distance</code></td></tr>
<tr><td style="text-align: left"><code>Ivf</code></td><td style="text-align: left">Vector</td><td style="text-align: left"><code>dimension</code>, <code>distance</code>, <code>n_clusters</code>, <code>n_probe</code></td></tr>
</tbody></table>
</div>
<p><strong>Example:</strong></p>
<pre><code class="language-bash"># Generate schema.toml interactively
laurus create schema

# Specify output path
laurus create schema --output my_schema.toml

# Then create an index from the generated schema
laurus create index --schema schema.toml
</code></pre>
<hr />
<h2 id="get--get-a-resource"><a class="header" href="#get--get-a-resource"><code>get</code> — Get a Resource</a></h2>
<h3 id="get-index"><a class="header" href="#get-index"><code>get index</code></a></h3>
<p>Display statistics about the index.</p>
<pre><code class="language-bash">laurus get index
</code></pre>
<p><strong>Table output example:</strong></p>
<pre><code class="language-text">Document count: 42

Vector fields:
╭──────────┬─────────┬───────────╮
│ Field    │ Vectors │ Dimension │
├──────────┼─────────┼───────────┤
│ text_vec │ 42      │ 384       │
╰──────────┴─────────┴───────────╯
</code></pre>
<p><strong>JSON output example:</strong></p>
<pre><code class="language-bash">laurus --format json get index
</code></pre>
<pre><code class="language-json">{
  "document_count": 42,
  "fields": {
    "text_vec": {
      "vector_count": 42,
      "dimension": 384
    }
  }
}
</code></pre>
<h3 id="get-doc"><a class="header" href="#get-doc"><code>get doc</code></a></h3>
<p>Retrieve a document (and all its chunks) by external ID.</p>
<pre><code class="language-bash">laurus get doc --id &lt;ID&gt;
</code></pre>
<p><strong>Table output example:</strong></p>
<pre><code class="language-text">╭──────┬─────────────────────────────────────────╮
│ ID   │ Fields                                  │
├──────┼─────────────────────────────────────────┤
│ doc1 │ body: This is a test, title: Hello World │
╰──────┴─────────────────────────────────────────╯
</code></pre>
<p><strong>JSON output example:</strong></p>
<pre><code class="language-bash">laurus --format json get doc --id doc1
</code></pre>
<pre><code class="language-json">[
  {
    "id": "doc1",
    "document": {
      "title": "Hello World",
      "body": "This is a test document."
    }
  }
]
</code></pre>
<hr />
<h2 id="add--add-a-resource"><a class="header" href="#add--add-a-resource"><code>add</code> — Add a Resource</a></h2>
<h3 id="add-doc"><a class="header" href="#add-doc"><code>add doc</code></a></h3>
<p>Add a document to the index. Documents are not searchable until <code>commit</code> is called.</p>
<pre><code class="language-bash">laurus add doc --id &lt;ID&gt; --data &lt;JSON&gt;
</code></pre>
<p><strong>Arguments:</strong></p>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Flag</th><th style="text-align: left">Required</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>--id &lt;ID&gt;</code></td><td style="text-align: left">Yes</td><td style="text-align: left">External document ID (string)</td></tr>
<tr><td style="text-align: left"><code>--data &lt;JSON&gt;</code></td><td style="text-align: left">Yes</td><td style="text-align: left">Document fields as a JSON string</td></tr>
</tbody></table>
</div>
<p>The JSON format is a flat object mapping field names to values:</p>
<pre><code class="language-json">{
  "title": "Introduction to Rust",
  "body": "Rust is a systems programming language.",
  "category": "programming"
}
</code></pre>
<p><strong>Example:</strong></p>
<pre><code class="language-bash">laurus add doc --id doc1 --data '{"title":"Hello World","body":"This is a test document."}'
# Document 'doc1' added. Run 'commit' to persist changes.
</code></pre>
<blockquote>
<p><strong>Tip:</strong> Multiple documents can share the same external ID (chunking pattern). Use <code>add doc</code> for each chunk.</p>
</blockquote>
<hr />
<h2 id="delete--delete-a-resource"><a class="header" href="#delete--delete-a-resource"><code>delete</code> — Delete a Resource</a></h2>
<h3 id="delete-doc"><a class="header" href="#delete-doc"><code>delete doc</code></a></h3>
<p>Delete a document (and all its chunks) by external ID.</p>
<pre><code class="language-bash">laurus delete doc --id &lt;ID&gt;
</code></pre>
<p><strong>Example:</strong></p>
<pre><code class="language-bash">laurus delete doc --id doc1
# Document 'doc1' deleted. Run 'commit' to persist changes.
</code></pre>
<hr />
<h2 id="commit"><a class="header" href="#commit"><code>commit</code></a></h2>
<p>Commit pending changes (additions and deletions) to the index. Until committed, changes are not visible to search.</p>
<pre><code class="language-bash">laurus commit
</code></pre>
<p><strong>Example:</strong></p>
<pre><code class="language-bash">laurus --data-dir ./my_index commit
# Changes committed successfully.
</code></pre>
<hr />
<h2 id="search-1"><a class="header" href="#search-1"><code>search</code></a></h2>
<p>Execute a search query using the <a href="cli/../advanced/query_dsl.html">Query DSL</a>.</p>
<pre><code class="language-bash">laurus search &lt;QUERY&gt; [--limit &lt;N&gt;] [--offset &lt;N&gt;]
</code></pre>
<p><strong>Arguments:</strong></p>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Argument / Flag</th><th style="text-align: left">Required</th><th style="text-align: left">Default</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>&lt;QUERY&gt;</code></td><td style="text-align: left">Yes</td><td style="text-align: left">—</td><td style="text-align: left">Query string in Laurus Query DSL</td></tr>
<tr><td style="text-align: left"><code>--limit &lt;N&gt;</code></td><td style="text-align: left">No</td><td style="text-align: left"><code>10</code></td><td style="text-align: left">Maximum number of results</td></tr>
<tr><td style="text-align: left"><code>--offset &lt;N&gt;</code></td><td style="text-align: left">No</td><td style="text-align: left"><code>0</code></td><td style="text-align: left">Number of results to skip</td></tr>
</tbody></table>
</div>
<p><strong>Query syntax examples:</strong></p>
<pre><code class="language-bash"># Term query
laurus search "body:rust"

# Phrase query
laurus search 'body:"machine learning"'

# Boolean query
laurus search "+body:programming -body:python"

# Fuzzy query (typo tolerance)
laurus search "body:programing~2"

# Wildcard query
laurus search "title:intro*"

# Range query
laurus search "price:[10 TO 50]"
</code></pre>
<p><strong>Table output example:</strong></p>
<pre><code class="language-text">╭──────┬────────┬─────────────────────────────────────────╮
│ ID   │ Score  │ Fields                                  │
├──────┼────────┼─────────────────────────────────────────┤
│ doc1 │ 0.8532 │ body: Rust is a systems..., title: Intr │
│ doc3 │ 0.4210 │ body: JavaScript powers..., title: Web  │
╰──────┴────────┴─────────────────────────────────────────╯
</code></pre>
<p><strong>JSON output example:</strong></p>
<pre><code class="language-bash">laurus --format json search "body:rust" --limit 5
</code></pre>
<pre><code class="language-json">[
  {
    "id": "doc1",
    "score": 0.8532,
    "document": {
      "title": "Introduction to Rust",
      "body": "Rust is a systems programming language."
    }
  }
]
</code></pre>
<hr />
<h2 id="repl"><a class="header" href="#repl"><code>repl</code></a></h2>
<p>Start an interactive REPL session. See <a href="cli/repl.html">REPL</a> for details.</p>
<pre><code class="language-bash">laurus repl
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="schema-format-reference"><a class="header" href="#schema-format-reference">Schema Format Reference</a></h1>
<p>The schema file defines the structure of your index — what fields exist, their types, and how they are indexed. Laurus uses TOML format for schema files.</p>
<h2 id="overview-1"><a class="header" href="#overview-1">Overview</a></h2>
<p>A schema consists of two top-level elements:</p>
<pre><code class="language-toml"># Fields to search by default when a query does not specify a field.
default_fields = ["title", "body"]

# Field definitions. Each field has a name and a typed configuration.
[fields.&lt;field_name&gt;.&lt;FieldType&gt;]
# ... type-specific options
</code></pre>
<ul>
<li><strong><code>default_fields</code></strong> — A list of field names used as default search targets by the <a href="cli/../advanced/query_dsl.html">Query DSL</a>. Only lexical fields (Text, Integer, Float, etc.) can be default fields. This key is optional and defaults to an empty list.</li>
<li><strong><code>fields</code></strong> — A map of field names to their typed configuration. Each field must specify exactly one field type.</li>
</ul>
<h2 id="field-naming"><a class="header" href="#field-naming">Field Naming</a></h2>
<ul>
<li>Field names are arbitrary strings (e.g., <code>title</code>, <code>body_vec</code>, <code>created_at</code>).</li>
<li>The <code>_id</code> field is reserved by Laurus for internal document ID management — do not use it.</li>
<li>Field names must be unique within a schema.</li>
</ul>
<h2 id="field-types-1"><a class="header" href="#field-types-1">Field Types</a></h2>
<p>Fields fall into two categories: <strong>Lexical</strong> (for keyword/full-text search) and <strong>Vector</strong> (for similarity search). A single field cannot be both.</p>
<h3 id="lexical-fields-1"><a class="header" href="#lexical-fields-1">Lexical Fields</a></h3>
<h4 id="text"><a class="header" href="#text">Text</a></h4>
<p>Full-text searchable field. Text is processed by the analysis pipeline (tokenization, normalization, stemming, etc.).</p>
<pre><code class="language-toml">[fields.title.Text]
indexed = true       # Whether to index this field for search
stored = true        # Whether to store the original value for retrieval
term_vectors = false # Whether to store term positions (for phrase queries, highlighting)
</code></pre>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Option</th><th style="text-align: left">Type</th><th style="text-align: left">Default</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>indexed</code></td><td style="text-align: left"><code>bool</code></td><td style="text-align: left"><code>true</code></td><td style="text-align: left">Enables searching this field</td></tr>
<tr><td style="text-align: left"><code>stored</code></td><td style="text-align: left"><code>bool</code></td><td style="text-align: left"><code>true</code></td><td style="text-align: left">Stores the original value so it can be returned in results</td></tr>
<tr><td style="text-align: left"><code>term_vectors</code></td><td style="text-align: left"><code>bool</code></td><td style="text-align: left"><code>true</code></td><td style="text-align: left">Stores term positions for phrase queries, highlighting, and more-like-this</td></tr>
</tbody></table>
</div>
<h4 id="integer"><a class="header" href="#integer">Integer</a></h4>
<p>64-bit signed integer field. Supports range queries and exact match.</p>
<pre><code class="language-toml">[fields.year.Integer]
indexed = true
stored = true
</code></pre>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Option</th><th style="text-align: left">Type</th><th style="text-align: left">Default</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>indexed</code></td><td style="text-align: left"><code>bool</code></td><td style="text-align: left"><code>true</code></td><td style="text-align: left">Enables range and exact-match queries</td></tr>
<tr><td style="text-align: left"><code>stored</code></td><td style="text-align: left"><code>bool</code></td><td style="text-align: left"><code>true</code></td><td style="text-align: left">Stores the original value</td></tr>
</tbody></table>
</div>
<h4 id="float"><a class="header" href="#float">Float</a></h4>
<p>64-bit floating point field. Supports range queries.</p>
<pre><code class="language-toml">[fields.rating.Float]
indexed = true
stored = true
</code></pre>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Option</th><th style="text-align: left">Type</th><th style="text-align: left">Default</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>indexed</code></td><td style="text-align: left"><code>bool</code></td><td style="text-align: left"><code>true</code></td><td style="text-align: left">Enables range queries</td></tr>
<tr><td style="text-align: left"><code>stored</code></td><td style="text-align: left"><code>bool</code></td><td style="text-align: left"><code>true</code></td><td style="text-align: left">Stores the original value</td></tr>
</tbody></table>
</div>
<h4 id="boolean"><a class="header" href="#boolean">Boolean</a></h4>
<p>Boolean field (<code>true</code> / <code>false</code>).</p>
<pre><code class="language-toml">[fields.published.Boolean]
indexed = true
stored = true
</code></pre>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Option</th><th style="text-align: left">Type</th><th style="text-align: left">Default</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>indexed</code></td><td style="text-align: left"><code>bool</code></td><td style="text-align: left"><code>true</code></td><td style="text-align: left">Enables filtering by boolean value</td></tr>
<tr><td style="text-align: left"><code>stored</code></td><td style="text-align: left"><code>bool</code></td><td style="text-align: left"><code>true</code></td><td style="text-align: left">Stores the original value</td></tr>
</tbody></table>
</div>
<h4 id="datetime"><a class="header" href="#datetime">DateTime</a></h4>
<p>UTC timestamp field. Supports range queries.</p>
<pre><code class="language-toml">[fields.created_at.DateTime]
indexed = true
stored = true
</code></pre>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Option</th><th style="text-align: left">Type</th><th style="text-align: left">Default</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>indexed</code></td><td style="text-align: left"><code>bool</code></td><td style="text-align: left"><code>true</code></td><td style="text-align: left">Enables range queries on date/time</td></tr>
<tr><td style="text-align: left"><code>stored</code></td><td style="text-align: left"><code>bool</code></td><td style="text-align: left"><code>true</code></td><td style="text-align: left">Stores the original value</td></tr>
</tbody></table>
</div>
<h4 id="geo"><a class="header" href="#geo">Geo</a></h4>
<p>Geographic point field (latitude/longitude). Supports radius and bounding box queries.</p>
<pre><code class="language-toml">[fields.location.Geo]
indexed = true
stored = true
</code></pre>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Option</th><th style="text-align: left">Type</th><th style="text-align: left">Default</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>indexed</code></td><td style="text-align: left"><code>bool</code></td><td style="text-align: left"><code>true</code></td><td style="text-align: left">Enables geo queries (radius, bounding box)</td></tr>
<tr><td style="text-align: left"><code>stored</code></td><td style="text-align: left"><code>bool</code></td><td style="text-align: left"><code>true</code></td><td style="text-align: left">Stores the original value</td></tr>
</tbody></table>
</div>
<h4 id="bytes"><a class="header" href="#bytes">Bytes</a></h4>
<p>Raw binary data field. Not indexed — stored only.</p>
<pre><code class="language-toml">[fields.thumbnail.Bytes]
stored = true
</code></pre>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Option</th><th style="text-align: left">Type</th><th style="text-align: left">Default</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>stored</code></td><td style="text-align: left"><code>bool</code></td><td style="text-align: left"><code>true</code></td><td style="text-align: left">Stores the binary data</td></tr>
</tbody></table>
</div>
<h3 id="vector-fields-1"><a class="header" href="#vector-fields-1">Vector Fields</a></h3>
<p>Vector fields are indexed for approximate nearest neighbor (ANN) search. They require a <code>dimension</code> (the length of each vector) and a <code>distance</code> metric.</p>
<h4 id="hnsw"><a class="header" href="#hnsw">Hnsw</a></h4>
<p>Hierarchical Navigable Small World graph index. Best for most use cases — offers a good balance of speed and recall.</p>
<pre><code class="language-toml">[fields.body_vec.Hnsw]
dimension = 384
distance = "Cosine"
m = 16
ef_construction = 200
base_weight = 1.0
</code></pre>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Option</th><th style="text-align: left">Type</th><th style="text-align: left">Default</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>dimension</code></td><td style="text-align: left"><code>integer</code></td><td style="text-align: left"><code>128</code></td><td style="text-align: left">Vector dimensionality (must match your embedding model)</td></tr>
<tr><td style="text-align: left"><code>distance</code></td><td style="text-align: left"><code>string</code></td><td style="text-align: left"><code>"Cosine"</code></td><td style="text-align: left">Distance metric (see <a href="cli/schema_format.html#distance-metrics">Distance Metrics</a>)</td></tr>
<tr><td style="text-align: left"><code>m</code></td><td style="text-align: left"><code>integer</code></td><td style="text-align: left"><code>16</code></td><td style="text-align: left">Max bi-directional connections per node. Higher = better recall, more memory</td></tr>
<tr><td style="text-align: left"><code>ef_construction</code></td><td style="text-align: left"><code>integer</code></td><td style="text-align: left"><code>200</code></td><td style="text-align: left">Search width during index construction. Higher = better quality, slower build</td></tr>
<tr><td style="text-align: left"><code>base_weight</code></td><td style="text-align: left"><code>float</code></td><td style="text-align: left"><code>1.0</code></td><td style="text-align: left">Scoring weight in hybrid search fusion</td></tr>
<tr><td style="text-align: left"><code>quantizer</code></td><td style="text-align: left"><code>object</code></td><td style="text-align: left"><em>none</em></td><td style="text-align: left">Optional quantization method (see <a href="cli/schema_format.html#quantization">Quantization</a>)</td></tr>
</tbody></table>
</div>
<p><strong>Tuning guidelines:</strong></p>
<ul>
<li><code>m</code>: 12–48 is typical. Use higher values for higher-dimensional vectors.</li>
<li><code>ef_construction</code>: 100–500. Higher values produce a better graph but increase build time.</li>
<li><code>dimension</code>: Must exactly match the output dimension of your embedding model (e.g., 384 for <code>all-MiniLM-L6-v2</code>, 768 for <code>BERT-base</code>, 1536 for <code>text-embedding-3-small</code>).</li>
</ul>
<h4 id="flat"><a class="header" href="#flat">Flat</a></h4>
<p>Brute-force linear scan index. Provides exact results with no approximation. Best for small datasets (&lt; 10,000 vectors).</p>
<pre><code class="language-toml">[fields.embedding.Flat]
dimension = 384
distance = "Cosine"
base_weight = 1.0
</code></pre>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Option</th><th style="text-align: left">Type</th><th style="text-align: left">Default</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>dimension</code></td><td style="text-align: left"><code>integer</code></td><td style="text-align: left"><code>128</code></td><td style="text-align: left">Vector dimensionality</td></tr>
<tr><td style="text-align: left"><code>distance</code></td><td style="text-align: left"><code>string</code></td><td style="text-align: left"><code>"Cosine"</code></td><td style="text-align: left">Distance metric (see <a href="cli/schema_format.html#distance-metrics">Distance Metrics</a>)</td></tr>
<tr><td style="text-align: left"><code>base_weight</code></td><td style="text-align: left"><code>float</code></td><td style="text-align: left"><code>1.0</code></td><td style="text-align: left">Scoring weight in hybrid search fusion</td></tr>
<tr><td style="text-align: left"><code>quantizer</code></td><td style="text-align: left"><code>object</code></td><td style="text-align: left"><em>none</em></td><td style="text-align: left">Optional quantization method (see <a href="cli/schema_format.html#quantization">Quantization</a>)</td></tr>
</tbody></table>
</div>
<h4 id="ivf"><a class="header" href="#ivf">Ivf</a></h4>
<p>Inverted File Index. Clusters vectors and searches only a subset of clusters. Suitable for very large datasets.</p>
<pre><code class="language-toml">[fields.embedding.Ivf]
dimension = 384
distance = "Cosine"
n_clusters = 100
n_probe = 1
base_weight = 1.0
</code></pre>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Option</th><th style="text-align: left">Type</th><th style="text-align: left">Default</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>dimension</code></td><td style="text-align: left"><code>integer</code></td><td style="text-align: left"><em>(required)</em></td><td style="text-align: left">Vector dimensionality</td></tr>
<tr><td style="text-align: left"><code>distance</code></td><td style="text-align: left"><code>string</code></td><td style="text-align: left"><code>"Cosine"</code></td><td style="text-align: left">Distance metric (see <a href="cli/schema_format.html#distance-metrics">Distance Metrics</a>)</td></tr>
<tr><td style="text-align: left"><code>n_clusters</code></td><td style="text-align: left"><code>integer</code></td><td style="text-align: left"><code>100</code></td><td style="text-align: left">Number of clusters. More clusters = finer partitioning</td></tr>
<tr><td style="text-align: left"><code>n_probe</code></td><td style="text-align: left"><code>integer</code></td><td style="text-align: left"><code>1</code></td><td style="text-align: left">Number of clusters to search at query time. Higher = better recall, slower</td></tr>
<tr><td style="text-align: left"><code>base_weight</code></td><td style="text-align: left"><code>float</code></td><td style="text-align: left"><code>1.0</code></td><td style="text-align: left">Scoring weight in hybrid search fusion</td></tr>
<tr><td style="text-align: left"><code>quantizer</code></td><td style="text-align: left"><code>object</code></td><td style="text-align: left"><em>none</em></td><td style="text-align: left">Optional quantization method (see <a href="cli/schema_format.html#quantization">Quantization</a>)</td></tr>
</tbody></table>
</div>
<blockquote>
<p><strong>Note:</strong> Unlike Hnsw and Flat, the <code>dimension</code> field in Ivf is <strong>required</strong> and has no default value.</p>
</blockquote>
<p><strong>Tuning guidelines:</strong></p>
<ul>
<li><code>n_clusters</code>: A common heuristic is <code>sqrt(N)</code> where N is the total number of vectors.</li>
<li><code>n_probe</code>: Start with 1 and increase until recall is acceptable. Typical range is 1–20.</li>
</ul>
<h2 id="distance-metrics-2"><a class="header" href="#distance-metrics-2">Distance Metrics</a></h2>
<p>The <code>distance</code> option for vector fields accepts the following values:</p>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Value</th><th style="text-align: left">Description</th><th style="text-align: left">Use When</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>"Cosine"</code></td><td style="text-align: left">Cosine distance (1 - cosine similarity). Default.</td><td style="text-align: left">Normalized text/image embeddings</td></tr>
<tr><td style="text-align: left"><code>"Euclidean"</code></td><td style="text-align: left">L2 (Euclidean) distance</td><td style="text-align: left">Spatial data, non-normalized vectors</td></tr>
<tr><td style="text-align: left"><code>"Manhattan"</code></td><td style="text-align: left">L1 (Manhattan) distance</td><td style="text-align: left">Sparse feature vectors</td></tr>
<tr><td style="text-align: left"><code>"DotProduct"</code></td><td style="text-align: left">Dot product (higher = more similar)</td><td style="text-align: left">Pre-normalized vectors where magnitude matters</td></tr>
<tr><td style="text-align: left"><code>"Angular"</code></td><td style="text-align: left">Angular distance</td><td style="text-align: left">Similar to cosine, but based on angle</td></tr>
</tbody></table>
</div>
<p>For most embedding models (BERT, Sentence Transformers, OpenAI, etc.), <code>"Cosine"</code> is the correct choice.</p>
<h2 id="quantization-1"><a class="header" href="#quantization-1">Quantization</a></h2>
<p>Vector fields optionally support quantization to reduce memory usage at the cost of some accuracy. Specify the <code>quantizer</code> option as a TOML table.</p>
<h3 id="none-default"><a class="header" href="#none-default">None (default)</a></h3>
<p>No quantization — full precision 32-bit floats.</p>
<pre><code class="language-toml">[fields.embedding.Hnsw]
dimension = 384
distance = "Cosine"
# quantizer is omitted (no quantization)
</code></pre>
<h3 id="scalar-8-bit"><a class="header" href="#scalar-8-bit">Scalar 8-bit</a></h3>
<p>Compresses each float32 component to uint8 (~4x memory reduction).</p>
<pre><code class="language-toml">[fields.embedding.Hnsw]
dimension = 384
distance = "Cosine"
quantizer = "Scalar8Bit"
</code></pre>
<h3 id="product-quantization"><a class="header" href="#product-quantization">Product Quantization</a></h3>
<p>Splits the vector into subvectors and quantizes each independently.</p>
<pre><code class="language-toml">[fields.embedding.Hnsw]
dimension = 384
distance = "Cosine"

[fields.embedding.Hnsw.quantizer.ProductQuantization]
subvector_count = 48
</code></pre>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Option</th><th style="text-align: left">Type</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>subvector_count</code></td><td style="text-align: left"><code>integer</code></td><td style="text-align: left">Number of subvectors. Must evenly divide <code>dimension</code>.</td></tr>
</tbody></table>
</div>
<h2 id="complete-examples"><a class="header" href="#complete-examples">Complete Examples</a></h2>
<h3 id="full-text-search-only"><a class="header" href="#full-text-search-only">Full-text search only</a></h3>
<p>A simple blog post index with lexical search:</p>
<pre><code class="language-toml">default_fields = ["title", "body"]

[fields.title.Text]
indexed = true
stored = true
term_vectors = false

[fields.body.Text]
indexed = true
stored = true
term_vectors = false

[fields.category.Text]
indexed = true
stored = true
term_vectors = false

[fields.published_at.DateTime]
indexed = true
stored = true
</code></pre>
<h3 id="vector-search-only"><a class="header" href="#vector-search-only">Vector search only</a></h3>
<p>A vector-only index for semantic similarity:</p>
<pre><code class="language-toml">[fields.embedding.Hnsw]
dimension = 768
distance = "Cosine"
m = 16
ef_construction = 200
</code></pre>
<h3 id="hybrid-search-lexical--vector"><a class="header" href="#hybrid-search-lexical--vector">Hybrid search (lexical + vector)</a></h3>
<p>Combine lexical and vector search for best-of-both-worlds retrieval:</p>
<pre><code class="language-toml">default_fields = ["title", "body"]

[fields.title.Text]
indexed = true
stored = true
term_vectors = false

[fields.body.Text]
indexed = true
stored = true
term_vectors = true

[fields.category.Text]
indexed = true
stored = true
term_vectors = false

[fields.body_vec.Hnsw]
dimension = 384
distance = "Cosine"
m = 16
ef_construction = 200
</code></pre>
<blockquote>
<p><strong>Tip:</strong> A single field cannot be both lexical and vector. Use separate fields (e.g., <code>body</code> for text, <code>body_vec</code> for embedding) and map them both to the same source content.</p>
</blockquote>
<h3 id="e-commerce-product-index"><a class="header" href="#e-commerce-product-index">E-commerce product index</a></h3>
<p>A more complex schema with mixed field types:</p>
<pre><code class="language-toml">default_fields = ["name", "description"]

[fields.name.Text]
indexed = true
stored = true
term_vectors = false

[fields.description.Text]
indexed = true
stored = true
term_vectors = true

[fields.price.Float]
indexed = true
stored = true

[fields.in_stock.Boolean]
indexed = true
stored = true

[fields.created_at.DateTime]
indexed = true
stored = true

[fields.location.Geo]
indexed = true
stored = true

[fields.description_vec.Hnsw]
dimension = 384
distance = "Cosine"
</code></pre>
<h2 id="generating-a-schema"><a class="header" href="#generating-a-schema">Generating a Schema</a></h2>
<p>You can generate a schema TOML file interactively using the CLI:</p>
<pre><code class="language-bash">laurus create schema
laurus create schema --output my_schema.toml
</code></pre>
<p>See <a href="cli/commands.html#create-schema"><code>create schema</code></a> for details.</p>
<h2 id="using-a-schema"><a class="header" href="#using-a-schema">Using a Schema</a></h2>
<p>Once you have a schema file, create an index from it:</p>
<pre><code class="language-bash">laurus create index --schema schema.toml
</code></pre>
<p>Or load it programmatically in Rust:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::Schema;

let toml_str = std::fs::read_to_string("schema.toml")?;
let schema: Schema = toml::from_str(&amp;toml_str)?;
<span class="boring">}</span></code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="repl-interactive-mode"><a class="header" href="#repl-interactive-mode">REPL (Interactive Mode)</a></h1>
<p>The REPL provides an interactive session for exploring your index without typing the full <code>laurus</code> command each time.</p>
<h2 id="starting-the-repl"><a class="header" href="#starting-the-repl">Starting the REPL</a></h2>
<pre><code class="language-bash">laurus --data-dir ./my_index repl
</code></pre>
<pre><code class="language-text">Laurus REPL (type 'help' for commands, 'quit' to exit)
laurus&gt;
</code></pre>
<p>The REPL opens the index at startup and keeps it loaded throughout the session.</p>
<h2 id="available-commands"><a class="header" href="#available-commands">Available Commands</a></h2>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Command</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>search &lt;query&gt; [limit]</code></td><td style="text-align: left">Search the index</td></tr>
<tr><td style="text-align: left"><code>doc add &lt;id&gt; &lt;json&gt;</code></td><td style="text-align: left">Add a document</td></tr>
<tr><td style="text-align: left"><code>doc get &lt;id&gt;</code></td><td style="text-align: left">Get a document by ID</td></tr>
<tr><td style="text-align: left"><code>doc delete &lt;id&gt;</code></td><td style="text-align: left">Delete a document by ID</td></tr>
<tr><td style="text-align: left"><code>commit</code></td><td style="text-align: left">Commit pending changes</td></tr>
<tr><td style="text-align: left"><code>stats</code></td><td style="text-align: left">Show index statistics</td></tr>
<tr><td style="text-align: left"><code>help</code></td><td style="text-align: left">Show available commands</td></tr>
<tr><td style="text-align: left"><code>quit</code> / <code>exit</code></td><td style="text-align: left">Exit the REPL</td></tr>
</tbody></table>
</div>
<h2 id="usage-examples"><a class="header" href="#usage-examples">Usage Examples</a></h2>
<h3 id="searching"><a class="header" href="#searching">Searching</a></h3>
<pre><code class="language-text">laurus&gt; search body:rust
╭──────┬────────┬────────────────────────────────────╮
│ ID   │ Score  │ Fields                             │
├──────┼────────┼────────────────────────────────────┤
│ doc1 │ 0.8532 │ body: Rust is a systems..., title… │
╰──────┴────────┴────────────────────────────────────╯
</code></pre>
<h3 id="adding-and-committing-documents"><a class="header" href="#adding-and-committing-documents">Adding and Committing Documents</a></h3>
<pre><code class="language-text">laurus&gt; doc add doc4 {"title":"New Document","body":"Some content here."}
Document 'doc4' added.
laurus&gt; commit
Changes committed.
</code></pre>
<h3 id="retrieving-documents-1"><a class="header" href="#retrieving-documents-1">Retrieving Documents</a></h3>
<pre><code class="language-text">laurus&gt; doc get doc4
╭──────┬───────────────────────────────────────────────╮
│ ID   │ Fields                                        │
├──────┼───────────────────────────────────────────────┤
│ doc4 │ body: Some content here., title: New Document │
╰──────┴───────────────────────────────────────────────╯
</code></pre>
<h3 id="deleting-documents-1"><a class="header" href="#deleting-documents-1">Deleting Documents</a></h3>
<pre><code class="language-text">laurus&gt; doc delete doc4
Document 'doc4' deleted.
laurus&gt; commit
Changes committed.
</code></pre>
<h3 id="viewing-statistics"><a class="header" href="#viewing-statistics">Viewing Statistics</a></h3>
<pre><code class="language-text">laurus&gt; stats
Document count: 3
</code></pre>
<h2 id="features-1"><a class="header" href="#features-1">Features</a></h2>
<ul>
<li><strong>Line editing</strong> — Arrow keys, Home/End, and standard readline shortcuts</li>
<li><strong>History</strong> — Use Up/Down arrows to recall previous commands</li>
<li><strong>Ctrl+C / Ctrl+D</strong> — Exit the REPL gracefully</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="advanced-features"><a class="header" href="#advanced-features">Advanced Features</a></h1>
<p>This section covers advanced topics for users who want to go deeper into Laurus's capabilities.</p>
<h2 id="topics-3"><a class="header" href="#topics-3">Topics</a></h2>
<h3 id="query-dsl-2"><a class="header" href="#query-dsl-2"><a href="advanced/query_dsl.html">Query DSL</a></a></h3>
<p>A human-readable query language for lexical, vector, and hybrid search. Supports boolean operators, phrase matching, fuzzy search, range queries, and more — all in a single query string.</p>
<h3 id="id-management"><a class="header" href="#id-management"><a href="advanced/id_management.html">ID Management</a></a></h3>
<p>How Laurus manages document identity with a dual-tiered ID system:</p>
<ul>
<li>External IDs (user-provided strings)</li>
<li>Internal IDs (shard-prefixed <code>u64</code> for performance)</li>
</ul>
<h3 id="persistence--wal"><a class="header" href="#persistence--wal"><a href="advanced/persistence.html">Persistence &amp; WAL</a></a></h3>
<p>How Laurus ensures data durability through Write-Ahead Logging (WAL) and the commit lifecycle.</p>
<h3 id="deletions--compaction"><a class="header" href="#deletions--compaction"><a href="advanced/deletions.html">Deletions &amp; Compaction</a></a></h3>
<p>How documents are deleted (logical deletion via bitmaps) and how space is reclaimed (compaction).</p>
<h3 id="error-handling"><a class="header" href="#error-handling"><a href="advanced/error_handling.html">Error Handling</a></a></h3>
<p>Understanding <code>LaurusError</code> and <code>Result&lt;T&gt;</code> for robust application development. Covers all error variants, matching patterns, and common error scenarios.</p>
<h3 id="extensibility"><a class="header" href="#extensibility"><a href="advanced/extensibility.html">Extensibility</a></a></h3>
<p>Implementing custom components by extending Laurus's trait-based abstractions:</p>
<ul>
<li>Custom <code>Analyzer</code> for text analysis</li>
<li>Custom <code>Embedder</code> for vector embeddings</li>
<li>Custom <code>Storage</code> for new backends</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="query-dsl-3"><a class="header" href="#query-dsl-3">Query DSL</a></h1>
<p>Laurus provides a unified query DSL (Domain Specific Language) that allows lexical (keyword) and vector (semantic) search in a single query string. The <code>UnifiedQueryParser</code> splits the input into lexical and vector portions and delegates to the appropriate sub-parser.</p>
<h2 id="overview-2"><a class="header" href="#overview-2">Overview</a></h2>
<pre><code class="language-text">title:hello AND content:~"cute kitten"^0.8
|--- lexical --|    |--- vector --------|
</code></pre>
<p>The <code>~"</code> pattern distinguishes vector clauses from lexical clauses. Everything else is treated as a lexical query.</p>
<h2 id="lexical-query-syntax"><a class="header" href="#lexical-query-syntax">Lexical Query Syntax</a></h2>
<p>Lexical queries search the inverted index using exact or approximate keyword matching.</p>
<h3 id="term-query"><a class="header" href="#term-query">Term Query</a></h3>
<p>Match a single term against a field (or the default field):</p>
<pre><code class="language-text">hello
title:hello
</code></pre>
<h3 id="boolean-operators"><a class="header" href="#boolean-operators">Boolean Operators</a></h3>
<p>Combine clauses with <code>AND</code> and <code>OR</code> (case-insensitive):</p>
<pre><code class="language-text">title:hello AND body:world
title:hello OR title:goodbye
</code></pre>
<p>Space-separated clauses without an explicit operator use implicit boolean (behaves like OR with scoring).</p>
<h3 id="required--prohibited-clauses"><a class="header" href="#required--prohibited-clauses">Required / Prohibited Clauses</a></h3>
<p>Use <code>+</code> (must match) and <code>-</code> (must not match):</p>
<pre><code class="language-text">+title:hello -title:goodbye
</code></pre>
<h3 id="phrase-query"><a class="header" href="#phrase-query">Phrase Query</a></h3>
<p>Match an exact phrase using double quotes. Optional proximity (<code>~N</code>) allows N words between terms:</p>
<pre><code class="language-text">"hello world"
"hello world"~2
</code></pre>
<h3 id="fuzzy-query"><a class="header" href="#fuzzy-query">Fuzzy Query</a></h3>
<p>Approximate matching with edit distance. Append <code>~</code> and optionally the maximum edit distance:</p>
<pre><code class="language-text">roam~
roam~2
</code></pre>
<h3 id="wildcard-query"><a class="header" href="#wildcard-query">Wildcard Query</a></h3>
<p>Use <code>?</code> (single character) and <code>*</code> (zero or more characters):</p>
<pre><code class="language-text">te?t
test*
</code></pre>
<h3 id="range-query"><a class="header" href="#range-query">Range Query</a></h3>
<p>Inclusive <code>[]</code> or exclusive <code>{}</code> ranges, useful for numeric and date fields:</p>
<pre><code class="language-text">price:[100 TO 500]
date:{2024-01-01 TO 2024-12-31}
price:[* TO 100]
</code></pre>
<h3 id="boost"><a class="header" href="#boost">Boost</a></h3>
<p>Increase the weight of a clause with <code>^</code>:</p>
<pre><code class="language-text">title:hello^2
"important phrase"^1.5
</code></pre>
<h3 id="grouping"><a class="header" href="#grouping">Grouping</a></h3>
<p>Use parentheses for sub-expressions:</p>
<pre><code class="language-text">(title:hello OR title:hi) AND body:world
</code></pre>
<h3 id="peg-grammar"><a class="header" href="#peg-grammar">PEG Grammar</a></h3>
<p>The full lexical grammar (<a href="https://github.com/mosuka/laurus/blob/main/laurus/src/lexical/query/parser.pest">parser.pest</a>):</p>
<pre><code class="language-pest">query          = { SOI ~ boolean_query ~ EOI }
boolean_query  = { clause ~ (boolean_op ~ clause | clause)* }
clause         = { required_clause | prohibited_clause | sub_clause }
required_clause   = { "+" ~ sub_clause }
prohibited_clause = { "-" ~ sub_clause }
sub_clause     = { grouped_query | field_query | term_query }
grouped_query  = { "(" ~ boolean_query ~ ")" ~ boost? }
boolean_op     = { ^"AND" | ^"OR" }
field_query    = { field ~ ":" ~ field_value }
field_value    = { range_query | phrase_query | fuzzy_term
                 | wildcard_term | simple_term }
phrase_query   = { "\"" ~ phrase_content ~ "\"" ~ proximity? ~ boost? }
proximity      = { "~" ~ number }
fuzzy_term     = { term ~ "~" ~ fuzziness? ~ boost? }
wildcard_term  = { wildcard_pattern ~ boost? }
simple_term    = { term ~ boost? }
boost          = { "^" ~ boost_value }
</code></pre>
<h2 id="vector-query-syntax"><a class="header" href="#vector-query-syntax">Vector Query Syntax</a></h2>
<p>Vector queries embed text into vectors at parse time and perform similarity search.</p>
<h3 id="basic-syntax"><a class="header" href="#basic-syntax">Basic Syntax</a></h3>
<pre><code class="language-text">field:~"text"
field:~"text"^weight
</code></pre>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Element</th><th style="text-align: center">Required</th><th style="text-align: left">Description</th><th style="text-align: left">Example</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>field:</code></td><td style="text-align: center">No</td><td style="text-align: left">Target vector field name</td><td style="text-align: left"><code>content:</code></td></tr>
<tr><td style="text-align: left"><code>~</code></td><td style="text-align: center"><strong>Yes</strong></td><td style="text-align: left">Vector query marker</td><td style="text-align: left"></td></tr>
<tr><td style="text-align: left"><code>"text"</code></td><td style="text-align: center"><strong>Yes</strong></td><td style="text-align: left">Text to embed</td><td style="text-align: left"><code>"cute kitten"</code></td></tr>
<tr><td style="text-align: left"><code>^weight</code></td><td style="text-align: center">No</td><td style="text-align: left">Score weight (default: 1.0)</td><td style="text-align: left"><code>^0.8</code></td></tr>
</tbody></table>
</div>
<h3 id="examples-1"><a class="header" href="#examples-1">Examples</a></h3>
<pre><code class="language-text"># Single field
content:~"cute kitten"

# With boost weight
content:~"cute kitten"^0.8

# Default field (when configured)
~"cute kitten"

# Multiple clauses
content:~"cats" image:~"dogs"^0.5

# Nested field name (dot notation)
metadata.embedding:~"text"
</code></pre>
<h3 id="multiple-clauses"><a class="header" href="#multiple-clauses">Multiple Clauses</a></h3>
<p>Multiple vector clauses are space-separated. All clauses are executed and their scores are combined using the <code>score_mode</code> (default: <code>WeightedSum</code>):</p>
<pre><code class="language-text">content:~"cats" image:~"dogs"^0.5
</code></pre>
<p>This produces:</p>
<pre><code class="language-text">score = similarity("cats", content) * 1.0
      + similarity("dogs", image)   * 0.5
</code></pre>
<p>There are no <code>AND</code>/<code>OR</code> operators in the vector DSL. Vector search is inherently a ranking operation, and the weight (<code>^</code>) controls the contribution of each clause.</p>
<h3 id="score-modes-1"><a class="header" href="#score-modes-1">Score Modes</a></h3>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Mode</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>WeightedSum</code> (default)</td><td style="text-align: left">Sum of (similarity * weight) across all clauses</td></tr>
<tr><td style="text-align: left"><code>MaxSim</code></td><td style="text-align: left">Maximum similarity score across clauses</td></tr>
<tr><td style="text-align: left"><code>LateInteraction</code></td><td style="text-align: left">Late interaction scoring</td></tr>
</tbody></table>
</div>
<p>Score mode cannot be set from DSL syntax. Use the Rust API to override:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let mut request = parser.parse(r#"content:~"cats" image:~"dogs""#).await?;
request.score_mode = VectorScoreMode::MaxSim;
<span class="boring">}</span></code></pre></pre>
<h3 id="peg-grammar-1"><a class="header" href="#peg-grammar-1">PEG Grammar</a></h3>
<p>The full vector grammar (<a href="https://github.com/mosuka/laurus/blob/main/laurus/src/vector/query/parser.pest">parser.pest</a>):</p>
<pre><code class="language-pest">query          = { SOI ~ vector_clause+ ~ EOI }
vector_clause  = { field_prefix? ~ "~" ~ quoted_text ~ boost? }
field_prefix   = { field_name ~ ":" }
field_name     = @{ (ASCII_ALPHA | "_") ~ (ASCII_ALPHANUMERIC | "_" | ".")* }
quoted_text    = ${ "\"" ~ inner_text ~ "\"" }
inner_text     = @{ (!("\"") ~ ANY)* }
boost          = { "^" ~ float_value }
float_value    = @{ ASCII_DIGIT+ ~ ("." ~ ASCII_DIGIT+)? }
</code></pre>
<h2 id="unified-hybrid-query-syntax"><a class="header" href="#unified-hybrid-query-syntax">Unified (Hybrid) Query Syntax</a></h2>
<p>The <code>UnifiedQueryParser</code> allows mixing lexical and vector clauses freely in a single query string:</p>
<pre><code>title:hello content:~"cute kitten"^0.8
</code></pre>
<h3 id="how-it-works-2"><a class="header" href="#how-it-works-2">How It Works</a></h3>
<ol>
<li><strong>Split</strong>: Vector clauses (matching <code>field:~"text"^boost</code> pattern) are extracted via regex.</li>
<li><strong>Delegate</strong>: Vector portion goes to <code>VectorQueryParser</code>, remainder goes to lexical <code>QueryParser</code>.</li>
<li><strong>Fuse</strong>: If both lexical and vector results exist, they are combined using a fusion algorithm.</li>
</ol>
<h3 id="disambiguation"><a class="header" href="#disambiguation">Disambiguation</a></h3>
<p>The <code>~"</code> pattern unambiguously identifies vector clauses because in lexical syntax, <code>~</code> only appears <em>after</em> a term or phrase (e.g., <code>roam~2</code>, <code>"hello world"~10</code>), never before a quote.</p>
<h3 id="fusion-algorithms-1"><a class="header" href="#fusion-algorithms-1">Fusion Algorithms</a></h3>
<p>When a query contains both lexical and vector clauses, results are fused:</p>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Algorithm</th><th style="text-align: left">Formula</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><strong>RRF</strong> (default)</td><td style="text-align: left"><code>score = sum(1 / (k + rank))</code></td><td style="text-align: left">Reciprocal Rank Fusion. Robust to different score distributions. Default k=60.</td></tr>
<tr><td style="text-align: left"><strong>WeightedSum</strong></td><td style="text-align: left"><code>score = lexical * a + vector * b</code></td><td style="text-align: left">Linear combination with configurable weights.</td></tr>
</tbody></table>
</div>
<blockquote>
<p><strong>Note</strong>: The fusion algorithm cannot be specified in the DSL syntax. It is configured when constructing the <code>UnifiedQueryParser</code> via <code>.with_fusion()</code>. The default is RRF (k=60). See <a href="advanced/query_dsl.html#custom-fusion">Custom Fusion</a> for a code example.</p>
</blockquote>
<h3 id="examples-2"><a class="header" href="#examples-2">Examples</a></h3>
<pre><code># Lexical only — no fusion
title:hello AND body:world

# Vector only — no fusion
content:~"cute kitten"

# Hybrid — fusion applied automatically
title:hello content:~"cute kitten"

# Hybrid with boolean operators
title:hello AND category:animal content:~"cute kitten"^0.8

# Multiple vector clauses + lexical
category:animal content:~"cats" image:~"dogs"^0.5

# Default fields (when configured)
hello ~"cats"
</code></pre>
<h2 id="code-examples"><a class="header" href="#code-examples">Code Examples</a></h2>
<h3 id="lexical-search-with-dsl"><a class="header" href="#lexical-search-with-dsl">Lexical Search with DSL</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use std::sync::Arc;
use laurus::analysis::analyzer::standard::StandardAnalyzer;
use laurus::lexical::query::QueryParser;

let analyzer = Arc::new(StandardAnalyzer::new()?);
let parser = QueryParser::new(analyzer)
    .with_default_field("title");

let query = parser.parse("title:hello AND body:world")?;
<span class="boring">}</span></code></pre></pre>
<h3 id="vector-search-with-dsl"><a class="header" href="#vector-search-with-dsl">Vector Search with DSL</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use std::sync::Arc;
use laurus::vector::query::VectorQueryParser;

let parser = VectorQueryParser::new(embedder)
    .with_default_field("content");

let request = parser.parse(r#"content:~"cute kitten"^0.8"#).await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="hybrid-search-with-unified-dsl"><a class="header" href="#hybrid-search-with-unified-dsl">Hybrid Search with Unified DSL</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::engine::query::UnifiedQueryParser;

let unified = UnifiedQueryParser::new(lexical_parser, vector_parser);

let request = unified.parse(
    r#"title:hello content:~"cute kitten"^0.8"#
).await?;
// request.lexical_search_request  -&gt; Some(...)  — lexical query
// request.vector_search_request   -&gt; Some(...)  — vector query
// request.fusion_algorithm        -&gt; Some(RRF)  — fusion algorithm
<span class="boring">}</span></code></pre></pre>
<h3 id="custom-fusion"><a class="header" href="#custom-fusion">Custom Fusion</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::engine::search::FusionAlgorithm;

let unified = UnifiedQueryParser::new(lexical_parser, vector_parser)
    .with_fusion(FusionAlgorithm::WeightedSum {
        lexical_weight: 0.3,
        vector_weight: 0.7,
    });
<span class="boring">}</span></code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="id-management-1"><a class="header" href="#id-management-1">ID Management</a></h1>
<p>Laurus uses a dual-tiered ID management strategy to ensure efficient document retrieval, updates, and aggregation in distributed environments.</p>
<h2 id="1-external-id-string"><a class="header" href="#1-external-id-string">1. External ID (String)</a></h2>
<p>The External ID is a <strong>logical identifier</strong> used by users and applications to uniquely identify a document.</p>
<ul>
<li><strong>Type</strong>: <code>String</code></li>
<li><strong>Role</strong>: You can use any unique value, such as UUIDs, URLs, or database primary keys.</li>
<li><strong>Storage</strong>: Persisted transparently as a reserved system field name <code>_id</code> within the Lexical Index.</li>
<li><strong>Uniqueness</strong>: Expected to be unique across the entire system.</li>
<li><strong>Updates</strong>: Indexing a document with an existing <code>external_id</code> triggers an automatic "Delete-then-Insert" (Upsert) operation, replacing the old version with the newest.</li>
</ul>
<h2 id="2-internal-id-u64--stable-id"><a class="header" href="#2-internal-id-u64--stable-id">2. Internal ID (u64 / Stable ID)</a></h2>
<p>The Internal ID is a <strong>physical handle</strong> used internally by Laurus's engines (Lexical and Vector) for high-performance operations.</p>
<ul>
<li><strong>Type</strong>: Unsigned 64-bit Integer (<code>u64</code>)</li>
<li><strong>Role</strong>: Used for bitmap operations, point references, and routing between distributed nodes.</li>
<li><strong>Immutability (Stable)</strong>: Once assigned, an Internal ID never changes due to index merges (segment compaction) or restarts. This prevents inconsistencies in deletion logs and caches.</li>
</ul>
<h3 id="id-structure-shard-prefixed"><a class="header" href="#id-structure-shard-prefixed">ID Structure (Shard-Prefixed)</a></h3>
<p>Laurus employs a <strong>Shard-Prefixed Stable ID</strong> scheme designed for multi-node distributed environments.</p>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Bit Range</th><th style="text-align: left">Name</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><strong>48-63 bit</strong></td><td style="text-align: left"><strong>Shard ID</strong></td><td style="text-align: left">Prefix identifying the node or partition (up to 65,535 shards).</td></tr>
<tr><td style="text-align: left"><strong>0-47 bit</strong></td><td style="text-align: left"><strong>Local ID</strong></td><td style="text-align: left">Monotonically increasing document number within a shard (up to ~281 trillion documents).</td></tr>
</tbody></table>
</div>
<h4 id="why-this-structure"><a class="header" href="#why-this-structure">Why this structure?</a></h4>
<ol>
<li><strong>Zero-Cost Aggregation</strong>: Since <code>u64</code> IDs are globally unique, the aggregator can perform fast sorting and deduplication without worrying about ID collisions between nodes.</li>
<li><strong>Fast Routing</strong>: The aggregator can immediately identify the physical node responsible for a document just by looking at the upper bits, avoiding expensive hash lookups.</li>
<li><strong>High-Performance Fetching</strong>: Internal IDs map directly to physical data structures. This allows Laurus to skip the "External-to-Internal ID" conversion step during retrieval, achieving <strong>O(1)</strong> access speed.</li>
</ol>
<h2 id="id-lifecycle"><a class="header" href="#id-lifecycle">ID Lifecycle</a></h2>
<ol>
<li><strong>Registration (<code>engine.put_document()</code> / <code>engine.add_document()</code>)</strong>: User provides a document with an External ID.</li>
<li><strong>ID Assignment</strong>: The <code>Engine</code> combines the current <code>shard_id</code> with a new Local ID to issue a Shard-Prefixed Internal ID.</li>
<li><strong>Mapping</strong>: The engine maintains the relationship between the External ID and the new Internal ID.</li>
<li><strong>Search</strong>: Search results return the External ID (<code>String</code>), resolved from the Internal ID.</li>
<li><strong>Retrieval/Deletion</strong>: While the user-facing API accepts External IDs for convenience, the engine internally converts them to Internal IDs for near-instant processing.</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="persistence--wal-1"><a class="header" href="#persistence--wal-1">Persistence &amp; WAL</a></h1>
<p>Laurus uses a <strong>Write-Ahead Log (WAL)</strong> to ensure data durability. Every write operation is persisted to the WAL before modifying in-memory structures, guaranteeing that no data is lost even if the process crashes.</p>
<h2 id="write-path"><a class="header" href="#write-path">Write Path</a></h2>
<pre><code class="language-mermaid">sequenceDiagram
    participant App as Application
    participant Engine
    participant WAL as DocumentLog (WAL)
    participant Mem as In-Memory Buffers
    participant Disk as Storage (segments)

    App-&gt;&gt;Engine: add_document() / delete_documents()
    Engine-&gt;&gt;WAL: 1. Append operation to WAL
    Engine-&gt;&gt;Mem: 2. Update in-memory buffers

    Note over Mem: Document is buffered but\nNOT yet searchable

    App-&gt;&gt;Engine: commit()
    Engine-&gt;&gt;Disk: 3. Flush segments to storage
    Engine-&gt;&gt;WAL: 4. Truncate WAL
    Note over Disk: Documents are now\nsearchable and durable
</code></pre>
<h3 id="key-principles"><a class="header" href="#key-principles">Key Principles</a></h3>
<ol>
<li><strong>WAL-first</strong>: Every write (add or delete) is appended to the WAL before updating in-memory structures</li>
<li><strong>Buffered writes</strong>: In-memory buffers accumulate changes until <code>commit()</code> is called</li>
<li><strong>Atomic commit</strong>: <code>commit()</code> flushes all buffered changes to segment files and truncates the WAL</li>
<li><strong>Crash safety</strong>: If the process crashes between writes and commit, the WAL is replayed on the next startup</li>
</ol>
<h2 id="write-ahead-log-wal"><a class="header" href="#write-ahead-log-wal">Write-Ahead Log (WAL)</a></h2>
<p>The WAL is managed by the <code>DocumentLog</code> component and stored at the root level of the storage backend (<code>engine.wal</code>).</p>
<h3 id="wal-entry-types"><a class="header" href="#wal-entry-types">WAL Entry Types</a></h3>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Entry Type</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><strong>Upsert</strong></td><td style="text-align: left">Document content + external ID + assigned internal ID</td></tr>
<tr><td style="text-align: left"><strong>Delete</strong></td><td style="text-align: left">External ID of the document to remove</td></tr>
</tbody></table>
</div>
<h3 id="wal-file"><a class="header" href="#wal-file">WAL File</a></h3>
<p>The WAL file (<code>engine.wal</code>) is an append-only binary log. Each entry is self-contained with:</p>
<ul>
<li>Operation type (add/delete)</li>
<li>Sequence number</li>
<li>Payload (document data or ID)</li>
</ul>
<h2 id="recovery"><a class="header" href="#recovery">Recovery</a></h2>
<p>When an engine is built (<code>Engine::builder(...).build().await</code>), it automatically checks for remaining WAL entries and replays them (the WAL is truncated on commit, so any remaining entries are from a crashed session):</p>
<pre><code class="language-mermaid">graph TD
    Start["Engine::build()"] --&gt; Check["Check WAL for\nuncommitted entries"]
    Check --&gt;|"Entries found"| Replay["Replay operations\ninto in-memory buffers"]
    Replay --&gt; Ready["Engine ready"]
    Check --&gt;|"No entries"| Ready
</code></pre>
<p>Recovery is transparent — you do not need to handle it manually.</p>
<h2 id="the-commit-lifecycle"><a class="header" href="#the-commit-lifecycle">The Commit Lifecycle</a></h2>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// 1. Add documents (buffered, not yet searchable)
engine.add_document("doc-1", doc1).await?;
engine.add_document("doc-2", doc2).await?;

// 2. Commit — flush to persistent storage
engine.commit().await?;
// Documents are now searchable

// 3. Add more documents
engine.add_document("doc-3", doc3).await?;

// 4. If the process crashes here, doc-3 is in the WAL
//    and will be recovered on next startup
<span class="boring">}</span></code></pre></pre>
<h3 id="when-to-commit"><a class="header" href="#when-to-commit">When to Commit</a></h3>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Strategy</th><th style="text-align: left">Description</th><th style="text-align: left">Use Case</th></tr></thead><tbody>
<tr><td style="text-align: left"><strong>After each document</strong></td><td style="text-align: left">Maximum durability, minimum search latency</td><td style="text-align: left">Real-time search with few writes</td></tr>
<tr><td style="text-align: left"><strong>After a batch</strong></td><td style="text-align: left">Good balance of throughput and latency</td><td style="text-align: left">Bulk indexing</td></tr>
<tr><td style="text-align: left"><strong>Periodically</strong></td><td style="text-align: left">Maximum write throughput</td><td style="text-align: left">High-volume ingestion</td></tr>
</tbody></table>
</div>
<blockquote>
<p><strong>Tip:</strong> Commits are relatively expensive because they flush segments to storage. For bulk indexing, batch many documents before calling <code>commit()</code>.</p>
</blockquote>
<h2 id="storage-layout"><a class="header" href="#storage-layout">Storage Layout</a></h2>
<p>The engine uses <code>PrefixedStorage</code> to organize data:</p>
<pre><code>&lt;storage root&gt;/
├── lexical/          # Inverted index segments
│   ├── seg-000/
│   │   ├── terms.dict
│   │   ├── postings.post
│   │   └── ...
│   └── metadata.json
├── vector/           # Vector index segments
│   ├── seg-000/
│   │   ├── graph.hnsw
│   │   ├── vectors.vecs
│   │   └── ...
│   └── metadata.json
├── documents/        # Document storage
│   └── ...
└── engine.wal        # Write-ahead log
</code></pre>
<h2 id="next-steps-8"><a class="header" href="#next-steps-8">Next Steps</a></h2>
<ul>
<li>How deletions are handled: <a href="advanced/deletions.html">Deletions &amp; Compaction</a></li>
<li>Storage backends: <a href="advanced/../concepts/storage.html">Storage</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="deletions--compaction-1"><a class="header" href="#deletions--compaction-1">Deletions &amp; Compaction</a></h1>
<p>Laurus uses a two-phase deletion strategy: fast <strong>logical deletion</strong> followed by periodic <strong>physical compaction</strong>.</p>
<h2 id="deleting-documents-2"><a class="header" href="#deleting-documents-2">Deleting Documents</a></h2>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Delete a document by its external ID
engine.delete_documents("doc-1").await?;
engine.commit().await?;
<span class="boring">}</span></code></pre></pre>
<h2 id="logical-deletion"><a class="header" href="#logical-deletion">Logical Deletion</a></h2>
<p>When a document is deleted, it is <strong>not</strong> immediately removed from the index files. Instead:</p>
<pre><code class="language-mermaid">graph LR
    Del["delete_documents('doc-1')"] --&gt; Bitmap["Add internal ID\nto Deletion Bitmap"]
    Bitmap --&gt; Search["Search skips\ndeleted IDs"]
</code></pre>
<ol>
<li>The document's internal ID is added to a <strong>deletion bitmap</strong></li>
<li>The bitmap is checked during every search, filtering out deleted documents from results</li>
<li>The original data remains in the segment files</li>
</ol>
<h3 id="why-logical-deletion"><a class="header" href="#why-logical-deletion">Why Logical Deletion?</a></h3>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Benefit</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><strong>Speed</strong></td><td style="text-align: left">O(1) — flipping a bit is instant</td></tr>
<tr><td style="text-align: left"><strong>Immutable segments</strong></td><td style="text-align: left">Segment files are never modified in place, simplifying concurrency</td></tr>
<tr><td style="text-align: left"><strong>Safe recovery</strong></td><td style="text-align: left">If a crash occurs, the deletion bitmap can be reconstructed from the WAL</td></tr>
</tbody></table>
</div>
<h2 id="upserts-update--delete--insert"><a class="header" href="#upserts-update--delete--insert">Upserts (Update = Delete + Insert)</a></h2>
<p>When you index a document with an existing external ID, Laurus performs an automatic upsert:</p>
<ol>
<li>The old document is logically deleted (its ID is added to the deletion bitmap)</li>
<li>A new document is inserted with a new internal ID</li>
<li>The external-to-internal ID mapping is updated</li>
</ol>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// First insert
engine.put_document("doc-1", doc_v1).await?;
engine.commit().await?;

// Update: old version is logically deleted, new version is inserted
engine.put_document("doc-1", doc_v2).await?;
engine.commit().await?;
<span class="boring">}</span></code></pre></pre>
<h2 id="physical-compaction"><a class="header" href="#physical-compaction">Physical Compaction</a></h2>
<p>Over time, logically deleted documents accumulate and waste space. Compaction reclaims this space by rewriting segment files without the deleted entries.</p>
<pre><code class="language-mermaid">graph LR
    subgraph "Before Compaction"
        S1["Segment 0\ndoc-1 (deleted)\ndoc-2\ndoc-3 (deleted)"]
        S2["Segment 1\ndoc-4\ndoc-5"]
    end

    Compact["Compaction"]

    subgraph "After Compaction"
        S3["Segment 0\ndoc-2\ndoc-4\ndoc-5"]
    end

    S1 --&gt; Compact
    S2 --&gt; Compact
    Compact --&gt; S3
</code></pre>
<h3 id="what-compaction-does"><a class="header" href="#what-compaction-does">What Compaction Does</a></h3>
<ol>
<li>Reads all live (non-deleted) documents from existing segments</li>
<li>Rebuilds the inverted index and/or vector index without deleted entries</li>
<li>Writes new, clean segment files</li>
<li>Removes the old segment files</li>
<li>Resets the deletion bitmap</li>
</ol>
<h3 id="cost-and-frequency"><a class="header" href="#cost-and-frequency">Cost and Frequency</a></h3>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Aspect</th><th style="text-align: left">Detail</th></tr></thead><tbody>
<tr><td style="text-align: left"><strong>CPU cost</strong></td><td style="text-align: left">High — rebuilds index structures from scratch</td></tr>
<tr><td style="text-align: left"><strong>I/O cost</strong></td><td style="text-align: left">High — reads all data, writes new segments</td></tr>
<tr><td style="text-align: left"><strong>Blocking</strong></td><td style="text-align: left">Searches continue during compaction (reads see the old segments until the new ones are ready)</td></tr>
<tr><td style="text-align: left"><strong>Frequency</strong></td><td style="text-align: left">Run when deleted documents exceed a threshold (e.g., 10-20% of total)</td></tr>
</tbody></table>
</div>
<h3 id="when-to-compact"><a class="header" href="#when-to-compact">When to Compact</a></h3>
<ul>
<li><strong>Low-write workloads</strong>: Compact periodically (e.g., daily or weekly)</li>
<li><strong>High-write workloads</strong>: Compact when the deletion ratio exceeds a threshold</li>
<li><strong>After bulk updates</strong>: Compact after a large batch of upserts</li>
</ul>
<h2 id="deletion-bitmap"><a class="header" href="#deletion-bitmap">Deletion Bitmap</a></h2>
<p>The deletion bitmap tracks which internal IDs have been deleted:</p>
<ul>
<li><strong>Storage</strong>: HashSet of deleted document IDs (<code>AHashSet&lt;u64&gt;</code>)</li>
<li><strong>Lookup</strong>: O(1) — hash set lookup</li>
</ul>
<p>The bitmap is persisted alongside the index segments and is rebuilt from the WAL during recovery.</p>
<h2 id="next-steps-9"><a class="header" href="#next-steps-9">Next Steps</a></h2>
<ul>
<li>How data is persisted: <a href="advanced/persistence.html">Persistence &amp; WAL</a></li>
<li>ID management and internal/external ID mapping: <a href="advanced/id_management.html">ID Management</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="error-handling-1"><a class="header" href="#error-handling-1">Error Handling</a></h1>
<p>Laurus uses a unified error type for all operations. Understanding the error system helps you write robust applications that handle failures gracefully.</p>
<h2 id="lauruserror"><a class="header" href="#lauruserror">LaurusError</a></h2>
<p>All Laurus operations return <code>Result&lt;T&gt;</code>, which is an alias for <code>std::result::Result&lt;T, LaurusError&gt;</code>.</p>
<p><code>LaurusError</code> is an enum with variants for each category of failure:</p>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Variant</th><th style="text-align: left">Description</th><th style="text-align: left">Common Causes</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>Io</code></td><td style="text-align: left">I/O errors</td><td style="text-align: left">File not found, permission denied, disk full</td></tr>
<tr><td style="text-align: left"><code>Index</code></td><td style="text-align: left">Index operation errors</td><td style="text-align: left">Corrupt index, segment read failure</td></tr>
<tr><td style="text-align: left"><code>Schema</code></td><td style="text-align: left">Schema-related errors</td><td style="text-align: left">Unknown field name, type mismatch</td></tr>
<tr><td style="text-align: left"><code>Analysis</code></td><td style="text-align: left">Text analysis errors</td><td style="text-align: left">Tokenizer failure, invalid filter config</td></tr>
<tr><td style="text-align: left"><code>Query</code></td><td style="text-align: left">Query parsing/execution errors</td><td style="text-align: left">Malformed Query DSL, unknown field in query</td></tr>
<tr><td style="text-align: left"><code>Storage</code></td><td style="text-align: left">Storage backend errors</td><td style="text-align: left">Failed to open storage, write failure</td></tr>
<tr><td style="text-align: left"><code>Field</code></td><td style="text-align: left">Field definition errors</td><td style="text-align: left">Invalid field options, duplicate field name</td></tr>
<tr><td style="text-align: left"><code>Json</code></td><td style="text-align: left">JSON serialization errors</td><td style="text-align: left">Malformed document JSON</td></tr>
<tr><td style="text-align: left"><code>InvalidOperation</code></td><td style="text-align: left">Invalid operation</td><td style="text-align: left">Searching before commit, double close</td></tr>
<tr><td style="text-align: left"><code>ResourceExhausted</code></td><td style="text-align: left">Resource limits exceeded</td><td style="text-align: left">Out of memory, too many open files</td></tr>
<tr><td style="text-align: left"><code>SerializationError</code></td><td style="text-align: left">Binary serialization errors</td><td style="text-align: left">Corrupt data on disk</td></tr>
<tr><td style="text-align: left"><code>OperationCancelled</code></td><td style="text-align: left">Operation was cancelled</td><td style="text-align: left">Timeout, user cancellation</td></tr>
<tr><td style="text-align: left"><code>NotImplemented</code></td><td style="text-align: left">Feature not available</td><td style="text-align: left">Unimplemented operation</td></tr>
<tr><td style="text-align: left"><code>Other</code></td><td style="text-align: left">Generic errors</td><td style="text-align: left">Timeout, invalid config, invalid argument</td></tr>
</tbody></table>
</div>
<h2 id="basic-error-handling"><a class="header" href="#basic-error-handling">Basic Error Handling</a></h2>
<h3 id="using-the--operator"><a class="header" href="#using-the--operator">Using the <code>?</code> Operator</a></h3>
<p>The simplest approach — propagate errors to the caller:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::{Engine, Result};

async fn index_documents(engine: &amp;Engine) -&gt; Result&lt;()&gt; {
    let doc = laurus::Document::builder()
        .add_text("title", "Rust Programming")
        .build();

    engine.put_document("doc1", doc).await?;
    engine.commit().await?;
    Ok(())
}
<span class="boring">}</span></code></pre></pre>
<h3 id="matching-on-error-variants"><a class="header" href="#matching-on-error-variants">Matching on Error Variants</a></h3>
<p>When you need different behavior for different error types:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::{Engine, LaurusError};

async fn safe_search(engine: &amp;Engine, query: &amp;str) {
    match engine.search(/* request */).await {
        Ok(results) =&gt; {
            for result in results {
                println!("{}: {}", result.id, result.score);
            }
        }
        Err(LaurusError::Query(msg)) =&gt; {
            eprintln!("Invalid query syntax: {}", msg);
        }
        Err(LaurusError::Io(e)) =&gt; {
            eprintln!("Storage I/O error: {}", e);
        }
        Err(e) =&gt; {
            eprintln!("Unexpected error: {}", e);
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="checking-error-types-with-downcast"><a class="header" href="#checking-error-types-with-downcast">Checking Error Types with <code>downcast</code></a></h3>
<p>Since <code>LaurusError</code> implements <code>std::error::Error</code>, you can use standard error handling patterns:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::LaurusError;

fn is_retriable(error: &amp;LaurusError) -&gt; bool {
    matches!(error, LaurusError::Io(_) | LaurusError::ResourceExhausted(_))
}
<span class="boring">}</span></code></pre></pre>
<h2 id="common-error-scenarios"><a class="header" href="#common-error-scenarios">Common Error Scenarios</a></h2>
<h3 id="schema-mismatch"><a class="header" href="#schema-mismatch">Schema Mismatch</a></h3>
<p>Adding a document with fields that don't match the schema:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Schema has "title" (Text) and "year" (Integer)
let doc = Document::builder()
    .add_text("title", "Hello")
    .add_text("unknown_field", "this field is not in schema")
    .build();

// Fields not in the schema are silently ignored during indexing.
// No error is raised — only schema-defined fields are processed.
<span class="boring">}</span></code></pre></pre>
<h3 id="query-parsing-errors"><a class="header" href="#query-parsing-errors">Query Parsing Errors</a></h3>
<p>Invalid Query DSL syntax returns a <code>Query</code> error:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::engine::query::UnifiedQueryParser;

let parser = UnifiedQueryParser::new();
match parser.parse("title:\"unclosed phrase") {
    Ok(request) =&gt; { /* ... */ }
    Err(LaurusError::Query(msg)) =&gt; {
        // msg contains details about the parse failure
        eprintln!("Bad query: {}", msg);
    }
    Err(e) =&gt; { /* other errors */ }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="storage-io-errors"><a class="header" href="#storage-io-errors">Storage I/O Errors</a></h3>
<p>File-based storage may encounter I/O errors:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::storage::{StorageConfig, StorageFactory};

match StorageFactory::open(StorageConfig::File {
    path: "/nonexistent/path".into(),
    loading_mode: Default::default(),
}) {
    Ok(storage) =&gt; { /* ... */ }
    Err(LaurusError::Io(e)) =&gt; {
        eprintln!("Cannot open storage: {}", e);
    }
    Err(e) =&gt; { /* other errors */ }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="convenience-constructors"><a class="header" href="#convenience-constructors">Convenience Constructors</a></h2>
<p><code>LaurusError</code> provides factory methods for creating errors in custom implementations:</p>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Method</th><th style="text-align: left">Creates</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>LaurusError::index(msg)</code></td><td style="text-align: left"><code>Index</code> variant</td></tr>
<tr><td style="text-align: left"><code>LaurusError::schema(msg)</code></td><td style="text-align: left"><code>Schema</code> variant</td></tr>
<tr><td style="text-align: left"><code>LaurusError::analysis(msg)</code></td><td style="text-align: left"><code>Analysis</code> variant</td></tr>
<tr><td style="text-align: left"><code>LaurusError::query(msg)</code></td><td style="text-align: left"><code>Query</code> variant</td></tr>
<tr><td style="text-align: left"><code>LaurusError::storage(msg)</code></td><td style="text-align: left"><code>Storage</code> variant</td></tr>
<tr><td style="text-align: left"><code>LaurusError::field(msg)</code></td><td style="text-align: left"><code>Field</code> variant</td></tr>
<tr><td style="text-align: left"><code>LaurusError::other(msg)</code></td><td style="text-align: left"><code>Other</code> variant</td></tr>
<tr><td style="text-align: left"><code>LaurusError::cancelled(msg)</code></td><td style="text-align: left"><code>OperationCancelled</code> variant</td></tr>
<tr><td style="text-align: left"><code>LaurusError::invalid_argument(msg)</code></td><td style="text-align: left"><code>Other</code> with "Invalid argument" prefix</td></tr>
<tr><td style="text-align: left"><code>LaurusError::invalid_config(msg)</code></td><td style="text-align: left"><code>Other</code> with "Invalid configuration" prefix</td></tr>
<tr><td style="text-align: left"><code>LaurusError::not_found(msg)</code></td><td style="text-align: left"><code>Other</code> with "Not found" prefix</td></tr>
<tr><td style="text-align: left"><code>LaurusError::timeout(msg)</code></td><td style="text-align: left"><code>Other</code> with "Timeout" prefix</td></tr>
</tbody></table>
</div>
<p>These are useful when implementing custom <a href="advanced/extensibility.html">Analyzer, Embedder, or Storage</a> traits:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::{LaurusError, Result};

fn validate_dimension(dim: usize) -&gt; Result&lt;()&gt; {
    if dim == 0 {
        return Err(LaurusError::invalid_argument("dimension must be &gt; 0"));
    }
    Ok(())
}
<span class="boring">}</span></code></pre></pre>
<h2 id="automatic-conversions"><a class="header" href="#automatic-conversions">Automatic Conversions</a></h2>
<p><code>LaurusError</code> implements <code>From</code> for common error types, so they convert automatically with <code>?</code>:</p>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Source Type</th><th style="text-align: left">Target Variant</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>std::io::Error</code></td><td style="text-align: left"><code>LaurusError::Io</code></td></tr>
<tr><td style="text-align: left"><code>serde_json::Error</code></td><td style="text-align: left"><code>LaurusError::Json</code></td></tr>
<tr><td style="text-align: left"><code>anyhow::Error</code></td><td style="text-align: left"><code>LaurusError::Anyhow</code></td></tr>
</tbody></table>
</div>
<h2 id="next-steps-10"><a class="header" href="#next-steps-10">Next Steps</a></h2>
<ul>
<li><a href="advanced/extensibility.html">Extensibility</a> — implement custom traits with proper error handling</li>
<li><a href="advanced/../api_reference.html">API Reference</a> — full method signatures and return types</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="extensibility-1"><a class="header" href="#extensibility-1">Extensibility</a></h1>
<p>Laurus uses trait-based abstractions for its core components. You can implement these traits to provide custom analyzers, embedders, and storage backends.</p>
<h2 id="custom-analyzer"><a class="header" href="#custom-analyzer">Custom Analyzer</a></h2>
<p>Implement the <code>Analyzer</code> trait to create a custom text analysis pipeline:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::analysis::analyzer::analyzer::Analyzer;
use laurus::analysis::token::{Token, TokenStream};
use laurus::Result;

#[derive(Debug)]
struct ReverseAnalyzer;

impl Analyzer for ReverseAnalyzer {
    fn analyze(&amp;self, text: &amp;str) -&gt; Result&lt;TokenStream&gt; {
        let tokens: Vec&lt;Token&gt; = text
            .split_whitespace()
            .enumerate()
            .map(|(i, word)| Token {
                text: word.chars().rev().collect(),
                position: i,
                ..Default::default()
            })
            .collect();
        Ok(Box::new(tokens.into_iter()))
    }

    fn name(&amp;self) -&gt; &amp;str {
        "reverse"
    }

    fn as_any(&amp;self) -&gt; &amp;dyn std::any::Any {
        self
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="required-methods"><a class="header" href="#required-methods">Required Methods</a></h3>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Method</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>analyze(&amp;self, text: &amp;str) -&gt; Result&lt;TokenStream&gt;</code></td><td style="text-align: left">Process text into a stream of tokens</td></tr>
<tr><td style="text-align: left"><code>name(&amp;self) -&gt; &amp;str</code></td><td style="text-align: left">Return a unique identifier for this analyzer</td></tr>
<tr><td style="text-align: left"><code>as_any(&amp;self) -&gt; &amp;dyn Any</code></td><td style="text-align: left">Enable downcasting to the concrete type</td></tr>
</tbody></table>
</div>
<h3 id="using-a-custom-analyzer"><a class="header" href="#using-a-custom-analyzer">Using a Custom Analyzer</a></h3>
<p>Pass your analyzer to <code>EngineBuilder</code>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use std::sync::Arc;

let analyzer = Arc::new(ReverseAnalyzer);
let engine = Engine::builder(storage, schema)
    .analyzer(analyzer)
    .build()
    .await?;
<span class="boring">}</span></code></pre></pre>
<p>For per-field analyzers, wrap with <code>PerFieldAnalyzer</code>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::analysis::analyzer::per_field::PerFieldAnalyzer;
use laurus::analysis::analyzer::standard::StandardAnalyzer;

let mut per_field = PerFieldAnalyzer::new(Arc::new(StandardAnalyzer::new()?));
per_field.add_analyzer("custom_field", Arc::new(ReverseAnalyzer));

let engine = Engine::builder(storage, schema)
    .analyzer(Arc::new(per_field))
    .build()
    .await?;
<span class="boring">}</span></code></pre></pre>
<h2 id="custom-embedder"><a class="header" href="#custom-embedder">Custom Embedder</a></h2>
<p>Implement the <code>Embedder</code> trait to integrate your own vector embedding model:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use async_trait::async_trait;
use laurus::embedding::embedder::{Embedder, EmbedInput, EmbedInputType};
use laurus::vector::core::vector::Vector;
use laurus::{LaurusError, Result};

#[derive(Debug)]
struct MyEmbedder {
    dimension: usize,
}

#[async_trait]
impl Embedder for MyEmbedder {
    async fn embed(&amp;self, input: &amp;EmbedInput&lt;'_&gt;) -&gt; Result&lt;Vector&gt; {
        match input {
            EmbedInput::Text(text) =&gt; {
                // Your embedding logic here
                let vector = vec![0.0f32; self.dimension];
                Ok(Vector::new(vector))
            }
            _ =&gt; Err(LaurusError::invalid_argument(
                "this embedder only supports text input",
            )),
        }
    }

    fn supported_input_types(&amp;self) -&gt; Vec&lt;EmbedInputType&gt; {
        vec![EmbedInputType::Text]
    }

    fn name(&amp;self) -&gt; &amp;str {
        "my-embedder"
    }

    fn as_any(&amp;self) -&gt; &amp;dyn std::any::Any {
        self
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="required-methods-1"><a class="header" href="#required-methods-1">Required Methods</a></h3>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Method</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>async embed(&amp;self, input: &amp;EmbedInput) -&gt; Result&lt;Vector&gt;</code></td><td style="text-align: left">Generate an embedding vector for the given input</td></tr>
<tr><td style="text-align: left"><code>supported_input_types(&amp;self) -&gt; Vec&lt;EmbedInputType&gt;</code></td><td style="text-align: left">Declare supported input types (<code>Text</code>, <code>Image</code>)</td></tr>
<tr><td style="text-align: left"><code>as_any(&amp;self) -&gt; &amp;dyn Any</code></td><td style="text-align: left">Enable downcasting</td></tr>
</tbody></table>
</div>
<h3 id="optional-methods"><a class="header" href="#optional-methods">Optional Methods</a></h3>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Method</th><th style="text-align: left">Default</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>async embed_batch(&amp;self, inputs) -&gt; Result&lt;Vec&lt;Vector&gt;&gt;</code></td><td style="text-align: left">Sequential calls to <code>embed</code></td><td style="text-align: left">Override for batch optimization</td></tr>
<tr><td style="text-align: left"><code>name(&amp;self) -&gt; &amp;str</code></td><td style="text-align: left"><code>"unknown"</code></td><td style="text-align: left">Identifier for logging</td></tr>
<tr><td style="text-align: left"><code>supports(&amp;self, input_type) -&gt; bool</code></td><td style="text-align: left">Checks <code>supported_input_types</code></td><td style="text-align: left">Input type support check</td></tr>
<tr><td style="text-align: left"><code>supports_text() -&gt; bool</code></td><td style="text-align: left">Checks for <code>Text</code></td><td style="text-align: left">Text support shorthand</td></tr>
<tr><td style="text-align: left"><code>supports_image() -&gt; bool</code></td><td style="text-align: left">Checks for <code>Image</code></td><td style="text-align: left">Image support shorthand</td></tr>
<tr><td style="text-align: left"><code>is_multimodal() -&gt; bool</code></td><td style="text-align: left">Both text and image</td><td style="text-align: left">Multimodal check</td></tr>
</tbody></table>
</div>
<h3 id="using-a-custom-embedder"><a class="header" href="#using-a-custom-embedder">Using a Custom Embedder</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let embedder = Arc::new(MyEmbedder { dimension: 384 });
let engine = Engine::builder(storage, schema)
    .embedder(embedder)
    .build()
    .await?;
<span class="boring">}</span></code></pre></pre>
<p>For per-field embedders, wrap with <code>PerFieldEmbedder</code>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::embedding::per_field::PerFieldEmbedder;

let mut per_field = PerFieldEmbedder::new(Arc::new(MyEmbedder { dimension: 384 }));
per_field.add_embedder("image_vec", Arc::new(ClipEmbedder::new()?));

let engine = Engine::builder(storage, schema)
    .embedder(Arc::new(per_field))
    .build()
    .await?;
<span class="boring">}</span></code></pre></pre>
<h2 id="custom-storage"><a class="header" href="#custom-storage">Custom Storage</a></h2>
<p>Implement the <code>Storage</code> trait to add a new storage backend:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use laurus::storage::{Storage, StorageInput, StorageOutput, LoadingMode, FileMetadata};
use laurus::Result;

#[derive(Debug)]
struct S3Storage {
    bucket: String,
    prefix: String,
}

impl Storage for S3Storage {
    fn loading_mode(&amp;self) -&gt; LoadingMode {
        LoadingMode::Eager  // S3 requires full download
    }

    fn open_input(&amp;self, name: &amp;str) -&gt; Result&lt;Box&lt;dyn StorageInput&gt;&gt; {
        // Download from S3 and return a reader
        todo!()
    }

    fn create_output(&amp;self, name: &amp;str) -&gt; Result&lt;Box&lt;dyn StorageOutput&gt;&gt; {
        // Create an upload stream to S3
        todo!()
    }

    fn create_output_append(&amp;self, name: &amp;str) -&gt; Result&lt;Box&lt;dyn StorageOutput&gt;&gt; {
        todo!()
    }

    fn file_exists(&amp;self, name: &amp;str) -&gt; bool {
        todo!()
    }

    fn delete_file(&amp;self, name: &amp;str) -&gt; Result&lt;()&gt; {
        todo!()
    }

    fn list_files(&amp;self) -&gt; Result&lt;Vec&lt;String&gt;&gt; {
        todo!()
    }

    fn file_size(&amp;self, name: &amp;str) -&gt; Result&lt;u64&gt; {
        todo!()
    }

    fn metadata(&amp;self, name: &amp;str) -&gt; Result&lt;FileMetadata&gt; {
        todo!()
    }

    fn rename_file(&amp;self, old_name: &amp;str, new_name: &amp;str) -&gt; Result&lt;()&gt; {
        todo!()
    }

    fn create_temp_output(&amp;self, prefix: &amp;str) -&gt; Result&lt;(String, Box&lt;dyn StorageOutput&gt;)&gt; {
        todo!()
    }

    fn sync(&amp;self) -&gt; Result&lt;()&gt; {
        todo!()
    }

    fn close(&amp;mut self) -&gt; Result&lt;()&gt; {
        todo!()
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="required-methods-2"><a class="header" href="#required-methods-2">Required Methods</a></h3>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Method</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>open_input(name) -&gt; Result&lt;Box&lt;dyn StorageInput&gt;&gt;</code></td><td style="text-align: left">Open a file for reading</td></tr>
<tr><td style="text-align: left"><code>create_output(name) -&gt; Result&lt;Box&lt;dyn StorageOutput&gt;&gt;</code></td><td style="text-align: left">Create a file for writing</td></tr>
<tr><td style="text-align: left"><code>create_output_append(name) -&gt; Result&lt;Box&lt;dyn StorageOutput&gt;&gt;</code></td><td style="text-align: left">Open a file for appending</td></tr>
<tr><td style="text-align: left"><code>file_exists(name) -&gt; bool</code></td><td style="text-align: left">Check if a file exists</td></tr>
<tr><td style="text-align: left"><code>delete_file(name) -&gt; Result&lt;()&gt;</code></td><td style="text-align: left">Delete a file</td></tr>
<tr><td style="text-align: left"><code>list_files() -&gt; Result&lt;Vec&lt;String&gt;&gt;</code></td><td style="text-align: left">List all files</td></tr>
<tr><td style="text-align: left"><code>file_size(name) -&gt; Result&lt;u64&gt;</code></td><td style="text-align: left">Get file size in bytes</td></tr>
<tr><td style="text-align: left"><code>metadata(name) -&gt; Result&lt;FileMetadata&gt;</code></td><td style="text-align: left">Get file metadata</td></tr>
<tr><td style="text-align: left"><code>rename_file(old, new) -&gt; Result&lt;()&gt;</code></td><td style="text-align: left">Rename a file</td></tr>
<tr><td style="text-align: left"><code>create_temp_output(prefix) -&gt; Result&lt;(String, Box&lt;dyn StorageOutput&gt;)&gt;</code></td><td style="text-align: left">Create a temporary file</td></tr>
<tr><td style="text-align: left"><code>sync() -&gt; Result&lt;()&gt;</code></td><td style="text-align: left">Flush all pending writes</td></tr>
<tr><td style="text-align: left"><code>close(&amp;mut self) -&gt; Result&lt;()&gt;</code></td><td style="text-align: left">Close storage and release resources</td></tr>
</tbody></table>
</div>
<h3 id="optional-methods-1"><a class="header" href="#optional-methods-1">Optional Methods</a></h3>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Method</th><th style="text-align: left">Default</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>loading_mode() -&gt; LoadingMode</code></td><td style="text-align: left"><code>LoadingMode::Eager</code></td><td style="text-align: left">Preferred data loading mode</td></tr>
</tbody></table>
</div>
<h2 id="thread-safety"><a class="header" href="#thread-safety">Thread Safety</a></h2>
<p>All three traits require <code>Send + Sync</code>. This means your implementations must be safe to share across threads. Use <code>Arc&lt;Mutex&lt;_&gt;&gt;</code> or lock-free data structures for shared mutable state.</p>
<h2 id="next-steps-11"><a class="header" href="#next-steps-11">Next Steps</a></h2>
<ul>
<li><a href="advanced/error_handling.html">Error Handling</a> — handle errors in custom implementations</li>
<li><a href="advanced/../concepts/analysis.html">Text Analysis</a> — built-in analyzers and pipeline components</li>
<li><a href="advanced/../concepts/embedding.html">Embeddings</a> — built-in embedder options</li>
<li><a href="advanced/../concepts/storage.html">Storage</a> — built-in storage backends</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="architecture"><a class="header" href="#architecture">Architecture</a></h1>
<p>This page explains how Laurus is structured internally. Understanding the architecture will help you make better decisions about schema design, analyzer selection, and search strategies.</p>
<h2 id="high-level-overview"><a class="header" href="#high-level-overview">High-Level Overview</a></h2>
<p>Laurus is organized around a single <code>Engine</code> that coordinates four internal components:</p>
<pre><code class="language-mermaid">graph TB
    subgraph Engine
        SCH["Schema"]
        LS["LexicalStore\n(Inverted Index)"]
        VS["VectorStore\n(HNSW / Flat / IVF)"]
        DL["DocumentLog\n(WAL + Document Storage)"]
    end

    Storage["Storage (trait)\nMemory / File / File+Mmap"]

    LS --- Storage
    VS --- Storage
    DL --- Storage
</code></pre>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Component</th><th style="text-align: left">Responsibility</th></tr></thead><tbody>
<tr><td style="text-align: left"><strong>Schema</strong></td><td style="text-align: left">Declares fields and their types; determines how each field is routed</td></tr>
<tr><td style="text-align: left"><strong>LexicalStore</strong></td><td style="text-align: left">Inverted index for keyword search (BM25 scoring)</td></tr>
<tr><td style="text-align: left"><strong>VectorStore</strong></td><td style="text-align: left">Vector index for similarity search (Flat, HNSW, or IVF)</td></tr>
<tr><td style="text-align: left"><strong>DocumentLog</strong></td><td style="text-align: left">Write-ahead log (WAL) for durability + raw document storage</td></tr>
</tbody></table>
</div>
<p>All three stores share a single <code>Storage</code> backend, isolated by key prefixes (<code>lexical/</code>, <code>vector/</code>, <code>documents/</code>).</p>
<h2 id="engine-lifecycle"><a class="header" href="#engine-lifecycle">Engine Lifecycle</a></h2>
<h3 id="building-an-engine"><a class="header" href="#building-an-engine">Building an Engine</a></h3>
<p>The <code>EngineBuilder</code> assembles the engine from its parts:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let engine = Engine::builder(storage, schema)
    .analyzer(analyzer)      // optional: for text fields
    .embedder(embedder)      // optional: for vector fields
    .build()
    .await?;
<span class="boring">}</span></code></pre></pre>
<pre><code class="language-mermaid">sequenceDiagram
    participant User
    participant EngineBuilder
    participant Engine

    User-&gt;&gt;EngineBuilder: new(storage, schema)
    User-&gt;&gt;EngineBuilder: .analyzer(analyzer)
    User-&gt;&gt;EngineBuilder: .embedder(embedder)
    User-&gt;&gt;EngineBuilder: .build().await
    EngineBuilder-&gt;&gt;EngineBuilder: split_schema()
    Note over EngineBuilder: Separate fields into\nLexicalIndexConfig\n+ VectorIndexConfig
    EngineBuilder-&gt;&gt;Engine: Create LexicalStore
    EngineBuilder-&gt;&gt;Engine: Create VectorStore
    EngineBuilder-&gt;&gt;Engine: Create DocumentLog
    EngineBuilder-&gt;&gt;Engine: Recover from WAL
    EngineBuilder--&gt;&gt;User: Engine ready
</code></pre>
<p>During <code>build()</code>, the engine:</p>
<ol>
<li><strong>Splits the schema</strong> — lexical fields go to <code>LexicalIndexConfig</code>, vector fields go to <code>VectorIndexConfig</code></li>
<li><strong>Creates prefixed storage</strong> — each component gets an isolated namespace (<code>lexical/</code>, <code>vector/</code>, <code>documents/</code>)</li>
<li><strong>Initializes stores</strong> — <code>LexicalStore</code> and <code>VectorStore</code> are constructed with their configs</li>
<li><strong>Recovers from WAL</strong> — replays any uncommitted operations from a previous session</li>
</ol>
<h3 id="schema-splitting"><a class="header" href="#schema-splitting">Schema Splitting</a></h3>
<p>The <code>Schema</code> contains both lexical and vector fields. At build time, <code>split_schema()</code> separates them:</p>
<pre><code class="language-mermaid">graph LR
    S["Schema\ntitle: Text\nbody: Text\ncategory: Text\npage: Integer\ncontent_vec: HNSW"]

    S --&gt; LC["LexicalIndexConfig\ntitle: TextOption\nbody: TextOption\ncategory: TextOption\npage: IntegerOption\n_id: KeywordAnalyzer"]

    S --&gt; VC["VectorIndexConfig\ncontent_vec: HnswOption\n(dim=384, m=16, ef=200)"]
</code></pre>
<p>Key details:</p>
<ul>
<li>The reserved <code>_id</code> field is always added to the lexical config with <code>KeywordAnalyzer</code> (exact match)</li>
<li>A <code>PerFieldAnalyzer</code> wraps per-field analyzer settings; if you pass a simple <code>StandardAnalyzer</code>, it becomes the default for all text fields</li>
<li>A <code>PerFieldEmbedder</code> works the same way for vector fields</li>
</ul>
<h2 id="indexing-data-flow"><a class="header" href="#indexing-data-flow">Indexing Data Flow</a></h2>
<p>When you call <code>engine.add_document(id, doc)</code>:</p>
<pre><code class="language-mermaid">sequenceDiagram
    participant User
    participant Engine
    participant WAL as DocumentLog (WAL)
    participant Lexical as LexicalStore
    participant Vector as VectorStore

    User-&gt;&gt;Engine: add_document("doc-1", doc)
    Engine-&gt;&gt;WAL: Append to WAL
    Engine-&gt;&gt;Engine: Assign internal ID (u64)

    loop For each field in document
        alt Lexical field (text, integer, etc.)
            Engine-&gt;&gt;Lexical: Analyze + index field
        else Vector field
            Engine-&gt;&gt;Vector: Embed + index field
        end
    end

    Note over Engine: Document is buffered\nbut NOT yet searchable

    User-&gt;&gt;Engine: commit()
    Engine-&gt;&gt;Lexical: Flush segments to storage
    Engine-&gt;&gt;Vector: Flush segments to storage
    Engine-&gt;&gt;WAL: Truncate WAL
    Note over Engine: Documents are\nnow searchable
</code></pre>
<p>Key points:</p>
<ul>
<li><strong>WAL-first</strong>: every write is logged before modifying in-memory structures</li>
<li><strong>Dual indexing</strong>: each field is routed to either the lexical or vector store based on the schema</li>
<li><strong>Commit required</strong>: documents become searchable only after <code>commit()</code></li>
</ul>
<h2 id="search-data-flow"><a class="header" href="#search-data-flow">Search Data Flow</a></h2>
<p>When you call <code>engine.search(request)</code>:</p>
<pre><code class="language-mermaid">sequenceDiagram
    participant User
    participant Engine
    participant Lexical as LexicalStore
    participant Vector as VectorStore
    participant Fusion

    User-&gt;&gt;Engine: search(request)

    opt Filter query present
        Engine-&gt;&gt;Lexical: Execute filter query
        Lexical--&gt;&gt;Engine: Allowed document IDs
    end

    par Lexical search
        Engine-&gt;&gt;Lexical: Execute lexical query
        Lexical--&gt;&gt;Engine: Ranked hits (BM25)
    and Vector search
        Engine-&gt;&gt;Vector: Execute vector query
        Vector--&gt;&gt;Engine: Ranked hits (similarity)
    end

    alt Both lexical and vector results
        Engine-&gt;&gt;Fusion: Fuse results (RRF or WeightedSum)
        Fusion--&gt;&gt;Engine: Merged ranked list
    end

    Engine-&gt;&gt;Engine: Apply offset + limit
    Engine--&gt;&gt;User: Vec of SearchResult
</code></pre>
<p>The search pipeline has three stages:</p>
<ol>
<li><strong>Filter</strong> (optional) — execute a filter query on the lexical index to get a set of allowed document IDs</li>
<li><strong>Search</strong> — run lexical and/or vector queries in parallel</li>
<li><strong>Fusion</strong> — if both query types are present, merge results using RRF (default, k=60) or WeightedSum</li>
</ol>
<h2 id="storage-architecture"><a class="header" href="#storage-architecture">Storage Architecture</a></h2>
<p>All components share a single <code>Storage</code> trait implementation, but use key prefixes to isolate their data:</p>
<pre><code class="language-mermaid">graph TB
    Engine --&gt; PS1["PrefixedStorage\nprefix: 'lexical/'"]
    Engine --&gt; PS2["PrefixedStorage\nprefix: 'vector/'"]
    Engine --&gt; PS3["PrefixedStorage\nprefix: 'documents/'"]

    PS1 --&gt; S["Storage Backend\n(Memory / File / File+Mmap)"]
    PS2 --&gt; S
    PS3 --&gt; S
</code></pre>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Backend</th><th style="text-align: left">Description</th><th style="text-align: left">Best For</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>MemoryStorage</code></td><td style="text-align: left">All data in memory</td><td style="text-align: left">Testing, small datasets, ephemeral use</td></tr>
<tr><td style="text-align: left"><code>FileStorage</code></td><td style="text-align: left">Standard file I/O</td><td style="text-align: left">General production use</td></tr>
<tr><td style="text-align: left"><code>FileStorage</code> (mmap)</td><td style="text-align: left">Memory-mapped files (<code>use_mmap = true</code>)</td><td style="text-align: left">Large datasets, read-heavy workloads</td></tr>
</tbody></table>
</div>
<h2 id="per-field-dispatch"><a class="header" href="#per-field-dispatch">Per-Field Dispatch</a></h2>
<p>When a <code>PerFieldAnalyzer</code> is provided, the engine dispatches analysis to field-specific analyzers. The same pattern applies to <code>PerFieldEmbedder</code>.</p>
<pre><code class="language-mermaid">graph LR
    PFA["PerFieldAnalyzer"]
    PFA --&gt;|"title"| KA["KeywordAnalyzer"]
    PFA --&gt;|"body"| SA["StandardAnalyzer"]
    PFA --&gt;|"description"| JA["JapaneseAnalyzer"]
    PFA --&gt;|"_id"| KA2["KeywordAnalyzer\n(always)"]
    PFA --&gt;|other fields| DEF["Default Analyzer\n(StandardAnalyzer)"]
</code></pre>
<p>This allows different fields to use different analysis strategies within the same engine.</p>
<h2 id="summary"><a class="header" href="#summary">Summary</a></h2>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Aspect</th><th style="text-align: left">Detail</th></tr></thead><tbody>
<tr><td style="text-align: left"><strong>Core struct</strong></td><td style="text-align: left"><code>Engine</code> — coordinates all operations</td></tr>
<tr><td style="text-align: left"><strong>Builder</strong></td><td style="text-align: left"><code>EngineBuilder</code> — assembles Engine from Storage + Schema + Analyzer + Embedder</td></tr>
<tr><td style="text-align: left"><strong>Schema split</strong></td><td style="text-align: left">Lexical fields → <code>LexicalIndexConfig</code>, Vector fields → <code>VectorIndexConfig</code></td></tr>
<tr><td style="text-align: left"><strong>Write path</strong></td><td style="text-align: left">WAL → in-memory buffers → <code>commit()</code> → persistent storage</td></tr>
<tr><td style="text-align: left"><strong>Read path</strong></td><td style="text-align: left">Query → parallel lexical/vector search → fusion → ranked results</td></tr>
<tr><td style="text-align: left"><strong>Storage isolation</strong></td><td style="text-align: left"><code>PrefixedStorage</code> with <code>lexical/</code>, <code>vector/</code>, <code>documents/</code> prefixes</td></tr>
<tr><td style="text-align: left"><strong>Per-field dispatch</strong></td><td style="text-align: left"><code>PerFieldAnalyzer</code> and <code>PerFieldEmbedder</code> route to field-specific implementations</td></tr>
</tbody></table>
</div>
<h2 id="next-steps-12"><a class="header" href="#next-steps-12">Next Steps</a></h2>
<ul>
<li>Understand field types and schema design: <a href="concepts/schema_and_fields.html">Schema &amp; Fields</a></li>
<li>Learn about text analysis: <a href="concepts/analysis.html">Text Analysis</a></li>
<li>Learn about embeddings: <a href="concepts/embedding.html">Embeddings</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="api-reference"><a class="header" href="#api-reference">API Reference</a></h1>
<p>This page provides a quick reference of the most important types and methods in Laurus. For full details, generate the Rustdoc:</p>
<pre><code class="language-bash">cargo doc --open
</code></pre>
<h2 id="engine"><a class="header" href="#engine">Engine</a></h2>
<p>The central coordinator for all indexing and search operations.</p>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Method</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>Engine::builder(storage, schema)</code></td><td style="text-align: left">Create an <code>EngineBuilder</code></td></tr>
<tr><td style="text-align: left"><code>engine.put_document(id, doc).await?</code></td><td style="text-align: left">Upsert a document (replace if ID exists)</td></tr>
<tr><td style="text-align: left"><code>engine.add_document(id, doc).await?</code></td><td style="text-align: left">Add a document as a chunk (multiple chunks can share an ID)</td></tr>
<tr><td style="text-align: left"><code>engine.delete_documents(id).await?</code></td><td style="text-align: left">Delete all documents/chunks by external ID</td></tr>
<tr><td style="text-align: left"><code>engine.get_documents(id).await?</code></td><td style="text-align: left">Get all documents/chunks by external ID</td></tr>
<tr><td style="text-align: left"><code>engine.search(request).await?</code></td><td style="text-align: left">Execute a search request</td></tr>
<tr><td style="text-align: left"><code>engine.commit().await?</code></td><td style="text-align: left">Flush all pending changes to storage</td></tr>
<tr><td style="text-align: left"><code>engine.stats()?</code></td><td style="text-align: left">Get index statistics</td></tr>
</tbody></table>
</div>
<blockquote>
<p><strong><code>put_document</code> vs <code>add_document</code>:</strong> <code>put_document</code> performs an upsert — if a document with the same external ID already exists, it is deleted and replaced. <code>add_document</code> always appends, allowing multiple document chunks to share the same external ID. See <a href="concepts/schema_and_fields.html#indexing-documents">Schema &amp; Fields — Indexing Documents</a> for details.</p>
</blockquote>
<h3 id="enginebuilder"><a class="header" href="#enginebuilder">EngineBuilder</a></h3>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Method</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>EngineBuilder::new(storage, schema)</code></td><td style="text-align: left">Create a builder with storage and schema</td></tr>
<tr><td style="text-align: left"><code>.analyzer(Arc&lt;dyn Analyzer&gt;)</code></td><td style="text-align: left">Set the text analyzer (default: <code>StandardAnalyzer</code>)</td></tr>
<tr><td style="text-align: left"><code>.embedder(Arc&lt;dyn Embedder&gt;)</code></td><td style="text-align: left">Set the vector embedder (optional)</td></tr>
<tr><td style="text-align: left"><code>.build().await?</code></td><td style="text-align: left">Build the <code>Engine</code></td></tr>
</tbody></table>
</div>
<h2 id="schema-1"><a class="header" href="#schema-1">Schema</a></h2>
<p>Defines document structure.</p>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Method</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>Schema::builder()</code></td><td style="text-align: left">Create a <code>SchemaBuilder</code></td></tr>
</tbody></table>
</div>
<h3 id="schemabuilder"><a class="header" href="#schemabuilder">SchemaBuilder</a></h3>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Method</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>.add_text_field(name, TextOption)</code></td><td style="text-align: left">Add a full-text field</td></tr>
<tr><td style="text-align: left"><code>.add_integer_field(name, IntegerOption)</code></td><td style="text-align: left">Add an integer field</td></tr>
<tr><td style="text-align: left"><code>.add_float_field(name, FloatOption)</code></td><td style="text-align: left">Add a float field</td></tr>
<tr><td style="text-align: left"><code>.add_boolean_field(name, BooleanOption)</code></td><td style="text-align: left">Add a boolean field</td></tr>
<tr><td style="text-align: left"><code>.add_datetime_field(name, DateTimeOption)</code></td><td style="text-align: left">Add a datetime field</td></tr>
<tr><td style="text-align: left"><code>.add_geo_field(name, GeoOption)</code></td><td style="text-align: left">Add a geographic field</td></tr>
<tr><td style="text-align: left"><code>.add_bytes_field(name, BytesOption)</code></td><td style="text-align: left">Add a binary field</td></tr>
<tr><td style="text-align: left"><code>.add_hnsw_field(name, HnswOption)</code></td><td style="text-align: left">Add an HNSW vector field</td></tr>
<tr><td style="text-align: left"><code>.add_flat_field(name, FlatOption)</code></td><td style="text-align: left">Add a Flat vector field</td></tr>
<tr><td style="text-align: left"><code>.add_ivf_field(name, IvfOption)</code></td><td style="text-align: left">Add an IVF vector field</td></tr>
<tr><td style="text-align: left"><code>.add_default_field(name)</code></td><td style="text-align: left">Set a default search field</td></tr>
<tr><td style="text-align: left"><code>.build()</code></td><td style="text-align: left">Build the <code>Schema</code></td></tr>
</tbody></table>
</div>
<h2 id="document-1"><a class="header" href="#document-1">Document</a></h2>
<p>A collection of named field values.</p>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Method</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>Document::builder()</code></td><td style="text-align: left">Create a <code>DocumentBuilder</code></td></tr>
<tr><td style="text-align: left"><code>doc.get(name)</code></td><td style="text-align: left">Get a field value by name</td></tr>
<tr><td style="text-align: left"><code>doc.has_field(name)</code></td><td style="text-align: left">Check if a field exists</td></tr>
<tr><td style="text-align: left"><code>doc.field_names()</code></td><td style="text-align: left">Get all field names</td></tr>
</tbody></table>
</div>
<h3 id="documentbuilder"><a class="header" href="#documentbuilder">DocumentBuilder</a></h3>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Method</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>.add_text(name, value)</code></td><td style="text-align: left">Add a text field</td></tr>
<tr><td style="text-align: left"><code>.add_integer(name, value)</code></td><td style="text-align: left">Add an integer field</td></tr>
<tr><td style="text-align: left"><code>.add_float(name, value)</code></td><td style="text-align: left">Add a float field</td></tr>
<tr><td style="text-align: left"><code>.add_boolean(name, value)</code></td><td style="text-align: left">Add a boolean field</td></tr>
<tr><td style="text-align: left"><code>.add_datetime(name, value)</code></td><td style="text-align: left">Add a datetime field</td></tr>
<tr><td style="text-align: left"><code>.add_vector(name, vec)</code></td><td style="text-align: left">Add a pre-computed vector</td></tr>
<tr><td style="text-align: left"><code>.add_geo(name, lat, lon)</code></td><td style="text-align: left">Add a geographic point</td></tr>
<tr><td style="text-align: left"><code>.add_bytes(name, data)</code></td><td style="text-align: left">Add binary data</td></tr>
<tr><td style="text-align: left"><code>.build()</code></td><td style="text-align: left">Build the <code>Document</code></td></tr>
</tbody></table>
</div>
<h2 id="search-2"><a class="header" href="#search-2">Search</a></h2>
<h3 id="searchrequestbuilder"><a class="header" href="#searchrequestbuilder">SearchRequestBuilder</a></h3>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Method</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>SearchRequestBuilder::new()</code></td><td style="text-align: left">Create a new builder</td></tr>
<tr><td style="text-align: left"><code>.lexical_search_request(req)</code></td><td style="text-align: left">Set the lexical search component</td></tr>
<tr><td style="text-align: left"><code>.vector_search_request(req)</code></td><td style="text-align: left">Set the vector search component</td></tr>
<tr><td style="text-align: left"><code>.filter_query(query)</code></td><td style="text-align: left">Set a pre-filter query</td></tr>
<tr><td style="text-align: left"><code>.fusion_algorithm(algo)</code></td><td style="text-align: left">Set the fusion algorithm (default: RRF)</td></tr>
<tr><td style="text-align: left"><code>.limit(n)</code></td><td style="text-align: left">Maximum results (default: 10)</td></tr>
<tr><td style="text-align: left"><code>.offset(n)</code></td><td style="text-align: left">Skip N results (default: 0)</td></tr>
<tr><td style="text-align: left"><code>.build()</code></td><td style="text-align: left">Build the <code>SearchRequest</code></td></tr>
</tbody></table>
</div>
<h3 id="lexicalsearchrequest"><a class="header" href="#lexicalsearchrequest">LexicalSearchRequest</a></h3>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Method</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>LexicalSearchRequest::new(query)</code></td><td style="text-align: left">Create with a query</td></tr>
<tr><td style="text-align: left"><code>LexicalSearchRequest::from_dsl(query_str)</code></td><td style="text-align: left">Create from a DSL query string</td></tr>
<tr><td style="text-align: left"><code>.limit(n)</code></td><td style="text-align: left">Maximum results</td></tr>
<tr><td style="text-align: left"><code>.load_documents(bool)</code></td><td style="text-align: left">Whether to load document content</td></tr>
<tr><td style="text-align: left"><code>.min_score(f32)</code></td><td style="text-align: left">Minimum score threshold</td></tr>
<tr><td style="text-align: left"><code>.timeout_ms(u64)</code></td><td style="text-align: left">Search timeout in milliseconds</td></tr>
<tr><td style="text-align: left"><code>.parallel(bool)</code></td><td style="text-align: left">Enable parallel search</td></tr>
<tr><td style="text-align: left"><code>.sort_by_field_asc(field)</code></td><td style="text-align: left">Sort by field ascending</td></tr>
<tr><td style="text-align: left"><code>.sort_by_field_desc(field)</code></td><td style="text-align: left">Sort by field descending</td></tr>
<tr><td style="text-align: left"><code>.sort_by_score()</code></td><td style="text-align: left">Sort by relevance score (default)</td></tr>
<tr><td style="text-align: left"><code>.with_field_boost(field, boost)</code></td><td style="text-align: left">Add field-level boost</td></tr>
</tbody></table>
</div>
<h3 id="vectorsearchrequestbuilder-1"><a class="header" href="#vectorsearchrequestbuilder-1">VectorSearchRequestBuilder</a></h3>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Method</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>VectorSearchRequestBuilder::new()</code></td><td style="text-align: left">Create a new builder</td></tr>
<tr><td style="text-align: left"><code>.add_text(field, text)</code></td><td style="text-align: left">Add a text query for a field</td></tr>
<tr><td style="text-align: left"><code>.add_vector(field, vector)</code></td><td style="text-align: left">Add a pre-computed query vector</td></tr>
<tr><td style="text-align: left"><code>.add_bytes(field, bytes, mime)</code></td><td style="text-align: left">Add a binary payload (for multimodal)</td></tr>
<tr><td style="text-align: left"><code>.limit(n)</code></td><td style="text-align: left">Maximum results</td></tr>
<tr><td style="text-align: left"><code>.score_mode(VectorScoreMode)</code></td><td style="text-align: left">Score combination mode (WeightedSum, MaxSim)</td></tr>
<tr><td style="text-align: left"><code>.min_score(f32)</code></td><td style="text-align: left">Minimum score threshold</td></tr>
<tr><td style="text-align: left"><code>.field(name)</code></td><td style="text-align: left">Restrict search to a specific field</td></tr>
<tr><td style="text-align: left"><code>.build()</code></td><td style="text-align: left">Build the request</td></tr>
</tbody></table>
</div>
<h3 id="searchresult-1"><a class="header" href="#searchresult-1">SearchResult</a></h3>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Field</th><th style="text-align: left">Type</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>id</code></td><td style="text-align: left"><code>String</code></td><td style="text-align: left">External document ID</td></tr>
<tr><td style="text-align: left"><code>score</code></td><td style="text-align: left"><code>f32</code></td><td style="text-align: left">Relevance score</td></tr>
<tr><td style="text-align: left"><code>document</code></td><td style="text-align: left"><code>Option&lt;Document&gt;</code></td><td style="text-align: left">Document content (if loaded)</td></tr>
</tbody></table>
</div>
<h3 id="fusionalgorithm"><a class="header" href="#fusionalgorithm">FusionAlgorithm</a></h3>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Variant</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>RRF { k: f64 }</code></td><td style="text-align: left">Reciprocal Rank Fusion (default k=60.0)</td></tr>
<tr><td style="text-align: left"><code>WeightedSum { lexical_weight, vector_weight }</code></td><td style="text-align: left">Linear combination of scores</td></tr>
</tbody></table>
</div>
<h2 id="query-types-lexical"><a class="header" href="#query-types-lexical">Query Types (Lexical)</a></h2>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Query</th><th style="text-align: left">Description</th><th style="text-align: left">Example</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>TermQuery::new(field, term)</code></td><td style="text-align: left">Exact term match</td><td style="text-align: left"><code>TermQuery::new("body", "rust")</code></td></tr>
<tr><td style="text-align: left"><code>PhraseQuery::new(field, terms)</code></td><td style="text-align: left">Exact phrase</td><td style="text-align: left"><code>PhraseQuery::new("body", vec!["machine".into(), "learning".into()])</code></td></tr>
<tr><td style="text-align: left"><code>BooleanQueryBuilder::new()</code></td><td style="text-align: left">Boolean combination</td><td style="text-align: left"><code>.must(q1).should(q2).must_not(q3).build()</code></td></tr>
<tr><td style="text-align: left"><code>FuzzyQuery::new(field, term)</code></td><td style="text-align: left">Fuzzy match (default max_edits=2)</td><td style="text-align: left"><code>FuzzyQuery::new("body", "programing").max_edits(1)</code></td></tr>
<tr><td style="text-align: left"><code>WildcardQuery::new(field, pattern)</code></td><td style="text-align: left">Wildcard</td><td style="text-align: left"><code>WildcardQuery::new("file", "*.pdf")</code></td></tr>
<tr><td style="text-align: left"><code>NumericRangeQuery::new(...)</code></td><td style="text-align: left">Numeric range</td><td style="text-align: left">See <a href="search/lexical_search.html">Lexical Search</a></td></tr>
<tr><td style="text-align: left"><code>GeoQuery::within_radius(...)</code></td><td style="text-align: left">Geo radius</td><td style="text-align: left">See <a href="search/lexical_search.html">Lexical Search</a></td></tr>
<tr><td style="text-align: left"><code>SpanNearQuery::new(...)</code></td><td style="text-align: left">Proximity</td><td style="text-align: left">See <a href="search/lexical_search.html">Lexical Search</a></td></tr>
<tr><td style="text-align: left"><code>PrefixQuery::new(field, prefix)</code></td><td style="text-align: left">Prefix match</td><td style="text-align: left"><code>PrefixQuery::new("body", "pro")</code></td></tr>
<tr><td style="text-align: left"><code>RegexpQuery::new(field, pattern)?</code></td><td style="text-align: left">Regex match</td><td style="text-align: left"><code>RegexpQuery::new("body", "^pro.*ing$")?</code></td></tr>
</tbody></table>
</div>
<h2 id="query-parsers"><a class="header" href="#query-parsers">Query Parsers</a></h2>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Parser</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>QueryParser::new(analyzer)</code></td><td style="text-align: left">Parse lexical DSL queries</td></tr>
<tr><td style="text-align: left"><code>VectorQueryParser::new(embedder)</code></td><td style="text-align: left">Parse vector DSL queries</td></tr>
<tr><td style="text-align: left"><code>UnifiedQueryParser::new(lexical, vector)</code></td><td style="text-align: left">Parse hybrid DSL queries</td></tr>
</tbody></table>
</div>
<h2 id="analyzers"><a class="header" href="#analyzers">Analyzers</a></h2>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Type</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>StandardAnalyzer</code></td><td style="text-align: left">RegexTokenizer + lowercase + stop words</td></tr>
<tr><td style="text-align: left"><code>SimpleAnalyzer</code></td><td style="text-align: left">Tokenization only (no filtering)</td></tr>
<tr><td style="text-align: left"><code>EnglishAnalyzer</code></td><td style="text-align: left">RegexTokenizer + lowercase + English stop words</td></tr>
<tr><td style="text-align: left"><code>JapaneseAnalyzer</code></td><td style="text-align: left">Japanese morphological analysis</td></tr>
<tr><td style="text-align: left"><code>KeywordAnalyzer</code></td><td style="text-align: left">No tokenization (exact match)</td></tr>
<tr><td style="text-align: left"><code>PipelineAnalyzer</code></td><td style="text-align: left">Custom tokenizer + filter chain</td></tr>
<tr><td style="text-align: left"><code>PerFieldAnalyzer</code></td><td style="text-align: left">Per-field analyzer dispatch</td></tr>
</tbody></table>
</div>
<h2 id="embedders"><a class="header" href="#embedders">Embedders</a></h2>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Type</th><th style="text-align: left">Feature Flag</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>CandleBertEmbedder</code></td><td style="text-align: left"><code>embeddings-candle</code></td><td style="text-align: left">Local BERT model</td></tr>
<tr><td style="text-align: left"><code>OpenAIEmbedder</code></td><td style="text-align: left"><code>embeddings-openai</code></td><td style="text-align: left">OpenAI API</td></tr>
<tr><td style="text-align: left"><code>CandleClipEmbedder</code></td><td style="text-align: left"><code>embeddings-multimodal</code></td><td style="text-align: left">Local CLIP model</td></tr>
<tr><td style="text-align: left"><code>PrecomputedEmbedder</code></td><td style="text-align: left"><em>(default)</em></td><td style="text-align: left">Pre-computed vectors</td></tr>
<tr><td style="text-align: left"><code>PerFieldEmbedder</code></td><td style="text-align: left"><em>(default)</em></td><td style="text-align: left">Per-field embedder dispatch</td></tr>
</tbody></table>
</div>
<h2 id="storage-2"><a class="header" href="#storage-2">Storage</a></h2>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Type</th><th style="text-align: left">Description</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>MemoryStorage</code></td><td style="text-align: left">In-memory (non-durable)</td></tr>
<tr><td style="text-align: left"><code>FileStorage</code></td><td style="text-align: left">File-system based (supports <code>use_mmap</code> for memory-mapped I/O)</td></tr>
<tr><td style="text-align: left"><code>StorageFactory::create(config)</code></td><td style="text-align: left">Create from config</td></tr>
</tbody></table>
</div>
<h2 id="datavalue-1"><a class="header" href="#datavalue-1">DataValue</a></h2>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Variant</th><th style="text-align: left">Rust Type</th></tr></thead><tbody>
<tr><td style="text-align: left"><code>DataValue::Null</code></td><td style="text-align: left">—</td></tr>
<tr><td style="text-align: left"><code>DataValue::Bool(bool)</code></td><td style="text-align: left"><code>bool</code></td></tr>
<tr><td style="text-align: left"><code>DataValue::Int64(i64)</code></td><td style="text-align: left"><code>i64</code></td></tr>
<tr><td style="text-align: left"><code>DataValue::Float64(f64)</code></td><td style="text-align: left"><code>f64</code></td></tr>
<tr><td style="text-align: left"><code>DataValue::Text(String)</code></td><td style="text-align: left"><code>String</code></td></tr>
<tr><td style="text-align: left"><code>DataValue::Bytes(Vec&lt;u8&gt;, Option&lt;String&gt;)</code></td><td style="text-align: left"><code>(data, mime_type)</code></td></tr>
<tr><td style="text-align: left"><code>DataValue::Vector(Vec&lt;f32&gt;)</code></td><td style="text-align: left"><code>Vec&lt;f32&gt;</code></td></tr>
<tr><td style="text-align: left"><code>DataValue::DateTime(DateTime&lt;Utc&gt;)</code></td><td style="text-align: left"><code>chrono::DateTime&lt;Utc&gt;</code></td></tr>
<tr><td style="text-align: left"><code>DataValue::Geo(f64, f64)</code></td><td style="text-align: left"><code>(latitude, longitude)</code></td></tr>
</tbody></table>
</div>
                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->
        <script src="mermaid.min.js"></script>
        <script src="mermaid-init.js"></script>

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>


    </div>
    </body>
</html>
